
<!DOCTYPE HTML>

<html lang="en" class="_theme-default">

<head>
  <meta charset="utf-8">
  <title>tf.Tensor - TensorFlow 1.15 - W3cubDocs</title>
  
  <meta name="description" content=" ">
  <meta name="keywords" content="tf, tensor, tensorflow, tensorflow~1.15">
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="mobile-web-app-capable" content="yes">
  
  <link rel="canonical" href="https://docs.w3cub.com/tensorflow~1.15/tensor.html">
  <link href="/favicon.png" rel="icon">
  <link rel="stylesheet" type="text/css" href="/assets/application-e4ebd3a2a5652ff55173659804c4390a004917f3bdd17b5bb3ba78ea5c9c46fe181cadaac34517ccd815f5bdc982bbfe67179d6f4ac2f084ef2265e2a3dc8dc5.css" integrity="sha512-5OvToqVlL/VRc2WYBMQ5CgBJF/O90Xtbs7p46lycRv4YHK2qw0UXzNgV9b3Jgrv+Zxedb0rC8ITvImXio9yNxQ==" crossorigin="anonymous">
  <script type="text/javascript" integrity="sha512-EpkDeu98lN/jPKijllzVWdRg/dUSSMCaldYZNFz6bcNoBvpWRNz0HSTRQJ3ENmQc5Cuj1zDW1vHd7b0DzpOgyA==" crossorigin="anonymous" src="/assets/application-1299037aef7c94dfe33ca8a3965cd559d460fdd51248c09a95d619345cfa6dc36806fa5644dcf41d24d1409dc436641ce42ba3d730d6d6f1ddedbd03ce93a0c8.js"></script>
  <script src="/json/tensorflow~1.15.js"></script>
  
  <script type="text/javascript">
    var _gaq = _gaq || [];
    _gaq.push(['_setAccount', 'UA-71174418-1']);
    _gaq.push(['_trackPageview']);

    (function() {
      var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
      ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
      var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
    })();
  </script>
  <script data-ad-client="ca-pub-2572770204602497" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script async custom-element="amp-auto-ads"
  src="https://cdn.ampproject.org/v0/amp-auto-ads-0.1.js">
</script>


</head>

<body>
	<amp-auto-ads type="adsense"
              data-ad-client="ca-pub-2572770204602497">
	</amp-auto-ads>
	<div class="_app">
	<header class="_header">
  
  <form class="_search">
    <input type="search" class="_search-input" placeholder="Search&hellip;" autocomplete="off" autocapitalize="off" autocorrect="off" spellcheck="false" maxlength="20">
    <a class="_search-clear"></a>
    <div class="_search-tag"></div>
  </form>
  
  <a class="_home-link" href="/" ></a>
  <a class="_menu-link"></a>
  <h1 class="_logo">
    <a href="/" class="_nav-link" title="API Documentation Browser">W3cubDocs</a>
  </h1>
  
  <span class="_logo-sub-nav">/</span><span class="_logo-sub-nav"><a href="/tensorflow~1.15/" class="_nav-link" title="" style="margin-left:0;">TensorFlow 1.15</a></span>
  
  <nav class="_nav">
    <a href="https://tools.w3cub.com/?_sp=docs" target="_blank" class="_nav-link ">W3cubTools</a>
    <a href="/cheatsheets/" class="_nav-link ">Cheatsheets</a>
    <a href="/about/" class="_nav-link ">About</a>
  </nav>
</header>
	<section class="_sidebar">
		<div class="_list-wrap">
			<div class="_list">
			
			</div>
		</div>
	</section>
	<section class="_container ">
		<div class="_content">
			<ins class="adsbygoogle"
     style="display:block"
     data-ad-client="ca-pub-2572770204602497"
     data-ad-slot="6861657091"
     data-ad-format="link"
     data-full-width-responsive="true"></ins>
<script>
     (adsbygoogle = window.adsbygoogle || []).push({});
</script>
			<div class="_page _tensorflow">
				
				
<h1 class="devsite-page-title">tf.Tensor</h1>   <p><devsite-mathjax config="TeX-AMS-MML_SVG"></devsite-mathjax> </p>   <table class="tfo-notebook-buttons tfo-api" align="left">  <td> <a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/v1.15.0/tensorflow/python/framework/ops.py#L288-L851">  View source on GitHub </a> </td> </table> <p>Represents one of the outputs of an <code translate="no" dir="ltr">Operation</code>.</p> <section class="expandable"> <h4 class="showalways" id="view-aliases" data-text="View aliases" tabindex="0">View aliases</h4> <p> <b>Compat aliases for migration</b> </p>
<p>See <a href="https://www.tensorflow.org/guide/migrate">Migration guide</a> for more details.</p> <p><a href="https://www.tensorflow.org/api_docs/python/tf/Tensor"><code translate="no" dir="ltr">tf.compat.v1.Tensor</code></a>, `tf.compat.v2.Tensor`</p> </section> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
tf.Tensor(
    op, value_index, dtype
)
</pre>  <p>A <code translate="no" dir="ltr">Tensor</code> is a symbolic handle to one of the outputs of an <code translate="no" dir="ltr">Operation</code>. It does not hold the values of that operation's output, but instead provides a means of computing those values in a TensorFlow <a href="session"><code translate="no" dir="ltr">tf.compat.v1.Session</code></a>.</p> <p>This class has two primary purposes:</p> <ol> <li><p>A <code translate="no" dir="ltr">Tensor</code> can be passed as an input to another <code translate="no" dir="ltr">Operation</code>. This builds a dataflow connection between operations, which enables TensorFlow to execute an entire <code translate="no" dir="ltr">Graph</code> that represents a large, multi-step computation.</p></li> <li><p>After the graph has been launched in a session, the value of the <code translate="no" dir="ltr">Tensor</code> can be computed by passing it to <a href="session#run"><code translate="no" dir="ltr">tf.Session.run</code></a>. <code translate="no" dir="ltr">t.eval()</code> is a shortcut for calling <code translate="no" dir="ltr">tf.compat.v1.get_default_session().run(t)</code>.</p></li> </ol> <p>In the following example, <code translate="no" dir="ltr">c</code>, <code translate="no" dir="ltr">d</code>, and <code translate="no" dir="ltr">e</code> are symbolic <code translate="no" dir="ltr">Tensor</code> objects, whereas <code translate="no" dir="ltr">result</code> is a numpy array that stores a concrete value:</p> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python"># Build a dataflow graph.
c = tf.constant([[1.0, 2.0], [3.0, 4.0]])
d = tf.constant([[1.0, 1.0], [0.0, 1.0]])
e = tf.matmul(c, d)

# Construct a `Session` to execute the graph.
sess = tf.compat.v1.Session()

# Execute the graph and store the value that `e` represents in `result`.
result = sess.run(e)
</pre>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Args</th></tr> 
<tr> <td> <code translate="no" dir="ltr">op</code> </td> <td> An <code translate="no" dir="ltr">Operation</code>. <code translate="no" dir="ltr">Operation</code> that computes this tensor. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">value_index</code> </td> <td> An <code translate="no" dir="ltr">int</code>. Index of the operation's endpoint that produces this tensor. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">dtype</code> </td> <td> A <code translate="no" dir="ltr">DType</code>. Type of elements stored in this tensor. </td> </tr> </table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Raises</th></tr> 
<tr> <td> <code translate="no" dir="ltr">TypeError</code> </td> <td> If the op is not an <code translate="no" dir="ltr">Operation</code>. </td> </tr> </table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Attributes</th></tr> 
<tr> <td> <code translate="no" dir="ltr">device</code> </td> <td> The name of the device on which this tensor will be produced, or None. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">dtype</code> </td> <td> The <code translate="no" dir="ltr">DType</code> of elements in this tensor. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">graph</code> </td> <td> The <code translate="no" dir="ltr">Graph</code> that contains this tensor. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">name</code> </td> <td> The string name of this tensor. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">op</code> </td> <td> The <code translate="no" dir="ltr">Operation</code> that produces this tensor as an output. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">shape</code> </td> <td> Returns the <code translate="no" dir="ltr">TensorShape</code> that represents the shape of this tensor. <p>The shape is computed using shape inference functions that are registered in the Op for each <code translate="no" dir="ltr">Operation</code>. See <a href="tensorshape"><code translate="no" dir="ltr">tf.TensorShape</code></a> for more details of what a shape represents.</p> <p>The inferred shape of a tensor is used to provide shape information without having to launch the graph in a session. This can be used for debugging, and providing early error messages. For example:</p> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">c = tf.constant([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]])

print(c.shape)
==&gt; TensorShape([Dimension(2), Dimension(3)])

d = tf.constant([[1.0, 0.0], [0.0, 1.0], [1.0, 0.0], [0.0, 1.0]])

print(d.shape)
==&gt; TensorShape([Dimension(4), Dimension(2)])

# Raises a ValueError, because `c` and `d` do not have compatible
# inner dimensions.
e = tf.matmul(c, d)

f = tf.matmul(c, d, transpose_a=True, transpose_b=True)

print(f.shape)
==&gt; TensorShape([Dimension(3), Dimension(4)])
</pre> <p>In some cases, the inferred shape may have unknown dimensions. If the caller has additional information about the values of these dimensions, <a href="tensor#set_shape"><code translate="no" dir="ltr">Tensor.set_shape()</code></a> can be used to augment the inferred shape. </p>
</td> </tr>
<tr> <td> <code translate="no" dir="ltr">value_index</code> </td> <td> The index of this tensor in the outputs of its <code translate="no" dir="ltr">Operation</code>. </td> </tr> </table> <h2 id="methods" data-text="Methods" tabindex="0">Methods</h2> <h3 id="consumers" data-text="consumers" tabindex="0"><code translate="no" dir="ltr">consumers</code></h3> <p><a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/v1.15.0/tensorflow/python/framework/ops.py#L652-L664">View source</a></p> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
consumers()
</pre> <p>Returns a list of <code translate="no" dir="ltr">Operation</code>s that consume this tensor.</p>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Returns</th></tr> <tr class="alt"> <td colspan="2"> A list of <code translate="no" dir="ltr">Operation</code>s. </td> </tr> 
</table> <h3 id="eval" data-text="eval" tabindex="0"><code translate="no" dir="ltr">eval</code></h3> <p><a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/v1.15.0/tensorflow/python/framework/ops.py#L777-L798">View source</a></p> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
eval(
    feed_dict=None, session=None
)
</pre> <p>Evaluates this tensor in a <code translate="no" dir="ltr">Session</code>.</p> <p>Calling this method will execute all preceding operations that produce the inputs needed for the operation that produces this tensor.</p> <blockquote class="note">
<strong>Note:</strong><span> Before invoking <a href="tensor#eval"><code translate="no" dir="ltr">Tensor.eval()</code></a>, its graph must have been launched in a session, and either a default session must be available, or <code translate="no" dir="ltr">session</code> must be specified explicitly.</span>
</blockquote>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Args</th></tr> 
<tr> <td> <code translate="no" dir="ltr">feed_dict</code> </td> <td> A dictionary that maps <code translate="no" dir="ltr">Tensor</code> objects to feed values. See <a href="session#run"><code translate="no" dir="ltr">tf.Session.run</code></a> for a description of the valid feed values. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">session</code> </td> <td> (Optional.) The <code translate="no" dir="ltr">Session</code> to be used to evaluate this tensor. If none, the default session will be used. </td> </tr> </table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Returns</th></tr> <tr class="alt"> <td colspan="2"> A numpy array corresponding to the value of this tensor. </td> </tr> 
</table> <h3 id="experimental_ref" data-text="experimental_ref" tabindex="0"><code translate="no" dir="ltr">experimental_ref</code></h3> <p><a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/v1.15.0/tensorflow/python/framework/ops.py#L800-L851">View source</a></p> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
experimental_ref()
</pre> <p>Returns a hashable reference object to this Tensor.</p> <aside class="warning"><strong>Warning:</strong><span> Experimental API that could be changed or removed.</span></aside> <p>The primary usecase for this API is to put tensors in a set/dictionary. We can't put tensors in a set/dictionary as <code translate="no" dir="ltr">tensor.__hash__()</code> is no longer available starting Tensorflow 2.0.</p> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">import tensorflow as tf

x = tf.constant(5)
y = tf.constant(10)
z = tf.constant(10)

# The followings will raise an exception starting 2.0
# TypeError: Tensor is unhashable if Tensor equality is enabled.
tensor_set = {x, y, z}
tensor_dict = {x: 'five', y: 'ten', z: 'ten'}
</pre> <p>Instead, we can use <code translate="no" dir="ltr">tensor.experimental_ref()</code>.</p> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">tensor_set = {x.experimental_ref(),
              y.experimental_ref(),
              z.experimental_ref()}

print(x.experimental_ref() in tensor_set)
==&gt; True

tensor_dict = {x.experimental_ref(): 'five',
               y.experimental_ref(): 'ten',
               z.experimental_ref(): 'ten'}

print(tensor_dict[y.experimental_ref()])
==&gt; ten
</pre> <p>Also, the reference object provides <code translate="no" dir="ltr">.deref()</code> function that returns the original Tensor.</p> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">x = tf.constant(5)
print(x.experimental_ref().deref())
==&gt; tf.Tensor(5, shape=(), dtype=int32)
</pre> <h3 id="get_shape" data-text="get_shape" tabindex="0"><code translate="no" dir="ltr">get_shape</code></h3> <p><a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/v1.15.0/tensorflow/python/framework/ops.py#L580-L582">View source</a></p> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
get_shape()
</pre> <p>Alias of Tensor.shape.</p> <h3 id="set_shape" data-text="set_shape" tabindex="0"><code translate="no" dir="ltr">set_shape</code></h3> <p><a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/v1.15.0/tensorflow/python/framework/ops.py#L584-L645">View source</a></p> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
set_shape(
    shape
)
</pre> <p>Updates the shape of this tensor.</p> <p>This method can be called multiple times, and will merge the given <code translate="no" dir="ltr">shape</code> with the current shape of this tensor. It can be used to provide additional information about the shape of this tensor that cannot be inferred from the graph alone. For example, this can be used to provide additional information about the shapes of images:</p> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">_, image_data = tf.compat.v1.TFRecordReader(...).read(...)
image = tf.image.decode_png(image_data, channels=3)

# The height and width dimensions of `image` are data dependent, and
# cannot be computed without executing the op.
print(image.shape)
==&gt; TensorShape([Dimension(None), Dimension(None), Dimension(3)])

# We know that each image in this dataset is 28 x 28 pixels.
image.set_shape([28, 28, 3])
print(image.shape)
==&gt; TensorShape([Dimension(28), Dimension(28), Dimension(3)])
</pre>
<blockquote class="note">
<strong>Note:</strong><span> This shape is not enforced at runtime. Setting incorrect shapes can result in inconsistencies between the statically-known graph and the runtime value of tensors. For runtime validation of the shape, use <a href="ensure_shape"><code translate="no" dir="ltr">tf.ensure_shape</code></a> instead.</span>
</blockquote>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Args</th></tr> 
<tr> <td> <code translate="no" dir="ltr">shape</code> </td> <td> A <code translate="no" dir="ltr">TensorShape</code> representing the shape of this tensor, a <code translate="no" dir="ltr">TensorShapeProto</code>, a list, a tuple, or None. </td> </tr> </table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Raises</th></tr> 
<tr> <td> <code translate="no" dir="ltr">ValueError</code> </td> <td> If <code translate="no" dir="ltr">shape</code> is not compatible with the current shape of this tensor. </td> </tr> </table> <h3 id="__abs__" data-text="__abs__" tabindex="0"><code translate="no" dir="ltr">__abs__</code></h3> <p><a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/v1.15.0/tensorflow/python/ops/math_ops.py#L245-L278">View source</a></p> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
__abs__(
    x, name=None
)
</pre> <p>Computes the absolute value of a tensor.</p> <p>Given a tensor of integer or floating-point values, this operation returns a tensor of the same type, where each element contains the absolute value of the corresponding element in the input.</p> <p>Given a tensor <code translate="no" dir="ltr">x</code> of complex numbers, this operation returns a tensor of type <code translate="no" dir="ltr">float32</code> or <code translate="no" dir="ltr">float64</code> that is the absolute value of each element in <code translate="no" dir="ltr">x</code>. All elements in <code translate="no" dir="ltr">x</code> must be complex numbers of the form \(a + bj\). The absolute value is computed as \( \sqrt{a^2 + b^2}\). For example:</p> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">x = tf.constant([[-2.25 + 4.75j], [-3.25 + 5.75j]])
tf.abs(x)  # [5.25594902, 6.60492229]
</pre>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Args</th></tr> 
<tr> <td> <code translate="no" dir="ltr">x</code> </td> <td> A <code translate="no" dir="ltr">Tensor</code> or <code translate="no" dir="ltr">SparseTensor</code> of type <code translate="no" dir="ltr">float16</code>, <code translate="no" dir="ltr">float32</code>, <code translate="no" dir="ltr">float64</code>, <code translate="no" dir="ltr">int32</code>, <code translate="no" dir="ltr">int64</code>, <code translate="no" dir="ltr">complex64</code> or <code translate="no" dir="ltr">complex128</code>. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">name</code> </td> <td> A name for the operation (optional). </td> </tr> </table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Returns</th></tr> <tr class="alt"> <td colspan="2"> A <code translate="no" dir="ltr">Tensor</code> or <code translate="no" dir="ltr">SparseTensor</code> the same size, type, and sparsity as <code translate="no" dir="ltr">x</code> with absolute values. Note, for <code translate="no" dir="ltr">complex64</code> or <code translate="no" dir="ltr">complex128</code> input, the returned <code translate="no" dir="ltr">Tensor</code> will be of type <code translate="no" dir="ltr">float32</code> or <code translate="no" dir="ltr">float64</code>, respectively. <p>If <code translate="no" dir="ltr">x</code> is a <code translate="no" dir="ltr">SparseTensor</code>, returns <code translate="no" dir="ltr">SparseTensor(x.indices, tf.math.abs(x.values, ...), x.dense_shape)</code> </p>
</td> </tr> 
</table> <h3 id="__add__" data-text="__add__" tabindex="0"><code translate="no" dir="ltr">__add__</code></h3> <p><a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/v1.15.0/tensorflow/python/ops/math_ops.py#L896-L912">View source</a></p> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
__add__(
    x, y
)
</pre> <p>Dispatches to add for strings and add_v2 for all other types.</p> <h3 id="__and__" data-text="__and__" tabindex="0"><code translate="no" dir="ltr">__and__</code></h3> <p><a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/v1.15.0/tensorflow/python/ops/math_ops.py#L896-L912">View source</a></p> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
__and__(
    x, y
)
</pre> <p>Returns the truth value of x AND y element-wise.</p> <blockquote class="note">
<strong>Note:</strong><span> <a href="math/logical_and"><code translate="no" dir="ltr">math.logical_and</code></a> supports broadcasting. More about broadcasting <a href="http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html">here</a></span>
</blockquote>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Args</th></tr> 
<tr> <td> <code translate="no" dir="ltr">x</code> </td> <td> A <code translate="no" dir="ltr">Tensor</code> of type <code translate="no" dir="ltr">bool</code>. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">y</code> </td> <td> A <code translate="no" dir="ltr">Tensor</code> of type <code translate="no" dir="ltr">bool</code>. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">name</code> </td> <td> A name for the operation (optional). </td> </tr> </table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Returns</th></tr> <tr class="alt"> <td colspan="2"> A <code translate="no" dir="ltr">Tensor</code> of type <code translate="no" dir="ltr">bool</code>. </td> </tr> 
</table> <h3 id="__bool__" data-text="__bool__" tabindex="0"><code translate="no" dir="ltr">__bool__</code></h3> <p><a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/v1.15.0/tensorflow/python/framework/ops.py#L747-L765">View source</a></p> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
__bool__()
</pre> <p>Dummy method to prevent a tensor from being used as a Python <code translate="no" dir="ltr">bool</code>.</p> <p>This overload raises a <code translate="no" dir="ltr">TypeError</code> when the user inadvertently treats a <code translate="no" dir="ltr">Tensor</code> as a boolean (most commonly in an <code translate="no" dir="ltr">if</code> or <code translate="no" dir="ltr">while</code> statement), in code that was not converted by AutoGraph. For example:</p> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">if tf.constant(True):  # Will raise.
  # ...

if tf.constant(5) &lt; tf.constant(7):  # Will raise.
  # ...
</pre>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Raises</th></tr> <tr class="alt"> <td colspan="2"> <code translate="no" dir="ltr">TypeError</code>. </td> </tr> 
</table> <h3 id="__div__" data-text="__div__" tabindex="0"><code translate="no" dir="ltr">__div__</code></h3> <p><a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/v1.15.0/tensorflow/python/ops/math_ops.py#L896-L912">View source</a></p> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
__div__(
    x, y
)
</pre> <p>Divide two values using Python 2 semantics.</p> <p>Used for Tensor.<strong>div</strong>.</p>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Args</th></tr> 
<tr> <td> <code translate="no" dir="ltr">x</code> </td> <td> <code translate="no" dir="ltr">Tensor</code> numerator of real numeric type. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">y</code> </td> <td> <code translate="no" dir="ltr">Tensor</code> denominator of real numeric type. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">name</code> </td> <td> A name for the operation (optional). </td> </tr> </table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Returns</th></tr> <tr class="alt"> <td colspan="2"> <code translate="no" dir="ltr">x / y</code> returns the quotient of x and y. </td> </tr> 
</table> <h3 id="__eq__" data-text="__eq__" tabindex="0"><code translate="no" dir="ltr">__eq__</code></h3> <p><a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/v1.15.0/tensorflow/python/ops/math_ops.py#L1328-L1339">View source</a></p> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
__eq__(
    other
)
</pre> <p>Compares two tensors element-wise for equality.</p> <h3 id="__floordiv__" data-text="__floordiv__" tabindex="0"><code translate="no" dir="ltr">__floordiv__</code></h3> <p><a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/v1.15.0/tensorflow/python/ops/math_ops.py#L896-L912">View source</a></p> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
__floordiv__(
    x, y
)
</pre> <p>Divides <code translate="no" dir="ltr">x / y</code> elementwise, rounding toward the most negative integer.</p> <p>The same as <a href="div"><code translate="no" dir="ltr">tf.compat.v1.div(x,y)</code></a> for integers, but uses <code translate="no" dir="ltr">tf.floor(tf.compat.v1.div(x,y))</code> for floating point arguments so that the result is always an integer (though possibly an integer represented as floating point). This op is generated by <code translate="no" dir="ltr">x // y</code> floor division in Python 3 and in Python 2.7 with <code translate="no" dir="ltr">from __future__ import division</code>.</p> <p><code translate="no" dir="ltr">x</code> and <code translate="no" dir="ltr">y</code> must have the same type, and the result will have the same type as well.</p>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Args</th></tr> 
<tr> <td> <code translate="no" dir="ltr">x</code> </td> <td> <code translate="no" dir="ltr">Tensor</code> numerator of real numeric type. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">y</code> </td> <td> <code translate="no" dir="ltr">Tensor</code> denominator of real numeric type. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">name</code> </td> <td> A name for the operation (optional). </td> </tr> </table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Returns</th></tr> <tr class="alt"> <td colspan="2"> <code translate="no" dir="ltr">x / y</code> rounded down. </td> </tr> 
</table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Raises</th></tr> 
<tr> <td> <code translate="no" dir="ltr">TypeError</code> </td> <td> If the inputs are complex. </td> </tr> </table> <h3 id="__ge__" data-text="__ge__" tabindex="0"><code translate="no" dir="ltr">__ge__</code></h3> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
__ge__(
    x, y, name=None
)
</pre> <p>Returns the truth value of (x &gt;= y) element-wise.</p> <blockquote class="note">
<strong>Note:</strong><span> <a href="math/greater_equal"><code translate="no" dir="ltr">math.greater_equal</code></a> supports broadcasting. More about broadcasting <a href="http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html">here</a></span>
</blockquote>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Args</th></tr> 
<tr> <td> <code translate="no" dir="ltr">x</code> </td> <td> A <code translate="no" dir="ltr">Tensor</code>. Must be one of the following types: <code translate="no" dir="ltr">float32</code>, <code translate="no" dir="ltr">float64</code>, <code translate="no" dir="ltr">int32</code>, <code translate="no" dir="ltr">uint8</code>, <code translate="no" dir="ltr">int16</code>, <code translate="no" dir="ltr">int8</code>, <code translate="no" dir="ltr">int64</code>, <code translate="no" dir="ltr">bfloat16</code>, <code translate="no" dir="ltr">uint16</code>, <code translate="no" dir="ltr">half</code>, <code translate="no" dir="ltr">uint32</code>, <code translate="no" dir="ltr">uint64</code>. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">y</code> </td> <td> A <code translate="no" dir="ltr">Tensor</code>. Must have the same type as <code translate="no" dir="ltr">x</code>. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">name</code> </td> <td> A name for the operation (optional). </td> </tr> </table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Returns</th></tr> <tr class="alt"> <td colspan="2"> A <code translate="no" dir="ltr">Tensor</code> of type <code translate="no" dir="ltr">bool</code>. </td> </tr> 
</table> <h3 id="__getitem__" data-text="__getitem__" tabindex="0"><code translate="no" dir="ltr">__getitem__</code></h3> <p><a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/v1.15.0/tensorflow/python/ops/array_ops.py#L658-L802">View source</a></p> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
__getitem__(
    tensor, slice_spec, var=None
)
</pre> <p>Overload for Tensor.<strong>getitem</strong>.</p> <p>This operation extracts the specified region from the tensor. The notation is similar to NumPy with the restriction that currently only support basic indexing. That means that using a non-scalar tensor as input is not currently allowed.</p> <h4 id="some_useful_examples" data-text="Some useful examples:" tabindex="0">Some useful examples:</h4> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python"># Strip leading and trailing 2 elements
foo = tf.constant([1,2,3,4,5,6])
print(foo[2:-2].eval())  # =&gt; [3,4]

# Skip every other row and reverse the order of the columns
foo = tf.constant([[1,2,3], [4,5,6], [7,8,9]])
print(foo[::2,::-1].eval())  # =&gt; [[3,2,1], [9,8,7]]

# Use scalar tensors as indices on both dimensions
print(foo[tf.constant(0), tf.constant(2)].eval())  # =&gt; 3

# Insert another dimension
foo = tf.constant([[1,2,3], [4,5,6], [7,8,9]])
print(foo[tf.newaxis, :, :].eval()) # =&gt; [[[1,2,3], [4,5,6], [7,8,9]]]
print(foo[:, tf.newaxis, :].eval()) # =&gt; [[[1,2,3]], [[4,5,6]], [[7,8,9]]]
print(foo[:, :, tf.newaxis].eval()) # =&gt; [[[1],[2],[3]], [[4],[5],[6]],
[[7],[8],[9]]]

# Ellipses (3 equivalent operations)
foo = tf.constant([[1,2,3], [4,5,6], [7,8,9]])
print(foo[tf.newaxis, :, :].eval())  # =&gt; [[[1,2,3], [4,5,6], [7,8,9]]]
print(foo[tf.newaxis, ...].eval())  # =&gt; [[[1,2,3], [4,5,6], [7,8,9]]]
print(foo[tf.newaxis].eval())  # =&gt; [[[1,2,3], [4,5,6], [7,8,9]]]

# Masks
foo = tf.constant([[1,2,3], [4,5,6], [7,8,9]])
print(foo[foo &gt; 2].eval())  # =&gt; [3, 4, 5, 6, 7, 8, 9]
</pre> <h4 id="notes" data-text="Notes:" tabindex="0">Notes:</h4> <ul> <li>
<a href="../tf#newaxis"><code translate="no" dir="ltr">tf.newaxis</code></a> is <code translate="no" dir="ltr">None</code> as in NumPy.</li> <li>An implicit ellipsis is placed at the end of the <code translate="no" dir="ltr">slice_spec</code>
</li> <li>NumPy advanced indexing is currently not supported.</li> </ul>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Args</th></tr> 
<tr> <td> <code translate="no" dir="ltr">tensor</code> </td> <td> An ops.Tensor object. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">slice_spec</code> </td> <td> The arguments to Tensor.<strong>getitem</strong>. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">var</code> </td> <td> In the case of variable slice assignment, the Variable object to slice (i.e. tensor is the read-only view of this variable). </td> </tr> </table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Returns</th></tr> <tr class="alt"> <td colspan="2"> The appropriate slice of "tensor", based on "slice_spec". </td> </tr> 
</table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Raises</th></tr> 
<tr> <td> <code translate="no" dir="ltr">ValueError</code> </td> <td> If a slice range is negative size. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">TypeError</code> </td> <td> If the slice indices aren't int, slice, ellipsis, tf.newaxis or scalar int32/int64 tensors. </td> </tr> </table> <h3 id="__gt__" data-text="__gt__" tabindex="0"><code translate="no" dir="ltr">__gt__</code></h3> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
__gt__(
    x, y, name=None
)
</pre> <p>Returns the truth value of (x &gt; y) element-wise.</p> <blockquote class="note">
<strong>Note:</strong><span> <a href="math/greater"><code translate="no" dir="ltr">math.greater</code></a> supports broadcasting. More about broadcasting <a href="http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html">here</a></span>
</blockquote>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Args</th></tr> 
<tr> <td> <code translate="no" dir="ltr">x</code> </td> <td> A <code translate="no" dir="ltr">Tensor</code>. Must be one of the following types: <code translate="no" dir="ltr">float32</code>, <code translate="no" dir="ltr">float64</code>, <code translate="no" dir="ltr">int32</code>, <code translate="no" dir="ltr">uint8</code>, <code translate="no" dir="ltr">int16</code>, <code translate="no" dir="ltr">int8</code>, <code translate="no" dir="ltr">int64</code>, <code translate="no" dir="ltr">bfloat16</code>, <code translate="no" dir="ltr">uint16</code>, <code translate="no" dir="ltr">half</code>, <code translate="no" dir="ltr">uint32</code>, <code translate="no" dir="ltr">uint64</code>. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">y</code> </td> <td> A <code translate="no" dir="ltr">Tensor</code>. Must have the same type as <code translate="no" dir="ltr">x</code>. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">name</code> </td> <td> A name for the operation (optional). </td> </tr> </table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Returns</th></tr> <tr class="alt"> <td colspan="2"> A <code translate="no" dir="ltr">Tensor</code> of type <code translate="no" dir="ltr">bool</code>. </td> </tr> 
</table> <h3 id="__invert__" data-text="__invert__" tabindex="0"><code translate="no" dir="ltr">__invert__</code></h3> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
__invert__(
    x, name=None
)
</pre> <p>Returns the truth value of NOT x element-wise.</p>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Args</th></tr> 
<tr> <td> <code translate="no" dir="ltr">x</code> </td> <td> A <code translate="no" dir="ltr">Tensor</code> of type <code translate="no" dir="ltr">bool</code>. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">name</code> </td> <td> A name for the operation (optional). </td> </tr> </table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Returns</th></tr> <tr class="alt"> <td colspan="2"> A <code translate="no" dir="ltr">Tensor</code> of type <code translate="no" dir="ltr">bool</code>. </td> </tr> 
</table> <h3 id="__iter__" data-text="__iter__" tabindex="0"><code translate="no" dir="ltr">__iter__</code></h3> <p><a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/v1.15.0/tensorflow/python/framework/ops.py#L545-L558">View source</a></p> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
__iter__()
</pre> <h3 id="__le__" data-text="__le__" tabindex="0"><code translate="no" dir="ltr">__le__</code></h3> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
__le__(
    x, y, name=None
)
</pre> <p>Returns the truth value of (x &lt;= y) element-wise.</p> <blockquote class="note">
<strong>Note:</strong><span> <a href="math/less_equal"><code translate="no" dir="ltr">math.less_equal</code></a> supports broadcasting. More about broadcasting <a href="http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html">here</a></span>
</blockquote>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Args</th></tr> 
<tr> <td> <code translate="no" dir="ltr">x</code> </td> <td> A <code translate="no" dir="ltr">Tensor</code>. Must be one of the following types: <code translate="no" dir="ltr">float32</code>, <code translate="no" dir="ltr">float64</code>, <code translate="no" dir="ltr">int32</code>, <code translate="no" dir="ltr">uint8</code>, <code translate="no" dir="ltr">int16</code>, <code translate="no" dir="ltr">int8</code>, <code translate="no" dir="ltr">int64</code>, <code translate="no" dir="ltr">bfloat16</code>, <code translate="no" dir="ltr">uint16</code>, <code translate="no" dir="ltr">half</code>, <code translate="no" dir="ltr">uint32</code>, <code translate="no" dir="ltr">uint64</code>. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">y</code> </td> <td> A <code translate="no" dir="ltr">Tensor</code>. Must have the same type as <code translate="no" dir="ltr">x</code>. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">name</code> </td> <td> A name for the operation (optional). </td> </tr> </table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Returns</th></tr> <tr class="alt"> <td colspan="2"> A <code translate="no" dir="ltr">Tensor</code> of type <code translate="no" dir="ltr">bool</code>. </td> </tr> 
</table> <h3 id="__len__" data-text="__len__" tabindex="0"><code translate="no" dir="ltr">__len__</code></h3> <p><a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/v1.15.0/tensorflow/python/framework/ops.py#L738-L741">View source</a></p> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
__len__()
</pre> <h3 id="__lt__" data-text="__lt__" tabindex="0"><code translate="no" dir="ltr">__lt__</code></h3> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
__lt__(
    x, y, name=None
)
</pre> <p>Returns the truth value of (x &lt; y) element-wise.</p> <blockquote class="note">
<strong>Note:</strong><span> <a href="math/less"><code translate="no" dir="ltr">math.less</code></a> supports broadcasting. More about broadcasting <a href="http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html">here</a></span>
</blockquote>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Args</th></tr> 
<tr> <td> <code translate="no" dir="ltr">x</code> </td> <td> A <code translate="no" dir="ltr">Tensor</code>. Must be one of the following types: <code translate="no" dir="ltr">float32</code>, <code translate="no" dir="ltr">float64</code>, <code translate="no" dir="ltr">int32</code>, <code translate="no" dir="ltr">uint8</code>, <code translate="no" dir="ltr">int16</code>, <code translate="no" dir="ltr">int8</code>, <code translate="no" dir="ltr">int64</code>, <code translate="no" dir="ltr">bfloat16</code>, <code translate="no" dir="ltr">uint16</code>, <code translate="no" dir="ltr">half</code>, <code translate="no" dir="ltr">uint32</code>, <code translate="no" dir="ltr">uint64</code>. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">y</code> </td> <td> A <code translate="no" dir="ltr">Tensor</code>. Must have the same type as <code translate="no" dir="ltr">x</code>. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">name</code> </td> <td> A name for the operation (optional). </td> </tr> </table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Returns</th></tr> <tr class="alt"> <td colspan="2"> A <code translate="no" dir="ltr">Tensor</code> of type <code translate="no" dir="ltr">bool</code>. </td> </tr> 
</table> <h3 id="__matmul__" data-text="__matmul__" tabindex="0"><code translate="no" dir="ltr">__matmul__</code></h3> <p><a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/v1.15.0/tensorflow/python/ops/math_ops.py#L896-L912">View source</a></p> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
__matmul__(
    x, y
)
</pre> <p>Multiplies matrix <code translate="no" dir="ltr">a</code> by matrix <code translate="no" dir="ltr">b</code>, producing <code translate="no" dir="ltr">a</code> * <code translate="no" dir="ltr">b</code>.</p> <p>The inputs must, following any transpositions, be tensors of rank &gt;= 2 where the inner 2 dimensions specify valid matrix multiplication arguments, and any further outer dimensions match.</p> <p>Both matrices must be of the same type. The supported types are: <code translate="no" dir="ltr">float16</code>, <code translate="no" dir="ltr">float32</code>, <code translate="no" dir="ltr">float64</code>, <code translate="no" dir="ltr">int32</code>, <code translate="no" dir="ltr">complex64</code>, <code translate="no" dir="ltr">complex128</code>.</p> <p>Either matrix can be transposed or adjointed (conjugated and transposed) on the fly by setting one of the corresponding flag to <code translate="no" dir="ltr">True</code>. These are <code translate="no" dir="ltr">False</code> by default.</p> <p>If one or both of the matrices contain a lot of zeros, a more efficient multiplication algorithm can be used by setting the corresponding <code translate="no" dir="ltr">a_is_sparse</code> or <code translate="no" dir="ltr">b_is_sparse</code> flag to <code translate="no" dir="ltr">True</code>. These are <code translate="no" dir="ltr">False</code> by default. This optimization is only available for plain matrices (rank-2 tensors) with datatypes <code translate="no" dir="ltr">bfloat16</code> or <code translate="no" dir="ltr">float32</code>.</p> <h4 id="for_example" data-text="For example:" tabindex="0">For example:</h4> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python"># 2-D tensor `a`
# [[1, 2, 3],
#  [4, 5, 6]]
a = tf.constant([1, 2, 3, 4, 5, 6], shape=[2, 3])

# 2-D tensor `b`
# [[ 7,  8],
#  [ 9, 10],
#  [11, 12]]
b = tf.constant([7, 8, 9, 10, 11, 12], shape=[3, 2])

# `a` * `b`
# [[ 58,  64],
#  [139, 154]]
c = tf.matmul(a, b)


# 3-D tensor `a`
# [[[ 1,  2,  3],
#   [ 4,  5,  6]],
#  [[ 7,  8,  9],
#   [10, 11, 12]]]
a = tf.constant(np.arange(1, 13, dtype=np.int32),
                shape=[2, 2, 3])

# 3-D tensor `b`
# [[[13, 14],
#   [15, 16],
#   [17, 18]],
#  [[19, 20],
#   [21, 22],
#   [23, 24]]]
b = tf.constant(np.arange(13, 25, dtype=np.int32),
                shape=[2, 3, 2])

# `a` * `b`
# [[[ 94, 100],
#   [229, 244]],
#  [[508, 532],
#   [697, 730]]]
c = tf.matmul(a, b)

# Since python &gt;= 3.5 the @ operator is supported (see PEP 465).
# In TensorFlow, it simply calls the `tf.matmul()` function, so the
# following lines are equivalent:
d = a @ b @ [[10.], [11.]]
d = tf.matmul(tf.matmul(a, b), [[10.], [11.]])
</pre>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Args</th></tr> 
<tr> <td> <code translate="no" dir="ltr">a</code> </td> <td> <code translate="no" dir="ltr">Tensor</code> of type <code translate="no" dir="ltr">float16</code>, <code translate="no" dir="ltr">float32</code>, <code translate="no" dir="ltr">float64</code>, <code translate="no" dir="ltr">int32</code>, <code translate="no" dir="ltr">complex64</code>, <code translate="no" dir="ltr">complex128</code> and rank &gt; 1. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">b</code> </td> <td> <code translate="no" dir="ltr">Tensor</code> with same type and rank as <code translate="no" dir="ltr">a</code>. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">transpose_a</code> </td> <td> If <code translate="no" dir="ltr">True</code>, <code translate="no" dir="ltr">a</code> is transposed before multiplication. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">transpose_b</code> </td> <td> If <code translate="no" dir="ltr">True</code>, <code translate="no" dir="ltr">b</code> is transposed before multiplication. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">adjoint_a</code> </td> <td> If <code translate="no" dir="ltr">True</code>, <code translate="no" dir="ltr">a</code> is conjugated and transposed before multiplication. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">adjoint_b</code> </td> <td> If <code translate="no" dir="ltr">True</code>, <code translate="no" dir="ltr">b</code> is conjugated and transposed before multiplication. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">a_is_sparse</code> </td> <td> If <code translate="no" dir="ltr">True</code>, <code translate="no" dir="ltr">a</code> is treated as a sparse matrix. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">b_is_sparse</code> </td> <td> If <code translate="no" dir="ltr">True</code>, <code translate="no" dir="ltr">b</code> is treated as a sparse matrix. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">name</code> </td> <td> Name for the operation (optional). </td> </tr> </table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Returns</th></tr> <tr class="alt"> <td colspan="2"> A <code translate="no" dir="ltr">Tensor</code> of the same type as <code translate="no" dir="ltr">a</code> and <code translate="no" dir="ltr">b</code> where each inner-most matrix is the product of the corresponding matrices in <code translate="no" dir="ltr">a</code> and <code translate="no" dir="ltr">b</code>, e.g. if all transpose or adjoint attributes are <code translate="no" dir="ltr">False</code>: <p><code translate="no" dir="ltr">output</code>[..., i, j] = sum_k (<code translate="no" dir="ltr">a</code>[..., i, k] * <code translate="no" dir="ltr">b</code>[..., k, j]), for all indices i, j. </p>
</td> </tr> <tr> <td> <code translate="no" dir="ltr">Note</code> </td> <td> This is matrix product, not element-wise product. </td> </tr> </table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Raises</th></tr> 
<tr> <td> <code translate="no" dir="ltr">ValueError</code> </td> <td> If transpose_a and adjoint_a, or transpose_b and adjoint_b are both set to True. </td> </tr> </table> <h3 id="__mod__" data-text="__mod__" tabindex="0"><code translate="no" dir="ltr">__mod__</code></h3> <p><a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/v1.15.0/tensorflow/python/ops/math_ops.py#L896-L912">View source</a></p> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
__mod__(
    x, y
)
</pre> <p>Returns element-wise remainder of division. When <code translate="no" dir="ltr">x &lt; 0</code> xor <code translate="no" dir="ltr">y &lt; 0</code> is</p> <p>true, this follows Python semantics in that the result here is consistent with a flooring divide. E.g. <code translate="no" dir="ltr">floor(x / y) * y + mod(x, y) = x</code>.</p> <blockquote class="note">
<strong>Note:</strong><span> <a href="math/floormod"><code translate="no" dir="ltr">math.floormod</code></a> supports broadcasting. More about broadcasting <a href="http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html">here</a></span>
</blockquote>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Args</th></tr> 
<tr> <td> <code translate="no" dir="ltr">x</code> </td> <td> A <code translate="no" dir="ltr">Tensor</code>. Must be one of the following types: <code translate="no" dir="ltr">int32</code>, <code translate="no" dir="ltr">int64</code>, <code translate="no" dir="ltr">bfloat16</code>, <code translate="no" dir="ltr">half</code>, <code translate="no" dir="ltr">float32</code>, <code translate="no" dir="ltr">float64</code>. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">y</code> </td> <td> A <code translate="no" dir="ltr">Tensor</code>. Must have the same type as <code translate="no" dir="ltr">x</code>. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">name</code> </td> <td> A name for the operation (optional). </td> </tr> </table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Returns</th></tr> <tr class="alt"> <td colspan="2"> A <code translate="no" dir="ltr">Tensor</code>. Has the same type as <code translate="no" dir="ltr">x</code>. </td> </tr> 
</table> <h3 id="__mul__" data-text="__mul__" tabindex="0"><code translate="no" dir="ltr">__mul__</code></h3> <p><a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/v1.15.0/tensorflow/python/ops/math_ops.py#L896-L912">View source</a></p> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
__mul__(
    x, y
)
</pre> <p>Dispatches cwise mul for "Dense<em>Dense" and "Dense</em>Sparse".</p> <h3 id="__ne__" data-text="__ne__" tabindex="0"><code translate="no" dir="ltr">__ne__</code></h3> <p><a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/v1.15.0/tensorflow/python/ops/math_ops.py#L1342-L1351">View source</a></p> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
__ne__(
    other
)
</pre> <p>Compares two tensors element-wise for equality.</p> <h3 id="__neg__" data-text="__neg__" tabindex="0"><code translate="no" dir="ltr">__neg__</code></h3> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
__neg__(
    x, name=None
)
</pre> <p>Computes numerical negative value element-wise.</p> <p>I.e., \(y = -x\).</p>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Args</th></tr> 
<tr> <td> <code translate="no" dir="ltr">x</code> </td> <td> A <code translate="no" dir="ltr">Tensor</code>. Must be one of the following types: <code translate="no" dir="ltr">bfloat16</code>, <code translate="no" dir="ltr">half</code>, <code translate="no" dir="ltr">float32</code>, <code translate="no" dir="ltr">float64</code>, <code translate="no" dir="ltr">int32</code>, <code translate="no" dir="ltr">int64</code>, <code translate="no" dir="ltr">complex64</code>, <code translate="no" dir="ltr">complex128</code>. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">name</code> </td> <td> A name for the operation (optional). </td> </tr> </table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Returns</th></tr> <tr class="alt"> <td colspan="2"> A <code translate="no" dir="ltr">Tensor</code>. Has the same type as <code translate="no" dir="ltr">x</code>. <p>If <code translate="no" dir="ltr">x</code> is a <code translate="no" dir="ltr">SparseTensor</code>, returns <code translate="no" dir="ltr">SparseTensor(x.indices, tf.math.negative(x.values, ...), x.dense_shape)</code> </p>
</td> </tr> 
</table> <h3 id="__nonzero__" data-text="__nonzero__" tabindex="0"><code translate="no" dir="ltr">__nonzero__</code></h3> <p><a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/v1.15.0/tensorflow/python/framework/ops.py#L767-L775">View source</a></p> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
__nonzero__()
</pre> <p>Dummy method to prevent a tensor from being used as a Python <code translate="no" dir="ltr">bool</code>.</p> <p>This is the Python 2.x counterpart to <code translate="no" dir="ltr">__bool__()</code> above.</p>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Raises</th></tr> <tr class="alt"> <td colspan="2"> <code translate="no" dir="ltr">TypeError</code>. </td> </tr> 
</table> <h3 id="__or__" data-text="__or__" tabindex="0"><code translate="no" dir="ltr">__or__</code></h3> <p><a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/v1.15.0/tensorflow/python/ops/math_ops.py#L896-L912">View source</a></p> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
__or__(
    x, y
)
</pre> <p>Returns the truth value of x OR y element-wise.</p> <blockquote class="note">
<strong>Note:</strong><span> <a href="math/logical_or"><code translate="no" dir="ltr">math.logical_or</code></a> supports broadcasting. More about broadcasting <a href="http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html">here</a></span>
</blockquote>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Args</th></tr> 
<tr> <td> <code translate="no" dir="ltr">x</code> </td> <td> A <code translate="no" dir="ltr">Tensor</code> of type <code translate="no" dir="ltr">bool</code>. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">y</code> </td> <td> A <code translate="no" dir="ltr">Tensor</code> of type <code translate="no" dir="ltr">bool</code>. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">name</code> </td> <td> A name for the operation (optional). </td> </tr> </table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Returns</th></tr> <tr class="alt"> <td colspan="2"> A <code translate="no" dir="ltr">Tensor</code> of type <code translate="no" dir="ltr">bool</code>. </td> </tr> 
</table> <h3 id="__pow__" data-text="__pow__" tabindex="0"><code translate="no" dir="ltr">__pow__</code></h3> <p><a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/v1.15.0/tensorflow/python/ops/math_ops.py#L896-L912">View source</a></p> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
__pow__(
    x, y
)
</pre> <p>Computes the power of one value to another.</p> <p>Given a tensor <code translate="no" dir="ltr">x</code> and a tensor <code translate="no" dir="ltr">y</code>, this operation computes \(x^y\) for corresponding elements in <code translate="no" dir="ltr">x</code> and <code translate="no" dir="ltr">y</code>. For example:</p> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">x = tf.constant([[2, 2], [3, 3]])
y = tf.constant([[8, 16], [2, 3]])
tf.pow(x, y)  # [[256, 65536], [9, 27]]
</pre>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Args</th></tr> 
<tr> <td> <code translate="no" dir="ltr">x</code> </td> <td> A <code translate="no" dir="ltr">Tensor</code> of type <code translate="no" dir="ltr">float16</code>, <code translate="no" dir="ltr">float32</code>, <code translate="no" dir="ltr">float64</code>, <code translate="no" dir="ltr">int32</code>, <code translate="no" dir="ltr">int64</code>, <code translate="no" dir="ltr">complex64</code>, or <code translate="no" dir="ltr">complex128</code>. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">y</code> </td> <td> A <code translate="no" dir="ltr">Tensor</code> of type <code translate="no" dir="ltr">float16</code>, <code translate="no" dir="ltr">float32</code>, <code translate="no" dir="ltr">float64</code>, <code translate="no" dir="ltr">int32</code>, <code translate="no" dir="ltr">int64</code>, <code translate="no" dir="ltr">complex64</code>, or <code translate="no" dir="ltr">complex128</code>. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">name</code> </td> <td> A name for the operation (optional). </td> </tr> </table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Returns</th></tr> <tr class="alt"> <td colspan="2"> A <code translate="no" dir="ltr">Tensor</code>. </td> </tr> 
</table> <h3 id="__radd__" data-text="__radd__" tabindex="0"><code translate="no" dir="ltr">__radd__</code></h3> <p><a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/v1.15.0/tensorflow/python/ops/math_ops.py#L922-L925">View source</a></p> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
__radd__(
    y, x
)
</pre> <p>Dispatches to add for strings and add_v2 for all other types.</p> <h3 id="__rand__" data-text="__rand__" tabindex="0"><code translate="no" dir="ltr">__rand__</code></h3> <p><a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/v1.15.0/tensorflow/python/ops/math_ops.py#L922-L925">View source</a></p> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
__rand__(
    y, x
)
</pre> <p>Returns the truth value of x AND y element-wise.</p> <blockquote class="note">
<strong>Note:</strong><span> <a href="math/logical_and"><code translate="no" dir="ltr">math.logical_and</code></a> supports broadcasting. More about broadcasting <a href="http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html">here</a></span>
</blockquote>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Args</th></tr> 
<tr> <td> <code translate="no" dir="ltr">x</code> </td> <td> A <code translate="no" dir="ltr">Tensor</code> of type <code translate="no" dir="ltr">bool</code>. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">y</code> </td> <td> A <code translate="no" dir="ltr">Tensor</code> of type <code translate="no" dir="ltr">bool</code>. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">name</code> </td> <td> A name for the operation (optional). </td> </tr> </table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Returns</th></tr> <tr class="alt"> <td colspan="2"> A <code translate="no" dir="ltr">Tensor</code> of type <code translate="no" dir="ltr">bool</code>. </td> </tr> 
</table> <h3 id="__rdiv__" data-text="__rdiv__" tabindex="0"><code translate="no" dir="ltr">__rdiv__</code></h3> <p><a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/v1.15.0/tensorflow/python/ops/math_ops.py#L922-L925">View source</a></p> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
__rdiv__(
    y, x
)
</pre> <p>Divide two values using Python 2 semantics.</p> <p>Used for Tensor.<strong>div</strong>.</p>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Args</th></tr> 
<tr> <td> <code translate="no" dir="ltr">x</code> </td> <td> <code translate="no" dir="ltr">Tensor</code> numerator of real numeric type. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">y</code> </td> <td> <code translate="no" dir="ltr">Tensor</code> denominator of real numeric type. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">name</code> </td> <td> A name for the operation (optional). </td> </tr> </table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Returns</th></tr> <tr class="alt"> <td colspan="2"> <code translate="no" dir="ltr">x / y</code> returns the quotient of x and y. </td> </tr> 
</table> <h3 id="__rfloordiv__" data-text="__rfloordiv__" tabindex="0"><code translate="no" dir="ltr">__rfloordiv__</code></h3> <p><a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/v1.15.0/tensorflow/python/ops/math_ops.py#L922-L925">View source</a></p> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
__rfloordiv__(
    y, x
)
</pre> <p>Divides <code translate="no" dir="ltr">x / y</code> elementwise, rounding toward the most negative integer.</p> <p>The same as <a href="div"><code translate="no" dir="ltr">tf.compat.v1.div(x,y)</code></a> for integers, but uses <code translate="no" dir="ltr">tf.floor(tf.compat.v1.div(x,y))</code> for floating point arguments so that the result is always an integer (though possibly an integer represented as floating point). This op is generated by <code translate="no" dir="ltr">x // y</code> floor division in Python 3 and in Python 2.7 with <code translate="no" dir="ltr">from __future__ import division</code>.</p> <p><code translate="no" dir="ltr">x</code> and <code translate="no" dir="ltr">y</code> must have the same type, and the result will have the same type as well.</p>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Args</th></tr> 
<tr> <td> <code translate="no" dir="ltr">x</code> </td> <td> <code translate="no" dir="ltr">Tensor</code> numerator of real numeric type. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">y</code> </td> <td> <code translate="no" dir="ltr">Tensor</code> denominator of real numeric type. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">name</code> </td> <td> A name for the operation (optional). </td> </tr> </table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Returns</th></tr> <tr class="alt"> <td colspan="2"> <code translate="no" dir="ltr">x / y</code> rounded down. </td> </tr> 
</table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Raises</th></tr> 
<tr> <td> <code translate="no" dir="ltr">TypeError</code> </td> <td> If the inputs are complex. </td> </tr> </table> <h3 id="__rmatmul__" data-text="__rmatmul__" tabindex="0"><code translate="no" dir="ltr">__rmatmul__</code></h3> <p><a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/v1.15.0/tensorflow/python/ops/math_ops.py#L922-L925">View source</a></p> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
__rmatmul__(
    y, x
)
</pre> <p>Multiplies matrix <code translate="no" dir="ltr">a</code> by matrix <code translate="no" dir="ltr">b</code>, producing <code translate="no" dir="ltr">a</code> * <code translate="no" dir="ltr">b</code>.</p> <p>The inputs must, following any transpositions, be tensors of rank &gt;= 2 where the inner 2 dimensions specify valid matrix multiplication arguments, and any further outer dimensions match.</p> <p>Both matrices must be of the same type. The supported types are: <code translate="no" dir="ltr">float16</code>, <code translate="no" dir="ltr">float32</code>, <code translate="no" dir="ltr">float64</code>, <code translate="no" dir="ltr">int32</code>, <code translate="no" dir="ltr">complex64</code>, <code translate="no" dir="ltr">complex128</code>.</p> <p>Either matrix can be transposed or adjointed (conjugated and transposed) on the fly by setting one of the corresponding flag to <code translate="no" dir="ltr">True</code>. These are <code translate="no" dir="ltr">False</code> by default.</p> <p>If one or both of the matrices contain a lot of zeros, a more efficient multiplication algorithm can be used by setting the corresponding <code translate="no" dir="ltr">a_is_sparse</code> or <code translate="no" dir="ltr">b_is_sparse</code> flag to <code translate="no" dir="ltr">True</code>. These are <code translate="no" dir="ltr">False</code> by default. This optimization is only available for plain matrices (rank-2 tensors) with datatypes <code translate="no" dir="ltr">bfloat16</code> or <code translate="no" dir="ltr">float32</code>.</p> <h4 id="for_example_2" data-text="For example:" tabindex="0">For example:</h4> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python"># 2-D tensor `a`
# [[1, 2, 3],
#  [4, 5, 6]]
a = tf.constant([1, 2, 3, 4, 5, 6], shape=[2, 3])

# 2-D tensor `b`
# [[ 7,  8],
#  [ 9, 10],
#  [11, 12]]
b = tf.constant([7, 8, 9, 10, 11, 12], shape=[3, 2])

# `a` * `b`
# [[ 58,  64],
#  [139, 154]]
c = tf.matmul(a, b)


# 3-D tensor `a`
# [[[ 1,  2,  3],
#   [ 4,  5,  6]],
#  [[ 7,  8,  9],
#   [10, 11, 12]]]
a = tf.constant(np.arange(1, 13, dtype=np.int32),
                shape=[2, 2, 3])

# 3-D tensor `b`
# [[[13, 14],
#   [15, 16],
#   [17, 18]],
#  [[19, 20],
#   [21, 22],
#   [23, 24]]]
b = tf.constant(np.arange(13, 25, dtype=np.int32),
                shape=[2, 3, 2])

# `a` * `b`
# [[[ 94, 100],
#   [229, 244]],
#  [[508, 532],
#   [697, 730]]]
c = tf.matmul(a, b)

# Since python &gt;= 3.5 the @ operator is supported (see PEP 465).
# In TensorFlow, it simply calls the `tf.matmul()` function, so the
# following lines are equivalent:
d = a @ b @ [[10.], [11.]]
d = tf.matmul(tf.matmul(a, b), [[10.], [11.]])
</pre>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Args</th></tr> 
<tr> <td> <code translate="no" dir="ltr">a</code> </td> <td> <code translate="no" dir="ltr">Tensor</code> of type <code translate="no" dir="ltr">float16</code>, <code translate="no" dir="ltr">float32</code>, <code translate="no" dir="ltr">float64</code>, <code translate="no" dir="ltr">int32</code>, <code translate="no" dir="ltr">complex64</code>, <code translate="no" dir="ltr">complex128</code> and rank &gt; 1. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">b</code> </td> <td> <code translate="no" dir="ltr">Tensor</code> with same type and rank as <code translate="no" dir="ltr">a</code>. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">transpose_a</code> </td> <td> If <code translate="no" dir="ltr">True</code>, <code translate="no" dir="ltr">a</code> is transposed before multiplication. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">transpose_b</code> </td> <td> If <code translate="no" dir="ltr">True</code>, <code translate="no" dir="ltr">b</code> is transposed before multiplication. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">adjoint_a</code> </td> <td> If <code translate="no" dir="ltr">True</code>, <code translate="no" dir="ltr">a</code> is conjugated and transposed before multiplication. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">adjoint_b</code> </td> <td> If <code translate="no" dir="ltr">True</code>, <code translate="no" dir="ltr">b</code> is conjugated and transposed before multiplication. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">a_is_sparse</code> </td> <td> If <code translate="no" dir="ltr">True</code>, <code translate="no" dir="ltr">a</code> is treated as a sparse matrix. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">b_is_sparse</code> </td> <td> If <code translate="no" dir="ltr">True</code>, <code translate="no" dir="ltr">b</code> is treated as a sparse matrix. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">name</code> </td> <td> Name for the operation (optional). </td> </tr> </table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Returns</th></tr> <tr class="alt"> <td colspan="2"> A <code translate="no" dir="ltr">Tensor</code> of the same type as <code translate="no" dir="ltr">a</code> and <code translate="no" dir="ltr">b</code> where each inner-most matrix is the product of the corresponding matrices in <code translate="no" dir="ltr">a</code> and <code translate="no" dir="ltr">b</code>, e.g. if all transpose or adjoint attributes are <code translate="no" dir="ltr">False</code>: <p><code translate="no" dir="ltr">output</code>[..., i, j] = sum_k (<code translate="no" dir="ltr">a</code>[..., i, k] * <code translate="no" dir="ltr">b</code>[..., k, j]), for all indices i, j. </p>
</td> </tr> <tr> <td> <code translate="no" dir="ltr">Note</code> </td> <td> This is matrix product, not element-wise product. </td> </tr> </table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Raises</th></tr> 
<tr> <td> <code translate="no" dir="ltr">ValueError</code> </td> <td> If transpose_a and adjoint_a, or transpose_b and adjoint_b are both set to True. </td> </tr> </table> <h3 id="__rmod__" data-text="__rmod__" tabindex="0"><code translate="no" dir="ltr">__rmod__</code></h3> <p><a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/v1.15.0/tensorflow/python/ops/math_ops.py#L922-L925">View source</a></p> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
__rmod__(
    y, x
)
</pre> <p>Returns element-wise remainder of division. When <code translate="no" dir="ltr">x &lt; 0</code> xor <code translate="no" dir="ltr">y &lt; 0</code> is</p> <p>true, this follows Python semantics in that the result here is consistent with a flooring divide. E.g. <code translate="no" dir="ltr">floor(x / y) * y + mod(x, y) = x</code>.</p> <blockquote class="note">
<strong>Note:</strong><span> <a href="math/floormod"><code translate="no" dir="ltr">math.floormod</code></a> supports broadcasting. More about broadcasting <a href="http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html">here</a></span>
</blockquote>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Args</th></tr> 
<tr> <td> <code translate="no" dir="ltr">x</code> </td> <td> A <code translate="no" dir="ltr">Tensor</code>. Must be one of the following types: <code translate="no" dir="ltr">int32</code>, <code translate="no" dir="ltr">int64</code>, <code translate="no" dir="ltr">bfloat16</code>, <code translate="no" dir="ltr">half</code>, <code translate="no" dir="ltr">float32</code>, <code translate="no" dir="ltr">float64</code>. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">y</code> </td> <td> A <code translate="no" dir="ltr">Tensor</code>. Must have the same type as <code translate="no" dir="ltr">x</code>. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">name</code> </td> <td> A name for the operation (optional). </td> </tr> </table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Returns</th></tr> <tr class="alt"> <td colspan="2"> A <code translate="no" dir="ltr">Tensor</code>. Has the same type as <code translate="no" dir="ltr">x</code>. </td> </tr> 
</table> <h3 id="__rmul__" data-text="__rmul__" tabindex="0"><code translate="no" dir="ltr">__rmul__</code></h3> <p><a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/v1.15.0/tensorflow/python/ops/math_ops.py#L922-L925">View source</a></p> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
__rmul__(
    y, x
)
</pre> <p>Dispatches cwise mul for "Dense<em>Dense" and "Dense</em>Sparse".</p> <h3 id="__ror__" data-text="__ror__" tabindex="0"><code translate="no" dir="ltr">__ror__</code></h3> <p><a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/v1.15.0/tensorflow/python/ops/math_ops.py#L922-L925">View source</a></p> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
__ror__(
    y, x
)
</pre> <p>Returns the truth value of x OR y element-wise.</p> <blockquote class="note">
<strong>Note:</strong><span> <a href="math/logical_or"><code translate="no" dir="ltr">math.logical_or</code></a> supports broadcasting. More about broadcasting <a href="http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html">here</a></span>
</blockquote>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Args</th></tr> 
<tr> <td> <code translate="no" dir="ltr">x</code> </td> <td> A <code translate="no" dir="ltr">Tensor</code> of type <code translate="no" dir="ltr">bool</code>. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">y</code> </td> <td> A <code translate="no" dir="ltr">Tensor</code> of type <code translate="no" dir="ltr">bool</code>. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">name</code> </td> <td> A name for the operation (optional). </td> </tr> </table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Returns</th></tr> <tr class="alt"> <td colspan="2"> A <code translate="no" dir="ltr">Tensor</code> of type <code translate="no" dir="ltr">bool</code>. </td> </tr> 
</table> <h3 id="__rpow__" data-text="__rpow__" tabindex="0"><code translate="no" dir="ltr">__rpow__</code></h3> <p><a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/v1.15.0/tensorflow/python/ops/math_ops.py#L922-L925">View source</a></p> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
__rpow__(
    y, x
)
</pre> <p>Computes the power of one value to another.</p> <p>Given a tensor <code translate="no" dir="ltr">x</code> and a tensor <code translate="no" dir="ltr">y</code>, this operation computes \(x^y\) for corresponding elements in <code translate="no" dir="ltr">x</code> and <code translate="no" dir="ltr">y</code>. For example:</p> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">x = tf.constant([[2, 2], [3, 3]])
y = tf.constant([[8, 16], [2, 3]])
tf.pow(x, y)  # [[256, 65536], [9, 27]]
</pre>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Args</th></tr> 
<tr> <td> <code translate="no" dir="ltr">x</code> </td> <td> A <code translate="no" dir="ltr">Tensor</code> of type <code translate="no" dir="ltr">float16</code>, <code translate="no" dir="ltr">float32</code>, <code translate="no" dir="ltr">float64</code>, <code translate="no" dir="ltr">int32</code>, <code translate="no" dir="ltr">int64</code>, <code translate="no" dir="ltr">complex64</code>, or <code translate="no" dir="ltr">complex128</code>. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">y</code> </td> <td> A <code translate="no" dir="ltr">Tensor</code> of type <code translate="no" dir="ltr">float16</code>, <code translate="no" dir="ltr">float32</code>, <code translate="no" dir="ltr">float64</code>, <code translate="no" dir="ltr">int32</code>, <code translate="no" dir="ltr">int64</code>, <code translate="no" dir="ltr">complex64</code>, or <code translate="no" dir="ltr">complex128</code>. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">name</code> </td> <td> A name for the operation (optional). </td> </tr> </table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Returns</th></tr> <tr class="alt"> <td colspan="2"> A <code translate="no" dir="ltr">Tensor</code>. </td> </tr> 
</table> <h3 id="__rsub__" data-text="__rsub__" tabindex="0"><code translate="no" dir="ltr">__rsub__</code></h3> <p><a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/v1.15.0/tensorflow/python/ops/math_ops.py#L922-L925">View source</a></p> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
__rsub__(
    y, x
)
</pre> <p>Returns x - y element-wise.</p> <blockquote class="note">
<strong>Note:</strong><span> <code translate="no" dir="ltr">Subtract</code> supports broadcasting. More about broadcasting <a href="http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html">here</a></span>
</blockquote>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Args</th></tr> 
<tr> <td> <code translate="no" dir="ltr">x</code> </td> <td> A <code translate="no" dir="ltr">Tensor</code>. Must be one of the following types: <code translate="no" dir="ltr">bfloat16</code>, <code translate="no" dir="ltr">half</code>, <code translate="no" dir="ltr">float32</code>, <code translate="no" dir="ltr">float64</code>, <code translate="no" dir="ltr">uint8</code>, <code translate="no" dir="ltr">int8</code>, <code translate="no" dir="ltr">uint16</code>, <code translate="no" dir="ltr">int16</code>, <code translate="no" dir="ltr">int32</code>, <code translate="no" dir="ltr">int64</code>, <code translate="no" dir="ltr">complex64</code>, <code translate="no" dir="ltr">complex128</code>. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">y</code> </td> <td> A <code translate="no" dir="ltr">Tensor</code>. Must have the same type as <code translate="no" dir="ltr">x</code>. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">name</code> </td> <td> A name for the operation (optional). </td> </tr> </table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Returns</th></tr> <tr class="alt"> <td colspan="2"> A <code translate="no" dir="ltr">Tensor</code>. Has the same type as <code translate="no" dir="ltr">x</code>. </td> </tr> 
</table> <h3 id="__rtruediv__" data-text="__rtruediv__" tabindex="0"><code translate="no" dir="ltr">__rtruediv__</code></h3> <p><a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/v1.15.0/tensorflow/python/ops/math_ops.py#L922-L925">View source</a></p> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
__rtruediv__(
    y, x
)
</pre> <h3 id="__rxor__" data-text="__rxor__" tabindex="0"><code translate="no" dir="ltr">__rxor__</code></h3> <p><a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/v1.15.0/tensorflow/python/ops/math_ops.py#L922-L925">View source</a></p> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
__rxor__(
    y, x
)
</pre> <p>Logical XOR function.</p> <p>x ^ y = (x | y) &amp; ~(x &amp; y)</p> <p>Inputs are tensor and if the tensors contains more than one element, an element-wise logical XOR is computed.</p> <h4 id="usage" data-text="Usage:" tabindex="0">Usage:</h4> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">x = tf.constant([False, False, True, True], dtype = tf.bool)
y = tf.constant([False, True, False, True], dtype = tf.bool)
z = tf.logical_xor(x, y, name="LogicalXor")
#  here z = [False  True  True False]
</pre>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Args</th></tr> 
<tr> <td> <code translate="no" dir="ltr">x</code> </td> <td> A <code translate="no" dir="ltr">Tensor</code> type bool. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">y</code> </td> <td> A <code translate="no" dir="ltr">Tensor</code> of type bool. </td> </tr> </table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Returns</th></tr> <tr class="alt"> <td colspan="2"> A <code translate="no" dir="ltr">Tensor</code> of type bool with the same size as that of x or y. </td> </tr> 
</table> <h3 id="__sub__" data-text="__sub__" tabindex="0"><code translate="no" dir="ltr">__sub__</code></h3> <p><a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/v1.15.0/tensorflow/python/ops/math_ops.py#L896-L912">View source</a></p> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
__sub__(
    x, y
)
</pre> <p>Returns x - y element-wise.</p> <blockquote class="note">
<strong>Note:</strong><span> <code translate="no" dir="ltr">Subtract</code> supports broadcasting. More about broadcasting <a href="http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html">here</a></span>
</blockquote>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Args</th></tr> 
<tr> <td> <code translate="no" dir="ltr">x</code> </td> <td> A <code translate="no" dir="ltr">Tensor</code>. Must be one of the following types: <code translate="no" dir="ltr">bfloat16</code>, <code translate="no" dir="ltr">half</code>, <code translate="no" dir="ltr">float32</code>, <code translate="no" dir="ltr">float64</code>, <code translate="no" dir="ltr">uint8</code>, <code translate="no" dir="ltr">int8</code>, <code translate="no" dir="ltr">uint16</code>, <code translate="no" dir="ltr">int16</code>, <code translate="no" dir="ltr">int32</code>, <code translate="no" dir="ltr">int64</code>, <code translate="no" dir="ltr">complex64</code>, <code translate="no" dir="ltr">complex128</code>. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">y</code> </td> <td> A <code translate="no" dir="ltr">Tensor</code>. Must have the same type as <code translate="no" dir="ltr">x</code>. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">name</code> </td> <td> A name for the operation (optional). </td> </tr> </table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Returns</th></tr> <tr class="alt"> <td colspan="2"> A <code translate="no" dir="ltr">Tensor</code>. Has the same type as <code translate="no" dir="ltr">x</code>. </td> </tr> 
</table> <h3 id="__truediv__" data-text="__truediv__" tabindex="0"><code translate="no" dir="ltr">__truediv__</code></h3> <p><a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/v1.15.0/tensorflow/python/ops/math_ops.py#L896-L912">View source</a></p> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
__truediv__(
    x, y
)
</pre> <h3 id="__xor__" data-text="__xor__" tabindex="0"><code translate="no" dir="ltr">__xor__</code></h3> <p><a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/v1.15.0/tensorflow/python/ops/math_ops.py#L896-L912">View source</a></p> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
__xor__(
    x, y
)
</pre> <p>Logical XOR function.</p> <p>x ^ y = (x | y) &amp; ~(x &amp; y)</p> <p>Inputs are tensor and if the tensors contains more than one element, an element-wise logical XOR is computed.</p> <h4 id="usage_2" data-text="Usage:" tabindex="0">Usage:</h4> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">x = tf.constant([False, False, True, True], dtype = tf.bool)
y = tf.constant([False, True, False, True], dtype = tf.bool)
z = tf.logical_xor(x, y, name="LogicalXor")
#  here z = [False  True  True False]
</pre>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Args</th></tr> 
<tr> <td> <code translate="no" dir="ltr">x</code> </td> <td> A <code translate="no" dir="ltr">Tensor</code> type bool. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">y</code> </td> <td> A <code translate="no" dir="ltr">Tensor</code> of type bool. </td> </tr> </table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Returns</th></tr> <tr class="alt"> <td colspan="2"> A <code translate="no" dir="ltr">Tensor</code> of type bool with the same size as that of x or y. </td> </tr> 
</table> <h2 id="class_variables" data-text="Class Variables" tabindex="0">Class Variables</h2> <ul> <li>
<code translate="no" dir="ltr">OVERLOADABLE_OPERATORS</code> 
</li> </ul>  <devsite-page-rating position="footer" selected-rating="0" hover-rating-star="0"> </devsite-page-rating><div class="_attribution">
  <p class="_attribution-p">
     2020 The TensorFlow Authors. All rights reserved.<br>Licensed under the Creative Commons Attribution License 3.0.<br>Code samples licensed under the Apache 2.0 License.<br>
    <a href="https://www.tensorflow.org/versions/r1.15/api_docs/python/tf/Tensor" class="_attribution-link">https://www.tensorflow.org/versions/r1.15/api_docs/python/tf/Tensor</a>
  </p>
</div>

				
			</div>
			<ins class="adsbygoogle"
     style="display:block"
     data-ad-client="ca-pub-2572770204602497"
     data-ad-slot="1992473792"
     data-ad-format="auto"
     data-full-width-responsive="true"></ins>
<script>
     (adsbygoogle = window.adsbygoogle || []).push({});
</script>
		</div>
	</section>

	</div>
	<svg style="display:none">
		<symbol id="icon-dir"><svg viewBox="0 0 20 20"><path d="M15 10c0 .3-.305.515-.305.515l-8.56 5.303c-.625.41-1.135.106-1.135-.67V4.853c0-.777.51-1.078 1.135-.67l8.56 5.305S15 9.702 15 10z"/></svg></symbol>
	  </svg>
</body>
</html>
