
<!DOCTYPE HTML>

<html lang="en" class="_theme-default">

<head>
  <meta charset="utf-8">
  <title>tf.contrib.estimator.replicate_model_fn - TensorFlow 1.15 - W3cubDocs</title>
  
  <meta name="description" content=" Replicate Estimator.model_fn over GPUs. (deprecated) ">
  <meta name="keywords" content="tf, contrib, estimator, replicate, model, fn, tensorflow, tensorflow~1.15">
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="mobile-web-app-capable" content="yes">
  
  <link rel="canonical" href="https://docs.w3cub.com/tensorflow~1.15/contrib/estimator/replicate_model_fn.html">
  <link href="/favicon.png" rel="icon">
  <link rel="stylesheet" type="text/css" href="/assets/application-e498cd0ebe8746846fec95b1a53ab3bb0fb7f47f794f0a38f44c98a1f0d03b21d777ae2c583732e44a5a890f6eacb79a5333545db9d5f3616091ba21ca17d916.css">
  <script src="/assets/application-79c555f6b25481fffac2cac30a7f3e54e608ca09e9e8e42bb1790095ba6d0fcace47d6bc624ddce952c70370892f2d46864f89e6943d4f7f7ff16c8a3231a91a.js" type="text/javascript"></script>
  <script src="/json/tensorflow~1.15.js"></script>
  
<!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-R3WC07G3GB"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());
  gtag('config', 'G-R3WC07G3GB');
</script>
<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-2572770204602497"
     crossorigin="anonymous"></script>
<script async custom-element="amp-auto-ads"
  src="https://cdn.ampproject.org/v0/amp-auto-ads-0.1.js">
</script>


</head>

<body class="docs">
	<amp-auto-ads type="adsense"
              data-ad-client="ca-pub-2572770204602497">
	</amp-auto-ads>
	<div class="_app">
	<header class="_header">

  <a class="_home-link" href="/" ></a>
  <a class="_menu-link"></a>
  <h1 class="_logo">
    <a href="/" class="_nav-link" title="API Documentation Browser">W3cubDocs</a>
  </h1>
  
  <span class="_logo-sub-nav">/</span><span class="_logo-sub-nav"><a href="/tensorflow~1.15/" class="_nav-link" title="" style="margin-left:0;">TensorFlow 1.15</a></span>
  
  <nav class="_nav">
    <a href="https://tools.w3cub.com/?_sp=docs" target="_blank" class="_nav-link ">W3cubTools</a>
    <a href="/cheatsheets/" class="_nav-link ">Cheatsheets</a>
    <a href="/about/" class="_nav-link ">About</a>
  </nav>
</header>
	<section class="_sidebar">
		
		<form class="_search">
		  <input type="search" class="_search-input" placeholder="Search&hellip;" autocomplete="off" autocapitalize="off" autocorrect="off" spellcheck="false" maxlength="20">
		  <a class="_search-clear"></a>
		  <div class="_search-tag"></div>
		</form>
		
		<div class="_list-wrap">
			<div class="_list">
			
			</div>
		</div>
	</section>
	<section class="_container ">
		<div class="_content">
			<ins class="adsbygoogle"
     style="display:block"
     data-ad-client="ca-pub-2572770204602497"
     data-ad-slot="6861657091"
     data-ad-format="auto"
     data-full-width-responsive="true"></ins>
<script>
     (adsbygoogle = window.adsbygoogle || []).push({});
</script>
			<div class="_page _tensorflow">
				
				
<h1 class="devsite-page-title">tf.contrib.estimator.replicate_model_fn</h1>       <p>Replicate <a href="https://www.tensorflow.org/api_docs/python/tf/compat/v1/estimator/Estimator#model_fn"><code translate="no" dir="ltr">Estimator.model_fn</code></a> over GPUs. (deprecated)</p> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
tf.contrib.estimator.replicate_model_fn(
    model_fn, loss_reduction=losses.Reduction.SUM_BY_NONZERO_WEIGHTS, devices=None
)
</pre>  <aside class="warning"><strong>Warning:</strong><span> THIS FUNCTION IS DEPRECATED. It will be removed after 2018-05-31. Instructions for updating: Please use <a href="../distribute/mirroredstrategy"><code translate="no" dir="ltr">tf.contrib.distribute.MirroredStrategy</code></a> instead.</span></aside> <p>The given <code translate="no" dir="ltr">model_fn</code> specifies a single forward pass of a model. To replicate such a model over GPUs, each GPU gets its own instance of the forward pass (a.k.a. a tower). The input features and labels get sharded into the chunks that correspond to the number of GPUs. Each tower computes a loss based on its input. For each such loss, gradients are computed. After that, the available losses are aggregated to form aggregated loss. Available gradients are summed. Then, they update weights using the specified optimizer.</p> <p>If <code translate="no" dir="ltr">devices</code> are <code translate="no" dir="ltr">None</code>, then all available GPUs are going to be used for replication. If no GPUs are available, then the model is going to be placed on the CPU.</p> <p>Two modes of local replication over available GPUs are supported:</p> <p>1) If exactly 1 GPU is detected, then variables and operations are placed onto the GPU. 2) If more than 1 GPU is detected, then variables are going to be placed on the CPU. Replicas of operations are placed on each individual GPU.</p> <p>Here is an example of how one might use their <code translate="no" dir="ltr">model_fn</code> to run over GPUs:</p> <pre class="prettyprint" translate="no" dir="ltr" data-language="cpp">...
def model_fn(...):  # See `model_fn` in `Estimator`.
  loss = ...
  optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.001)
  optimizer = tf.contrib.estimator.TowerOptimizer(optimizer)
  if mode == tf.estimator.ModeKeys.TRAIN:
    #  See the section below on &lt;a href="/api_docs/python/tf/estimator/EstimatorSpec.md#train_op"&gt;&lt;code&gt;EstimatorSpec.train_op&lt;/code&gt;&lt;/a&gt;.
    return EstimatorSpec(mode=mode, loss=loss,
                         train_op=optimizer.minimize(loss))

  #  No change for &lt;a href="/api_docs/python/tf/estimator/ModeKeys.md#EVAL"&gt;&lt;code&gt;ModeKeys.EVAL&lt;/code&gt;&lt;/a&gt; or &lt;a href="/api_docs/python/tf/estimator/ModeKeys.md#PREDICT"&gt;&lt;code&gt;ModeKeys.PREDICT&lt;/code&gt;&lt;/a&gt;.
  return EstimatorSpec(...)
...
classifier = tf.estimator.Estimator(
  model_fn=tf.contrib.estimator.replicate_model_fn(model_fn))
</pre> <p>Please see <code translate="no" dir="ltr">DNNClassifierIntegrationTest</code> for an example with a canned Estimator.</p> <p>On <a href="https://www.tensorflow.org/api_docs/python/tf/estimator/EstimatorSpec#train_op"><code translate="no" dir="ltr">EstimatorSpec.train_op</code></a>: <code translate="no" dir="ltr">model_fn</code> returns <a href="https://www.tensorflow.org/api_docs/python/tf/estimator/EstimatorSpec#train_op"><code translate="no" dir="ltr">EstimatorSpec.train_op</code></a> for <code translate="no" dir="ltr">tf.estimator.GraphKeys.TRAIN</code>. It is typically derived using an optimizer. Towers are expected to populate it in the same way. Gradients from all towers are reduced and applied in the last tower. To achieve that in the case of multiple towers, <code translate="no" dir="ltr">TowerOptimizer</code> needs to be used. See <code translate="no" dir="ltr">TowerOptimizer</code>.</p> <p>On sharding input features and labels: Input features and labels are split for consumption by each tower. They are split across the dimension 0. Features and labels need to be batch major.</p> <p>On reduction algorithms: Certain algorithms were chosen for aggregating results of computations on multiple towers:</p> <ul> <li>Losses from all towers are reduced according to <code translate="no" dir="ltr">loss_reduction</code>.</li> <li>Gradients from all towers are reduced according to <code translate="no" dir="ltr">loss_reduction</code> for each trainable variable.</li> <li>
<code translate="no" dir="ltr">eval_metrics_ops</code> are reduced per metric using <code translate="no" dir="ltr">reduce_mean</code>.</li> <li>
<a href="https://www.tensorflow.org/api_docs/python/tf/estimator/EstimatorSpec#predictions"><code translate="no" dir="ltr">EstimatorSpec.predictions</code></a> and <a href="https://www.tensorflow.org/api_docs/python/tf/estimator/EstimatorSpec#export_outputs"><code translate="no" dir="ltr">EstimatorSpec.export_outputs</code></a> are reduced using concatenation.</li> <li>For all other fields of <code translate="no" dir="ltr">EstimatorSpec</code> the values of the first tower are taken.</li> </ul> <p>On distribution of variables: Variables are not duplicated between towers. Instead, they are placed on a single device as defined above and shared across towers.</p> <h4 id="on_overhead" data-text="On overhead:" tabindex="0">On overhead:</h4> <p>If only one device is specified, then aggregation of loss and gradients doesn't happen. Replication consists of placing <code translate="no" dir="ltr">model_fn</code> onto the specified device.</p> <p>On current limitations:</p> <ul> <li>
<code translate="no" dir="ltr">predictions</code> are not supported for <a href="https://www.tensorflow.org/api_docs/python/tf/estimator/ModeKeys#EVAL"><code translate="no" dir="ltr">ModeKeys.EVAL</code></a>. They are required for <a href="add_metrics"><code translate="no" dir="ltr">tf.contrib.estimator.add_metrics</code></a>.</li> </ul>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Args</th></tr> 
<tr> <td> <code translate="no" dir="ltr">model_fn</code> </td> <td> <code translate="no" dir="ltr">model_fn</code> as defined in <code translate="no" dir="ltr">Estimator</code>. See the section above about the train_op argument of <code translate="no" dir="ltr">EstimatorSpec</code>. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">loss_reduction</code> </td> <td> controls whether losses are summed or averaged. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">devices</code> </td> <td> Optional list of devices to replicate the model across. This argument can be used to replicate only on the subset of available GPUs. If <code translate="no" dir="ltr">None</code>, then all available GPUs are going to be used for replication. If no GPUs are available, then the model is going to be placed on the CPU. </td> </tr> </table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Raises</th></tr> 
<tr> <td> <code translate="no" dir="ltr">ValueError</code> </td> <td> if there is no <code translate="no" dir="ltr">loss_reduction</code> or if TowerOptimizer is mis-used. </td> </tr> </table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Returns</th></tr> <tr class="alt"> <td colspan="2"> A replicated version of the supplied <code translate="no" dir="ltr">model_fn</code>. Returned function that conforms to the requirements of <code translate="no" dir="ltr">Estimator</code>'s <code translate="no" dir="ltr">model_fn</code> and can be used instead of the supplied <code translate="no" dir="ltr">model_fn</code>. </td> </tr> 
</table>  <devsite-page-rating position="footer" selected-rating="0" hover-rating-star="0"> </devsite-page-rating><div class="_attribution">
  <p class="_attribution-p">
    Â© 2020 The TensorFlow Authors. All rights reserved.<br>Licensed under the Creative Commons Attribution License 3.0.<br>Code samples licensed under the Apache 2.0 License.<br>
    <a href="https://www.tensorflow.org/versions/r1.15/api_docs/python/tf/contrib/estimator/replicate_model_fn" class="_attribution-link">https://www.tensorflow.org/versions/r1.15/api_docs/python/tf/contrib/estimator/replicate_model_fn</a>
  </p>
</div>

				
			</div>
			<ins class="adsbygoogle"
     style="display:block"
     data-ad-client="ca-pub-2572770204602497"
     data-ad-slot="1992473792"
     data-ad-format="auto"
     data-full-width-responsive="true"></ins>
<script>
     (adsbygoogle = window.adsbygoogle || []).push({});
</script>
		</div>
	</section>

	</div>
	<svg style="display:none">
		<symbol id="icon-dir"><svg viewBox="0 0 20 20"><path d="M15 10c0 .3-.305.515-.305.515l-8.56 5.303c-.625.41-1.135.106-1.135-.67V4.853c0-.777.51-1.078 1.135-.67l8.56 5.305S15 9.702 15 10z"/></svg></symbol>
	  </svg>
</body>
</html>
