
<!DOCTYPE HTML>

<html lang="en" class="_theme-default">

<head>
  <meta charset="utf-8">
  <title>Losses - TensorFlow Python - W3cubDocs</title>
  
  <meta name="description" content=" This module is deprecated. Instructions for updating&#58; Use tf.losses instead. ">
  <meta name="keywords" content="losses, contrib, tensorflow, python, tensorflow~python">
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="mobile-web-app-capable" content="yes">
  
  <link rel="canonical" href="https://docs.w3cub.com/tensorflow~python/contrib.losses.html">
  <link href="/favicon.png" rel="icon">
  <link rel="stylesheet" type="text/css" href="/assets/application-e4ebd3a2a5652ff55173659804c4390a004917f3bdd17b5bb3ba78ea5c9c46fe181cadaac34517ccd815f5bdc982bbfe67179d6f4ac2f084ef2265e2a3dc8dc5.css" integrity="sha512-5OvToqVlL/VRc2WYBMQ5CgBJF/O90Xtbs7p46lycRv4YHK2qw0UXzNgV9b3Jgrv+Zxedb0rC8ITvImXio9yNxQ==" crossorigin="anonymous">
  <script type="text/javascript" integrity="sha512-EpkDeu98lN/jPKijllzVWdRg/dUSSMCaldYZNFz6bcNoBvpWRNz0HSTRQJ3ENmQc5Cuj1zDW1vHd7b0DzpOgyA==" crossorigin="anonymous" src="/assets/application-1299037aef7c94dfe33ca8a3965cd559d460fdd51248c09a95d619345cfa6dc36806fa5644dcf41d24d1409dc436641ce42ba3d730d6d6f1ddedbd03ce93a0c8.js"></script>
  <script src="/json/tensorflow~python.js"></script>
  
  <script type="text/javascript">
    var _gaq = _gaq || [];
    _gaq.push(['_setAccount', 'UA-71174418-1']);
    _gaq.push(['_trackPageview']);

    (function() {
      var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
      ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
      var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
    })();
  </script>
  <script data-ad-client="ca-pub-2572770204602497" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script async custom-element="amp-auto-ads"
  src="https://cdn.ampproject.org/v0/amp-auto-ads-0.1.js">
</script>


</head>

<body>
	<amp-auto-ads type="adsense"
              data-ad-client="ca-pub-2572770204602497">
	</amp-auto-ads>
	<div class="_app">
	<header class="_header">
  
  <form class="_search">
    <input type="search" class="_search-input" placeholder="Search&hellip;" autocomplete="off" autocapitalize="off" autocorrect="off" spellcheck="false" maxlength="20">
    <a class="_search-clear"></a>
    <div class="_search-tag"></div>
  </form>
  
  <a class="_home-link" href="/" ></a>
  <a class="_menu-link"></a>
  <h1 class="_logo">
    <a href="/" class="_nav-link" title="API Documentation Browser">W3cubDocs</a>
  </h1>
  
  <span class="_logo-sub-nav">/</span><span class="_logo-sub-nav"><a href="/tensorflow~python/" class="_nav-link" title="" style="margin-left:0;">TensorFlow Python</a></span>
  
  <nav class="_nav">
    <a href="https://tools.w3cub.com/?_sp=docs" target="_blank" class="_nav-link ">W3cubTools</a>
    <a href="/cheatsheets/" class="_nav-link ">Cheatsheets</a>
    <a href="/about/" class="_nav-link ">About</a>
  </nav>
</header>
	<section class="_sidebar">
		<div class="_list-wrap">
			<div class="_list">
			
			</div>
		</div>
	</section>
	<section class="_container ">
		<div class="_content">
			<ins class="adsbygoogle"
     style="display:block"
     data-ad-client="ca-pub-2572770204602497"
     data-ad-slot="6861657091"
     data-ad-format="link"
     data-full-width-responsive="true"></ins>
<script>
     (adsbygoogle = window.adsbygoogle || []).push({});
</script>
			<div class="_page _tensorflow">
				
				
<h1 itemprop="name" class="devsite-page-title"> Losses (contrib) </h1>     <h2 id="Deprecated">Deprecated</h2> <p>This module is deprecated. Instructions for updating: Use <a href="https://www.tensorflow.org/api_docs/python/tf/losses"><code>tf.losses</code></a> instead.</p> <h2 id="Loss_operations_for_use_in_neural_networks_">Loss operations for use in neural networks.</h2> <blockquote class="note">
<strong>Note:</strong><span> By default, all the losses are collected into the <code>GraphKeys.LOSSES</code> collection.</span>
</blockquote> <p>All of the loss functions take a pair of predictions and ground truth labels, from which the loss is computed. It is assumed that the shape of both these tensors is of the form [batch_size, d1, ... dN] where <code>batch_size</code> is the number of samples in the batch and <code>d1</code> ... <code>dN</code> are the remaining dimensions.</p> <p>It is common, when training with multiple loss functions, to adjust the relative strengths of individual losses. This is performed by rescaling the losses via a <code>weight</code> parameter passed to the loss functions. For example, if we were training with both log_loss and mean_squared_error, and we wished that the log_loss penalty be twice as severe as the mean_squared_error, we would implement this as:</p> <pre class="prettyprint lang-python" data-language="python"># Explicitly set the weight.
tf.contrib.losses.log(predictions, labels, weight=2.0)

# Uses default weight of 1.0
tf.contrib.losses.mean_squared_error(predictions, labels)

# All the losses are collected into the `GraphKeys.LOSSES` collection.
losses = tf.get_collection(tf.GraphKeys.LOSSES)
</pre> <p>While specifying a scalar loss rescales the loss over the entire batch, we sometimes want to rescale the loss per batch sample. For example, if we have certain examples that matter more to us to get correctly, we might want to have a higher loss that other samples whose mistakes matter less. In this case, we can provide a weight vector of length <code>batch_size</code> which results in the loss for each sample in the batch being scaled by the corresponding weight element. For example, consider the case of a classification problem where we want to maximize our accuracy but we especially interested in obtaining high accuracy for a specific class:</p> <pre class="prettyprint lang-python" data-language="python">inputs, labels = LoadData(batch_size=3)
logits = MyModelPredictions(inputs)

# Ensures that the loss for examples whose ground truth class is `3` is 5x
# higher than the loss for all other examples.
weight = tf.multiply(4, tf.cast(tf.equal(labels, 3), tf.float32)) + 1

onehot_labels = tf.one_hot(labels, num_classes=5)
tf.contrib.losses.softmax_cross_entropy(logits, onehot_labels, weight=weight)
</pre> <p>Finally, in certain cases, we may want to specify a different loss for every single measurable value. For example, if we are performing per-pixel depth prediction, or per-pixel denoising, a single batch sample has P values where P is the number of pixels in the image. For many losses, the number of measurable values matches the number of elements in the predictions and labels tensors. For others, such as softmax_cross_entropy and cosine_distance, the loss functions reduces the dimensions of the inputs to produces a tensor of losses for each measurable value. For example, softmax_cross_entropy takes as input predictions and labels of dimension [batch_size, num_classes] but the number of measurable values is [batch_size]. Consequently, when passing a weight tensor to specify a different loss for every measurable value, the dimension of the tensor will depend on the loss being used.</p> <p>For a concrete example, consider the case of per-pixel depth prediction where certain ground truth depth values are missing (due to sensor noise in the capture process). In this case, we want to assign zero weight to losses for these predictions.</p> <pre class="prettyprint lang-python" data-language="python"># 'depths' that are missing have a value of 0:
images, depths = LoadData(...)
predictions = MyModelPredictions(images)

weight = tf.cast(tf.greater(depths, 0), tf.float32)
loss  = tf.contrib.losses.mean_squared_error(predictions, depths, weight)
</pre> <p>Note that when using weights for the losses, the final average is computed by rescaling the losses by the weights and then dividing by the total number of non-zero samples. For an arbitrary set of weights, this may not necessarily produce a weighted average. Instead, it simply and transparently rescales the per-element losses before averaging over the number of observations. For example if the losses computed by the loss function is an array [4, 1, 2, 3] and the weights are an array [1, 0.5, 3, 9], then the average loss is:</p> <pre class="prettyprint lang-python" data-language="python">(4*1 + 1*0.5 + 2*3 + 3*9) / 4
</pre> <p>However, with a single loss function and an arbitrary set of weights, one can still easily create a loss function such that the resulting loss is a weighted average over the individual prediction errors:</p> <pre class="prettyprint lang-python" data-language="python">images, labels = LoadData(...)
predictions = MyModelPredictions(images)

weight = MyComplicatedWeightingFunction(labels)
weight = tf.div(weight, tf.size(weight))
loss = tf.contrib.losses.mean_squared_error(predictions, depths, weight)
</pre> <ul> <li><a href="https://www.tensorflow.org/api_docs/python/tf/contrib/losses/absolute_difference"><code>tf.contrib.losses.absolute_difference</code></a></li> <li><a href="https://www.tensorflow.org/api_docs/python/tf/contrib/losses/add_loss"><code>tf.contrib.losses.add_loss</code></a></li> <li><a href="https://www.tensorflow.org/api_docs/python/tf/contrib/losses/hinge_loss"><code>tf.contrib.losses.hinge_loss</code></a></li> <li><a href="https://www.tensorflow.org/api_docs/python/tf/contrib/losses/compute_weighted_loss"><code>tf.contrib.losses.compute_weighted_loss</code></a></li> <li><a href="https://www.tensorflow.org/api_docs/python/tf/contrib/losses/cosine_distance"><code>tf.contrib.losses.cosine_distance</code></a></li> <li><a href="https://www.tensorflow.org/api_docs/python/tf/contrib/losses/get_losses"><code>tf.contrib.losses.get_losses</code></a></li> <li><a href="https://www.tensorflow.org/api_docs/python/tf/contrib/losses/get_regularization_losses"><code>tf.contrib.losses.get_regularization_losses</code></a></li> <li><a href="https://www.tensorflow.org/api_docs/python/tf/contrib/losses/get_total_loss"><code>tf.contrib.losses.get_total_loss</code></a></li> <li><a href="https://www.tensorflow.org/api_docs/python/tf/contrib/losses/log_loss"><code>tf.contrib.losses.log_loss</code></a></li> <li><a href="https://www.tensorflow.org/api_docs/python/tf/contrib/losses/mean_pairwise_squared_error"><code>tf.contrib.losses.mean_pairwise_squared_error</code></a></li> <li><a href="https://www.tensorflow.org/api_docs/python/tf/contrib/losses/mean_squared_error"><code>tf.contrib.losses.mean_squared_error</code></a></li> <li><a href="https://www.tensorflow.org/api_docs/python/tf/contrib/losses/sigmoid_cross_entropy"><code>tf.contrib.losses.sigmoid_cross_entropy</code></a></li> <li><a href="https://www.tensorflow.org/api_docs/python/tf/contrib/losses/softmax_cross_entropy"><code>tf.contrib.losses.softmax_cross_entropy</code></a></li> <li><a href="https://www.tensorflow.org/api_docs/python/tf/contrib/losses/sparse_softmax_cross_entropy"><code>tf.contrib.losses.sparse_softmax_cross_entropy</code></a></li> </ul>
<div class="_attribution">
  <p class="_attribution-p">
    Â© 2018 The TensorFlow Authors. All rights reserved.<br>Licensed under the Creative Commons Attribution License 3.0.<br>Code samples licensed under the Apache 2.0 License.<br>
    <a href="https://www.tensorflow.org/api_guides/python/contrib.losses" class="_attribution-link">https://www.tensorflow.org/api_guides/python/contrib.losses</a>
  </p>
</div>

				
			</div>
			<ins class="adsbygoogle"
     style="display:block"
     data-ad-client="ca-pub-2572770204602497"
     data-ad-slot="1992473792"
     data-ad-format="auto"
     data-full-width-responsive="true"></ins>
<script>
     (adsbygoogle = window.adsbygoogle || []).push({});
</script>
		</div>
	</section>

	</div>
	<svg style="display:none">
		<symbol id="icon-dir"><svg viewBox="0 0 20 20"><path d="M15 10c0 .3-.305.515-.305.515l-8.56 5.303c-.625.41-1.135.106-1.135-.67V4.853c0-.777.51-1.078 1.135-.67l8.56 5.305S15 9.702 15 10z"/></svg></symbol>
	  </svg>
</body>
</html>
