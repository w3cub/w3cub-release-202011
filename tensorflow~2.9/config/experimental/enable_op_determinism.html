
<!DOCTYPE HTML>

<html lang="en" class="_theme-default">

<head>
  <meta charset="utf-8">
  <title>tf.config.experimental.enable_op_determinism - TensorFlow 2.9 - W3cubDocs</title>
  
  <meta name="description" content=" Configures TensorFlow ops to run deterministically. ">
  <meta name="keywords" content="tf, config, experimental, enable, op, determinism, tensorflow, tensorflow~2.9">
  <meta name="HandheldFriendly" content="True">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="mobile-web-app-capable" content="yes">
  
  <link rel="canonical" href="https://docs.w3cub.com/tensorflow~2.9/config/experimental/enable_op_determinism.html">
  <link href="/favicon.png" rel="icon">
  <link rel="stylesheet" type="text/css" href="/assets/application-f16eecbe420d8b2925d31ffbb21d05646497ecbd9515f08ffe69e9bba7332f5657accc7003c7f6c72cb4a132171acf171b359ae3bae4ae5660ddfb1718f88c67.css">
  <script src="/assets/application-79c555f6b25481fffac2cac30a7f3e54e608ca09e9e8e42bb1790095ba6d0fcace47d6bc624ddce952c70370892f2d46864f89e6943d4f7f7ff16c8a3231a91a.js" type="text/javascript"></script>
  <script src="/json/tensorflow~2.9.js"></script>
  
<!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-R3WC07G3GB"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());
  gtag('config', 'G-R3WC07G3GB');
</script>
<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-2572770204602497"
     crossorigin="anonymous"></script>
<script async custom-element="amp-auto-ads"
  src="https://cdn.ampproject.org/v0/amp-auto-ads-0.1.js">
</script>


</head>

<body class="docs">
	<amp-auto-ads type="adsense"
              data-ad-client="ca-pub-2572770204602497">
	</amp-auto-ads>
	<div class="_app">
	<header class="_header">

  <a class="_home-link" href="/" ></a>
  <a class="_menu-link"></a>
  <h1 class="_logo">
    <a href="/" class="_nav-link" title="API Documentation Browser">W3cubDocs</a>
  </h1>
  
  <span class="_logo-sub-nav">/</span><span class="_logo-sub-nav"><a href="/tensorflow~2.9/" class="_nav-link" title="" style="margin-left:0;">TensorFlow 2.9</a></span>
  
  <nav class="_nav">
    <a href="https://tools.w3cub.com/?_sp=docs" target="_blank" class="_nav-link ">W3cubTools</a>
    <a href="/cheatsheets/" class="_nav-link ">Cheatsheets</a>
    <a href="/about/" class="_nav-link ">About</a>
  </nav>
</header>
	<section class="_sidebar">
		
		<form class="_search">
		  <input type="search" class="_search-input" placeholder="Search&hellip;" autocomplete="off" autocapitalize="off" autocorrect="off" spellcheck="false" maxlength="20">
		  <a class="_search-clear"></a>
		  <div class="_search-tag"></div>
		</form>
		
		<div class="_list-wrap">
			<div class="_list">
			
			</div>
		</div>
	</section>
	<section class="_container ">
		<div class="_content">
			<ins class="adsbygoogle"
     style="display:block"
     data-ad-client="ca-pub-2572770204602497"
     data-ad-slot="6861657091"
     data-ad-format="auto"
     data-full-width-responsive="true"></ins>
<script>
     (adsbygoogle = window.adsbygoogle || []).push({});
</script>
			<div class="_page _tensorflow">
				
				
<h1 class="devsite-page-title">tf.config.experimental.enable_op_determinism</h1> <devsite-bookmark></devsite-bookmark>       <p>Configures TensorFlow ops to run deterministically.</p> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
tf.config.experimental.enable_op_determinism()
</pre>  <p>When op determinism is enabled, TensorFlow ops will be deterministic. This means that if an op is run multiple times with the same inputs on the same hardware, it will have the exact same outputs each time. This is useful for debugging models. Note that determinism in general comes at the expense of lower performance and so your model may run slower when op determinism is enabled.</p> <p>If you want your TensorFlow program to run deterministically, put the following code near the start of your program.</p> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">tf.keras.utils.set_random_seed(1)
tf.config.experimental.enable_op_determinism()
</pre> <p>Calling <a href="../../keras/utils/set_random_seed"><code translate="no" dir="ltr">tf.keras.utils.set_random_seed</code></a> sets the Python seed, the NumPy seed, and the TensorFlow seed. Setting these seeds is necessary to ensure any random numbers your program generates are also deterministic.</p> <p>By default, op determinism is not enabled, so ops might return different results when run with the same inputs. These differences are often caused by the use of asynchronous threads within the op nondeterministically changing the order in which floating-point numbers are added. Most of these cases of nondeterminism occur on GPUs, which have thousands of hardware threads that are used to run ops. Enabling determinism directs such ops to use a different algorithm, one that does not use threads in a nondeterministic way.</p> <p>Another potential source of nondeterminism is <a href="../../data"><code translate="no" dir="ltr">tf.data</code></a> based data processing. Typically, this can introduce nondeterminsm due to the use of parallelism in methods such as <a href="../../data/dataset#map"><code translate="no" dir="ltr">Dataset.map</code></a> producing inputs or running stateful ops in a nondeterministic order. Enabling determinism will remove such sources of nondeterminism.</p> <p>Enabling determinism will likely make your model or your <a href="../../data"><code translate="no" dir="ltr">tf.data</code></a> data processing slower. For example, <a href="../../data/dataset#map"><code translate="no" dir="ltr">Dataset.map</code></a> can become several orders of magnitude slower when the map function has random ops or other stateful ops. See the “Determinism and tf.data” section below for more details. In future TensorFlow releases, we plan on improving the performance of determinism, especially for common scenarios such as <a href="../../data/dataset#map"><code translate="no" dir="ltr">Dataset.map</code></a>.</p> <p>Certain ops will raise an <code translate="no" dir="ltr">UnimplementedError</code> because they do not yet have a deterministic implementation. Additionally, due to bugs, some ops might be nondeterministic and not raise an <code translate="no" dir="ltr">UnimplementedError</code>. If you encounter such ops, please <a href="https://github.com/tensorflow/tensorflow/issues">file an issue</a>.</p> <p>An example of enabling determinism follows. The <a href="../../nn/softmax_cross_entropy_with_logits"><code translate="no" dir="ltr">tf.nn.softmax_cross_entropy_with_logits</code></a> op is run multiple times and the output is shown to be the same each time. This example would likely fail when run on a GPU if determinism were not enabled, because <a href="../../nn/softmax_cross_entropy_with_logits"><code translate="no" dir="ltr">tf.nn.softmax_cross_entropy_with_logits</code></a> uses a nondeterministic algorithm on GPUs by default.</p> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">labels = tf.random.normal((1, 10000))
logits = tf.random.normal((1, 10000))
output = tf.nn.softmax_cross_entropy_with_logits(labels=labels,
                                                 logits=logits)
for _ in range(5):
  output2 = tf.nn.softmax_cross_entropy_with_logits(labels=labels,
                                                    logits=logits)
  tf.debugging.assert_equal(output, output2)
</pre> <h2 id="writing_deterministic_models" data-text="Writing deterministic models">Writing deterministic models</h2> <p>You can make your models deterministic by enabling op determinism. This means that you can train a model and finish each run with exactly the same trainable variables. This also means that the inferences of your previously-trained model will be exactly the same on each run. Typically, models can be made deterministic by simply setting the seeds and enabling op determinism, as in the example above. However, to guarantee that your model operates deterministically, you must meet all the following requirements:</p> <ul> <li>Call <a href="enable_op_determinism"><code translate="no" dir="ltr">tf.config.experimental.enable_op_determinism()</code></a>, as mentioned above.</li> <li>Reproducibly reset any pseudorandom number generators (PRNGs) you’re using, such as by setting the seeds for the default PRNGs in TensorFlow, Python, and NumPy, as mentioned above. Note that certain newer NumPy classes like <code translate="no" dir="ltr">numpy.random.default_rng</code> ignore the global NumPy seed, so a seed must be explicitly passed to such classes, if used.</li> <li>Use the same hardware configuration in every run.</li> <li>Use the same software environment in every run (OS, checkpoints, version of CUDA and TensorFlow, environmental variables, etc). Note that determinism is not guaranteed across different versions of TensorFlow.</li> <li>Do not use constructs outside TensorFlow that are nondeterministic, such as reading from <code translate="no" dir="ltr">/dev/random</code> or using multiple threads/processes in ways that influence TensorFlow’s behavior.</li> <li>Ensure your input pipeline is deterministic. If you use <a href="../../data"><code translate="no" dir="ltr">tf.data</code></a>, this is done automatically (at the expense of performance). See "Determinism and tf.data" below for more information.</li> <li>Do not use <a href="../../compat/v1/session"><code translate="no" dir="ltr">tf.compat.v1.Session</code></a> and <a href="../../distribute/experimental/parameterserverstrategy"><code translate="no" dir="ltr">tf.distribute.experimental.ParameterServerStrategy</code></a>, which can introduce nondeterminism. Besides ops (including <a href="../../data"><code translate="no" dir="ltr">tf.data</code></a> ops), these are the only known potential sources of nondeterminism within TensorFlow, (if you find more, please file an issue). Note that <a href="../../compat/v1/session"><code translate="no" dir="ltr">tf.compat.v1.Session</code></a> is required to use the TF1 API, so determinism cannot be guaranteed when using the TF1 API.</li> <li>Do not use nondeterministic custom ops.</li> </ul> <h2 id="additional_details_on_determinism" data-text="Additional details on determinism">Additional details on determinism</h2> <p>For stateful ops to be deterministic, the state of the system must be the same every time the op is run. For example the output of <a href="../../variable#sparse_read"><code translate="no" dir="ltr">tf.Variable.sparse_read</code></a> (obviously) depends on both the variable value and the <code translate="no" dir="ltr">indices</code> function parameter. When determinism is enabled, the side effects of stateful ops are deterministic.</p> <p>TensorFlow’s random ops, such as <a href="../../random/normal"><code translate="no" dir="ltr">tf.random.normal</code></a>, will raise a <code translate="no" dir="ltr">RuntimeError</code> if determinism is enabled and a seed has not been set. However, attempting to generate nondeterministic random numbers using Python or NumPy will not raise such errors. Make sure you remember to set the Python and NumPy seeds. Calling <a href="../../keras/utils/set_random_seed"><code translate="no" dir="ltr">tf.keras.utils.set_random_seed</code></a> is an easy way to set all three seeds.</p> <p>Note that latency, memory consumption, throughput, and other performance characteristics are <em>not</em> made deterministic by enabling op determinism. Only op outputs and side effects are made deterministic. Additionally, a model may nondeterministically raise a <a href="../../errors/resourceexhaustederror"><code translate="no" dir="ltr">tf.errors.ResourceExhaustedError</code></a> from a lack of memory due to the fact that memory consumption is nondeterministic.</p> <h2 id="determinism_and_tfdata" data-text="Determinism and tf.data">Determinism and tf.data</h2> <p>Enabling deterministic ops makes <a href="../../data"><code translate="no" dir="ltr">tf.data</code></a> deterministic in several ways:</p> <ol> <li>For dataset methods with a <code translate="no" dir="ltr">deterministic</code> argument, such as <a href="../../data/dataset#map"><code translate="no" dir="ltr">Dataset.map</code></a> and <a href="../../data/dataset#batch"><code translate="no" dir="ltr">Dataset.batch</code></a>, the <code translate="no" dir="ltr">deterministic</code> argument is overridden to be <code translate="no" dir="ltr">True</code> irrespective of its setting.</li> <li>The <code translate="no" dir="ltr">tf.data.Option.experimental_deterministic</code> option is overridden to be <code translate="no" dir="ltr">True</code> irrespective of its setting..</li> <li>In <a href="../../data/dataset#map"><code translate="no" dir="ltr">Dataset.map</code></a> and <a href="../../data/dataset#interleave"><code translate="no" dir="ltr">Dataset.interleave</code></a>, if the map or interleave function has stateful random ops or other stateful ops, the function will run serially instead of in parallel. This means the <code translate="no" dir="ltr">num_parallel_calls</code> argument to <code translate="no" dir="ltr">map</code> and <code translate="no" dir="ltr">interleave</code> is effectively ignored.</li> <li>Prefetching with <a href="../../data/dataset#prefetch"><code translate="no" dir="ltr">Dataset.prefetch</code></a> will be disabled if any function run as part of the input pipeline has certain stateful ops. Similarly, any dataset method with a <code translate="no" dir="ltr">num_parallel_calls</code> argument will be made to run serially if any function in the input pipeline has such stateful ops. Legacy random ops such as <a href="../../random/normal"><code translate="no" dir="ltr">tf.random.normal</code></a> will <em>not</em> cause such datasets to be changed, but most other stateful ops will.</li> </ol> <p>Unfortunately, due to (3), performance can be greatly reduced when stateful ops are used in <a href="../../data/dataset#map"><code translate="no" dir="ltr">Dataset.map</code></a> due to no longer running the map function in parallel. A common example of stateful ops used in <a href="../../data/dataset#map"><code translate="no" dir="ltr">Dataset.map</code></a> are random ops, such as <a href="../../random/normal"><code translate="no" dir="ltr">tf.random.normal</code></a>, which are typically used for distortions. One way to work around this is to use stateless random ops instead. Alternatively you can hoist all random ops into its own separate <a href="../../data/dataset#map"><code translate="no" dir="ltr">Dataset.map</code></a> call, making the original <a href="../../data/dataset#map"><code translate="no" dir="ltr">Dataset.map</code></a> call stateless and thus avoid the need to serialize its execution.</p> <p>(4) can also cause performance to be reduced, but occurs less frequently than (3) because legacy random ops do not cause (4) to take effect. However, unlike (3), when there are non-random stateful ops in a user-defined function, every <code translate="no" dir="ltr">map</code> and <code translate="no" dir="ltr">interleave</code> dataset is affected, instead of just the <code translate="no" dir="ltr">map</code> or <code translate="no" dir="ltr">interleave</code> dataset with the function that has stateful ops. Additionally, <code translate="no" dir="ltr">prefetch</code> datasets and any dataset with the <code translate="no" dir="ltr">num_parallel_calls</code> argument are also affected.</p>  <devsite-thumb-rating position="footer"> </devsite-thumb-rating><div class="_attribution">
  <p class="_attribution-p">
    © 2022 The TensorFlow Authors. All rights reserved.<br>Licensed under the Creative Commons Attribution License 4.0.<br>Code samples licensed under the Apache 2.0 License.<br>
    <a href="https://www.tensorflow.org/versions/r2.9/api_docs/python/tf/config/experimental/enable_op_determinism" class="_attribution-link">https://www.tensorflow.org/versions/r2.9/api_docs/python/tf/config/experimental/enable_op_determinism</a>
  </p>
</div>

				
			</div>
			<ins class="adsbygoogle"
     style="display:block"
     data-ad-client="ca-pub-2572770204602497"
     data-ad-slot="1992473792"
     data-ad-format="auto"
     data-full-width-responsive="true"></ins>
<script>
     (adsbygoogle = window.adsbygoogle || []).push({});
</script>
		</div>
	</section>

	</div>
	<svg style="display:none">
		<symbol id="icon-dir"><svg viewBox="0 0 20 20"><path d="M15 10c0 .3-.305.515-.305.515l-8.56 5.303c-.625.41-1.135.106-1.135-.67V4.853c0-.777.51-1.078 1.135-.67l8.56 5.305S15 9.702 15 10z"/></svg></symbol>
	  </svg>
</body>
</html>
