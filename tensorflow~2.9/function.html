
<!DOCTYPE HTML>

<html lang="en" class="_theme-default">

<head>
  <meta charset="utf-8">
  <title>tf.function - TensorFlow 2.9 - W3cubDocs</title>
  
  <meta name="description" content=" Compiles a function into a callable TensorFlow graph. (deprecated arguments) (deprecated arguments) ">
  <meta name="keywords" content="tf, function, tensorflow, tensorflow~2.9">
  <meta name="HandheldFriendly" content="True">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="mobile-web-app-capable" content="yes">
  
  <link rel="canonical" href="https://docs.w3cub.com/tensorflow~2.9/function.html">
  <link href="/favicon.png" rel="icon">
  <link rel="stylesheet" type="text/css" href="/assets/application-f16eecbe420d8b2925d31ffbb21d05646497ecbd9515f08ffe69e9bba7332f5657accc7003c7f6c72cb4a132171acf171b359ae3bae4ae5660ddfb1718f88c67.css">
  <script src="/assets/application-79c555f6b25481fffac2cac30a7f3e54e608ca09e9e8e42bb1790095ba6d0fcace47d6bc624ddce952c70370892f2d46864f89e6943d4f7f7ff16c8a3231a91a.js" type="text/javascript"></script>
  <script src="/json/tensorflow~2.9.js"></script>
  
<!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-R3WC07G3GB"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());
  gtag('config', 'G-R3WC07G3GB');
</script>
<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-2572770204602497"
     crossorigin="anonymous"></script>
<script async custom-element="amp-auto-ads"
  src="https://cdn.ampproject.org/v0/amp-auto-ads-0.1.js">
</script>


</head>

<body class="docs">
	<amp-auto-ads type="adsense"
              data-ad-client="ca-pub-2572770204602497">
	</amp-auto-ads>
	<div class="_app">
	<header class="_header">

  <a class="_home-link" href="/" ></a>
  <a class="_menu-link"></a>
  <h1 class="_logo">
    <a href="/" class="_nav-link" title="API Documentation Browser">W3cubDocs</a>
  </h1>
  
  <span class="_logo-sub-nav">/</span><span class="_logo-sub-nav"><a href="/tensorflow~2.9/" class="_nav-link" title="" style="margin-left:0;">TensorFlow 2.9</a></span>
  
  <nav class="_nav">
    <a href="https://tools.w3cub.com/?_sp=docs" target="_blank" class="_nav-link ">W3cubTools</a>
    <a href="/cheatsheets/" class="_nav-link ">Cheatsheets</a>
    <a href="/about/" class="_nav-link ">About</a>
  </nav>
</header>
	<section class="_sidebar">
		
		<form class="_search">
		  <input type="search" class="_search-input" placeholder="Search&hellip;" autocomplete="off" autocapitalize="off" autocorrect="off" spellcheck="false" maxlength="20">
		  <a class="_search-clear"></a>
		  <div class="_search-tag"></div>
		</form>
		
		<div class="_list-wrap">
			<div class="_list">
			
			</div>
		</div>
	</section>
	<section class="_container ">
		<div class="_content">
			<ins class="adsbygoogle"
     style="display:block"
     data-ad-client="ca-pub-2572770204602497"
     data-ad-slot="6861657091"
     data-ad-format="auto"
     data-full-width-responsive="true"></ins>
<script>
     (adsbygoogle = window.adsbygoogle || []).push({});
</script>
			<div class="_page _tensorflow">
				
				
<h1 class="devsite-page-title">tf.function</h1> <devsite-bookmark></devsite-bookmark>      <table class="tfo-notebook-buttons tfo-api nocontent" align="left">  <td> <a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/v2.9.0/tensorflow/python/eager/def_function.py#L1285-L1694">  View source on GitHub </a> </td> </table> <p>Compiles a function into a callable TensorFlow graph. (deprecated arguments) (deprecated arguments)</p> <section class="expandable"> <h4 class="showalways" id="view-aliases" data-text="View aliases">View aliases</h4> <p> <b>Compat aliases for migration</b> </p>
<p>See <a href="https://www.tensorflow.org/guide/migrate">Migration guide</a> for more details.</p> <p><a href="https://www.tensorflow.org/api_docs/python/tf/function"><code translate="no" dir="ltr">tf.compat.v1.function</code></a></p> </section> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
tf.function(
    func=None,
    input_signature=None,
    autograph=True,
    jit_compile=None,
    reduce_retracing=False,
    experimental_implements=None,
    experimental_autograph_options=None,
    experimental_relax_shapes=None,
    experimental_compile=None,
    experimental_follow_type_hints=None
) -&gt; tf.types.experimental.GenericFunction
</pre>  <aside class="deprecated"><strong>Deprecated:</strong><span> SOME ARGUMENTS ARE DEPRECATED: <code translate="no" dir="ltr">(experimental_compile)</code>. They will be removed in a future version. Instructions for updating: experimental_compile is deprecated, use jit_compile instead</span></aside><aside class="deprecated"><strong>Deprecated:</strong><span> SOME ARGUMENTS ARE DEPRECATED: <code translate="no" dir="ltr">(experimental_relax_shapes)</code>. They will be removed in a future version. Instructions for updating: experimental_relax_shapes is deprecated, use reduce_retracing instead</span></aside> <p><a href="function"><code translate="no" dir="ltr">tf.function</code></a> constructs a <a href="types/experimental/genericfunction"><code translate="no" dir="ltr">tf.types.experimental.GenericFunction</code></a> that executes a TensorFlow graph (<a href="graph"><code translate="no" dir="ltr">tf.Graph</code></a>) created by trace-compiling the TensorFlow operations in <code translate="no" dir="ltr">func</code>. More information on the topic can be found in <a href="https://www.tensorflow.org/guide/intro_to_graphs">Introduction to Graphs and tf.function</a>.</p> <p>See <a href="https://www.tensorflow.org/guide/function">Better Performance with tf.function</a> for tips on performance and known limitations.</p> <h4 id="example_usage" data-text="Example usage:">Example usage:</h4> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="cpp">
@tf.function
def f(x, y):
  return x ** 2 + y
x = tf.constant([2, 3])
y = tf.constant([3, -2])
f(x, y)
&lt;tf.Tensor: ... numpy=array([7, 7], ...)&gt;
</pre> <p>The trace-compilation allows non-TensorFlow operations to execute, but under special conditions. In general, only TensorFlow operations are guaranteed to run and create fresh results whenever the <code translate="no" dir="ltr">GenericFunction</code> is called.</p> <h2 id="features" data-text="Features">Features</h2> <p><code translate="no" dir="ltr">func</code> may use data-dependent Python control flow statements, including <code translate="no" dir="ltr">if</code>, <code translate="no" dir="ltr">for</code>, <code translate="no" dir="ltr">while</code> <code translate="no" dir="ltr">break</code>, <code translate="no" dir="ltr">continue</code> and <code translate="no" dir="ltr">return</code>:</p> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="cpp">
@tf.function
def f(x):
  if tf.reduce_sum(x) &gt; 0:
    return x * x
  else:
    return -x // 2
f(tf.constant(-2))
&lt;tf.Tensor: ... numpy=1&gt;
</pre> <p><code translate="no" dir="ltr">func</code>'s closure may include <a href="tensor"><code translate="no" dir="ltr">tf.Tensor</code></a> and <a href="variable"><code translate="no" dir="ltr">tf.Variable</code></a> objects:</p> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="cpp">
@tf.function
def f():
  return x ** 2 + y
x = tf.constant([-2, -3])
y = tf.Variable([3, -2])
f()
&lt;tf.Tensor: ... numpy=array([7, 7], ...)&gt;
</pre> <p><code translate="no" dir="ltr">func</code> may also use ops with side effects, such as <a href="print"><code translate="no" dir="ltr">tf.print</code></a>, <a href="variable"><code translate="no" dir="ltr">tf.Variable</code></a> and others:</p> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="cpp">
v = tf.Variable(1)
@tf.function
def f(x):
  for i in tf.range(x):
    v.assign_add(i)
f(3)
v
&lt;tf.Variable ... numpy=4&gt;
</pre> <aside class="special"><strong>Important:</strong><span> Any Python side-effects (appending to a list, printing with <code translate="no" dir="ltr">print</code>, etc) will only happen once, when <code translate="no" dir="ltr">func</code> is traced. To have side-effects executed into your <a href="function"><code translate="no" dir="ltr">tf.function</code></a> they need to be written as TF ops:</span></aside> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="cpp">
l = []
@tf.function
def f(x):
  for i in x:
    l.append(i + 1)    # Caution! Will only happen once when tracing
f(tf.constant([1, 2, 3]))
l
[&lt;tf.Tensor ...&gt;]
</pre> <p>Instead, use TensorFlow collections like <a href="tensorarray"><code translate="no" dir="ltr">tf.TensorArray</code></a>:</p> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="cpp">
@tf.function
def f(x):
  ta = tf.TensorArray(dtype=tf.int32, size=0, dynamic_size=True)
  for i in range(len(x)):
    ta = ta.write(i, x[i] + 1)
  return ta.stack()
f(tf.constant([1, 2, 3]))
&lt;tf.Tensor: ..., numpy=array([2, 3, 4], ...)&gt;
</pre> <h2 id="tffunction_creates_polymorphic_callables" data-text="tf.function creates polymorphic callables">
<a href="function"><code translate="no" dir="ltr">tf.function</code></a> creates polymorphic callables</h2> <p>Internally, <a href="types/experimental/genericfunction"><code translate="no" dir="ltr">tf.types.experimental.GenericFunction</code></a> may contain multiple <a href="types/experimental/concretefunction"><code translate="no" dir="ltr">tf.types.experimental.ConcreteFunction</code></a>s, each specialized to arguments with different data types or shapes, since TensorFlow can perform more optimizations on graphs of specific shapes, dtypes and values of constant arguments. <a href="function"><code translate="no" dir="ltr">tf.function</code></a> treats any pure Python values as opaque objects (best thought of as compile-time constants), and builds a separate <a href="graph"><code translate="no" dir="ltr">tf.Graph</code></a> for each set of Python arguments that it encounters. For more information, see the <a href="https://www.tensorflow.org/guide/function#rules_of_tracing">tf.function guide</a></p> <p>Executing a <code translate="no" dir="ltr">GenericFunction</code> will select and execute the appropriate <code translate="no" dir="ltr">ConcreteFunction</code> based on the argument types and values.</p> <p>To obtain an individual <code translate="no" dir="ltr">ConcreteFunction</code>, use the <a href="types/experimental/genericfunction#get_concrete_function"><code translate="no" dir="ltr">GenericFunction.get_concrete_function</code></a> method. It can be called with the same arguments as <code translate="no" dir="ltr">func</code> and returns a <a href="types/experimental/concretefunction"><code translate="no" dir="ltr">tf.types.experimental.ConcreteFunction</code></a>. <code translate="no" dir="ltr">ConcreteFunction</code>s are backed by a single <a href="graph"><code translate="no" dir="ltr">tf.Graph</code></a>:</p> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="cpp">
@tf.function
def f(x):
  return x + 1
isinstance(f.get_concrete_function(1).graph, tf.Graph)
True
</pre> <p><code translate="no" dir="ltr">ConcreteFunction</code>s can be executed just like <code translate="no" dir="ltr">GenericFunction</code>s, but their input is resticted to the types to which they're specialized.</p> <h2 id="retracing" data-text="Retracing">Retracing</h2> <p><code translate="no" dir="ltr">ConcreteFunctions</code> are built (traced) on the fly, as the <code translate="no" dir="ltr">GenericFunction</code> is called with new TensorFlow types or shapes, or with new Python values as arguments. When <code translate="no" dir="ltr">GenericFunction</code> builds a new trace, it is said that <code translate="no" dir="ltr">func</code> is retraced. Retracing is a frequent performance concern for <a href="function"><code translate="no" dir="ltr">tf.function</code></a> as it can be considerably slower than executing a graph that's already been traced. It is ideal to minimize the amount of retracing in your code.</p> <aside class="caution"><strong>Caution:</strong><span> Passing python scalars or lists as arguments to <a href="function"><code translate="no" dir="ltr">tf.function</code></a> will usually retrace. To avoid this, pass numeric arguments as Tensors whenever possible:</span></aside> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="cpp">
@tf.function
def f(x):
  return tf.abs(x)
f1 = f.get_concrete_function(1)
f2 = f.get_concrete_function(2)  # Slow - compiles new graph
f1 is f2
False
f1 = f.get_concrete_function(tf.constant(1))
f2 = f.get_concrete_function(tf.constant(2))  # Fast - reuses f1
f1 is f2
True
</pre> <p>Python numerical arguments should only be used when they take few distinct values, such as hyperparameters like the number of layers in a neural network.</p> <h2 id="input_signatures" data-text="Input signatures">Input signatures</h2> <p>For Tensor arguments, <code translate="no" dir="ltr">GenericFunction</code>creates a new <code translate="no" dir="ltr">ConcreteFunction</code> for every unique set of input shapes and datatypes. The example below creates two separate <code translate="no" dir="ltr">ConcreteFunction</code>s, each specialized to a different shape:</p> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="cpp">
@tf.function
def f(x):
  return x + 1
vector = tf.constant([1.0, 1.0])
matrix = tf.constant([[3.0]])
f.get_concrete_function(vector) is f.get_concrete_function(matrix)
False
</pre> <p>An "input signature" can be optionally provided to <a href="function"><code translate="no" dir="ltr">tf.function</code></a> to control this process. The input signature specifies the shape and type of each Tensor argument to the function using a <a href="tensorspec"><code translate="no" dir="ltr">tf.TensorSpec</code></a> object. More general shapes can be used. This ensures only one <code translate="no" dir="ltr">ConcreteFunction</code> is created, and restricts the <code translate="no" dir="ltr">GenericFunction</code> to the specified shapes and types. It is an effective way to limit retracing when Tensors have dynamic shapes.</p> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="cpp">
@tf.function(
    input_signature=[tf.TensorSpec(shape=None, dtype=tf.float32)])
def f(x):
  return x + 1
vector = tf.constant([1.0, 1.0])
matrix = tf.constant([[3.0]])
f.get_concrete_function(vector) is f.get_concrete_function(matrix)
True
</pre> <h2 id="variables_may_only_be_created_once" data-text="Variables may only be created once">Variables may only be created once</h2> <p><a href="function"><code translate="no" dir="ltr">tf.function</code></a> only allows creating new <a href="variable"><code translate="no" dir="ltr">tf.Variable</code></a> objects when it is called for the first time:</p> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="cpp">
class MyModule(tf.Module):
  def __init__(self):
    self.v = None

  @tf.function
  def __call__(self, x):
    if self.v is None:
      self.v = tf.Variable(tf.ones_like(x))
    return self.v * x
</pre> <p>In general, it is recommended to create <a href="variable"><code translate="no" dir="ltr">tf.Variable</code></a>s outside of <a href="function"><code translate="no" dir="ltr">tf.function</code></a>. In simple cases, persisting state across <a href="function"><code translate="no" dir="ltr">tf.function</code></a> boundaries may be implemented using a pure functional style in which state is represented by <a href="tensor"><code translate="no" dir="ltr">tf.Tensor</code></a>s passed as arguments and returned as return values.</p> <p>Contrast the two styles below:</p> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="cpp">
state = tf.Variable(1)
@tf.function
def f(x):
  state.assign_add(x)
f(tf.constant(2))  # Non-pure functional style
state
&lt;tf.Variable ... numpy=3&gt;
</pre> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="cpp">
state = tf.constant(1)
@tf.function
def f(state, x):
  state += x
  return state
state = f(state, tf.constant(2))  # Pure functional style
state
&lt;tf.Tensor: ... numpy=3&gt;
</pre> <h2 id="python_operations_execute_only_once_per_trace" data-text="Python operations execute only once per trace">Python operations execute only once per trace</h2> <p><code translate="no" dir="ltr">func</code> may contain TensorFlow operations mixed with pure Python operations. However, when the function is executed, only the TensorFlow operations will run. The Python operations run only once, at trace time. If TensorFlow operations depend on results from Pyhton operations, those results will be frozen into the graph.</p> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="cpp">
@tf.function
def f(a, b):
  print('this runs at trace time; a is', a, 'and b is', b)
  return b
f(1, tf.constant(1))
this runs at trace time; a is 1 and b is Tensor("...", shape=(), dtype=int32)
&lt;tf.Tensor: shape=(), dtype=int32, numpy=1&gt;
</pre> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="cpp">
f(1, tf.constant(2))
&lt;tf.Tensor: shape=(), dtype=int32, numpy=2&gt;
</pre> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="cpp">
f(2, tf.constant(1))
this runs at trace time; a is 2 and b is Tensor("...", shape=(), dtype=int32)
&lt;tf.Tensor: shape=(), dtype=int32, numpy=1&gt;
</pre> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="cpp">
f(2, tf.constant(2))
&lt;tf.Tensor: shape=(), dtype=int32, numpy=2&gt;
</pre> <h2 id="using_type_annotations_to_improve_performance" data-text="Using type annotations to improve performance">Using type annotations to improve performance</h2> <p>'experimental_follow_type_hints` can be used along with type annotations to reduce retracing by automatically casting any Python values to <a href="tensor"><code translate="no" dir="ltr">tf.Tensor</code></a> (something that is not done by default, unless you use input signatures).</p> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="cpp">
@tf.function(experimental_follow_type_hints=True)
def f_with_hints(x: tf.Tensor):
  print('Tracing')
  return x
@tf.function(experimental_follow_type_hints=False)
def f_no_hints(x: tf.Tensor):
  print('Tracing')
  return x
f_no_hints(1)
Tracing
&lt;tf.Tensor: shape=(), dtype=int32, numpy=1&gt;
f_no_hints(2)
Tracing
&lt;tf.Tensor: shape=(), dtype=int32, numpy=2&gt;
f_with_hints(1)
Tracing
&lt;tf.Tensor: shape=(), dtype=int32, numpy=1&gt;
f_with_hints(2)
&lt;tf.Tensor: shape=(), dtype=int32, numpy=2&gt;
</pre>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Args</th></tr> 
<tr> <td> <code translate="no" dir="ltr">func</code> </td> <td> the function to be compiled. If <code translate="no" dir="ltr">func</code> is None, <a href="function"><code translate="no" dir="ltr">tf.function</code></a> returns a decorator that can be invoked with a single argument - <code translate="no" dir="ltr">func</code>. In other words, <code translate="no" dir="ltr">tf.function(input_signature=...)(func)</code> is equivalent to <a href="function"><code translate="no" dir="ltr">tf.function(func, input_signature=...)</code></a>. The former can be used as decorator. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">input_signature</code> </td> <td> A possibly nested sequence of <a href="tensorspec"><code translate="no" dir="ltr">tf.TensorSpec</code></a> objects specifying the shapes and dtypes of the Tensors that will be supplied to this function. If <code translate="no" dir="ltr">None</code>, a separate function is instantiated for each inferred input signature. If input_signature is specified, every input to <code translate="no" dir="ltr">func</code> must be a <code translate="no" dir="ltr">Tensor</code>, and <code translate="no" dir="ltr">func</code> cannot accept <code translate="no" dir="ltr">**kwargs</code>. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">autograph</code> </td> <td> Whether autograph should be applied on <code translate="no" dir="ltr">func</code> before tracing a graph. Data-dependent Python control flow statements require <code translate="no" dir="ltr">autograph=True</code>. For more information, see the <a href="https://www.tensorflow.org/guide/function#autograph_transformations">tf.function and AutoGraph guide</a>. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">jit_compile</code> </td> <td> If <code translate="no" dir="ltr">True</code>, compiles the function using <a href="https://tensorflow.org/xla">XLA</a>. XLA performs compiler optimizations, such as fusion, and attempts to emit more efficient code. This may drastically improve the performance. If set to <code translate="no" dir="ltr">True</code>, the whole function needs to be compilable by XLA, or an <a href="errors/invalidargumenterror"><code translate="no" dir="ltr">errors.InvalidArgumentError</code></a> is thrown. If <code translate="no" dir="ltr">None</code> (default), compiles the function with XLA when running on TPU and goes through the regular function execution path when running on other devices. If <code translate="no" dir="ltr">False</code>, executes the function without XLA compilation. Set this value to <code translate="no" dir="ltr">False</code> when directly running a multi-device function on TPUs (e.g. two TPU cores, one TPU core and its host CPU). Not all functions are compilable, see a list of <a href="https://tensorflow.org/xla/known_issues">sharp corners</a>. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">reduce_retracing</code> </td> <td> When True, <a href="function"><code translate="no" dir="ltr">tf.function</code></a> attempts to reduce the amount of retracing, for example by using more generic shapes. This can be controlled for user objects by customizing their associated <a href="types/experimental/tracetype"><code translate="no" dir="ltr">tf.types.experimental.TraceType</code></a>. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">experimental_implements</code> </td> <td> If provided, contains a name of a "known" function this implements. For example "mycompany.my_recurrent_cell". This is stored as an attribute in inference function, which can then be detected when processing serialized function. See <a href="https://github.com/tensorflow/community/blob/master/rfcs/20190610-standardizing-composite_ops.md">standardizing composite ops</a><br> for details. For an example of utilizing this attribute see this <a href="https://github.com/tensorflow/tensorflow/blob/master/tensorflow/compiler/mlir/lite/transforms/prepare_composite_functions_tf.cc">example</a> The code above automatically detects and substitutes function that implements "embedded_matmul" and allows TFLite to substitute its own implementations. For instance, a tensorflow user can use this attribute to mark that their function also implements <code translate="no" dir="ltr">embedded_matmul</code> (perhaps more efficiently!) by specifying it using this parameter: <code translate="no" dir="ltr">@tf.function(experimental_implements="embedded_matmul")</code> This can either be specified as just the string name of the function or a NameAttrList corresponding to a list of key-value attributes associated with the function name. The name of the function will be in the 'name' field of the NameAttrList. To define a formal TF op for this function implements, try the experimental <a href="https://github.com/tensorflow/tensorflow/blob/master/tensorflow/compiler/mlir/tfr">composite TF</a> project. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">experimental_autograph_options</code> </td> <td> Optional tuple of <a href="autograph/experimental/feature"><code translate="no" dir="ltr">tf.autograph.experimental.Feature</code></a> values. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">experimental_relax_shapes</code> </td> <td> Deprecated. Use <code translate="no" dir="ltr">reduce_retracing</code> instead. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">experimental_compile</code> </td> <td> Deprecated alias to 'jit_compile'. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">experimental_follow_type_hints</code> </td> <td> When True, the function may use type annotations from <code translate="no" dir="ltr">func</code> to optimize the tracing performance. For example, arguments annotated with <a href="tensor"><code translate="no" dir="ltr">tf.Tensor</code></a> will automatically be converted to a Tensor. </td> </tr> </table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Returns</th></tr> <tr class="alt"> <td colspan="2"> If <code translate="no" dir="ltr">func</code> is not None, returns a <a href="types/experimental/genericfunction"><code translate="no" dir="ltr">tf.types.experimental.GenericFunction</code></a>. If <code translate="no" dir="ltr">func</code> is None, returns a decorator that, when invoked with a single <code translate="no" dir="ltr">func</code> argument, returns a <a href="types/experimental/genericfunction"><code translate="no" dir="ltr">tf.types.experimental.GenericFunction</code></a>. </td> </tr> 
</table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Raises</th></tr> <tr class="alt"> <td colspan="2"> <code translate="no" dir="ltr">ValueError</code> when attempting to use <code translate="no" dir="ltr">jit_compile=True</code>, but XLA support is not available. </td> </tr> 
</table>  <devsite-thumb-rating position="footer"> </devsite-thumb-rating><div class="_attribution">
  <p class="_attribution-p">
    Â© 2022 The TensorFlow Authors. All rights reserved.<br>Licensed under the Creative Commons Attribution License 4.0.<br>Code samples licensed under the Apache 2.0 License.<br>
    <a href="https://www.tensorflow.org/versions/r2.9/api_docs/python/tf/function" class="_attribution-link">https://www.tensorflow.org/versions/r2.9/api_docs/python/tf/function</a>
  </p>
</div>

				
			</div>
			<ins class="adsbygoogle"
     style="display:block"
     data-ad-client="ca-pub-2572770204602497"
     data-ad-slot="1992473792"
     data-ad-format="auto"
     data-full-width-responsive="true"></ins>
<script>
     (adsbygoogle = window.adsbygoogle || []).push({});
</script>
		</div>
	</section>

	</div>
	<svg style="display:none">
		<symbol id="icon-dir"><svg viewBox="0 0 20 20"><path d="M15 10c0 .3-.305.515-.305.515l-8.56 5.303c-.625.41-1.135.106-1.135-.67V4.853c0-.777.51-1.078 1.135-.67l8.56 5.305S15 9.702 15 10z"/></svg></symbol>
	  </svg>
</body>
</html>
