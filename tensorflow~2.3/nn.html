
<!DOCTYPE HTML>

<html lang="en" class="_theme-default">

<head>
  <meta charset="utf-8">
  <title>tf.nn - TensorFlow 2.3 - W3cubDocs</title>
  
  <meta name="description" content=" Wrappers for primitive Neural Net (NN) Operations. ">
  <meta name="keywords" content="module, tf, nn, tensorflow, tensorflow~2.3">
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="mobile-web-app-capable" content="yes">
  
  <link rel="canonical" href="https://docs.w3cub.com/tensorflow~2.3/nn.html">
  <link href="/favicon.png" rel="icon">
  <link rel="stylesheet" type="text/css" href="/assets/application-01fda2ddb8339756caccf7add5ad4cf849ab52d069bd799015c7f04f93164f64753bff0d15a49d8060b1e66e41002bb301ccadc2350937df079cea3cd52d3cca.css">
  <script src="/assets/application-d9be6f56a823612443fc15b2e027a630e02c4ad2685bb750d13fa4fae28d46c3e7f7ebb69bd4bafddf116f218f9372e9be44021d4247dc20424e2fd1ff8cef81.js" type="text/javascript"></script>
  <script src="/json/tensorflow~2.3.js"></script>
  
  <script type="text/javascript">
    var _gaq = _gaq || [];
    _gaq.push(['_setAccount', 'UA-71174418-1']);
    _gaq.push(['_trackPageview']);

    (function() {
      var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
      ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
      var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
    })();
  </script>
  <script data-ad-client="ca-pub-2572770204602497" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script async custom-element="amp-auto-ads"
  src="https://cdn.ampproject.org/v0/amp-auto-ads-0.1.js">
</script>


</head>

<body class="docs">
	<amp-auto-ads type="adsense"
              data-ad-client="ca-pub-2572770204602497">
	</amp-auto-ads>
	<div class="_app">
	<header class="_header">

  <a class="_home-link" href="/" ></a>
  <a class="_menu-link"></a>
  <h1 class="_logo">
    <a href="/" class="_nav-link" title="API Documentation Browser">W3cubDocs</a>
  </h1>
  
  <span class="_logo-sub-nav">/</span><span class="_logo-sub-nav"><a href="/tensorflow~2.3/" class="_nav-link" title="" style="margin-left:0;">TensorFlow 2.3</a></span>
  
  <nav class="_nav">
    <a href="https://tools.w3cub.com/?_sp=docs" target="_blank" class="_nav-link ">W3cubTools</a>
    <a href="/cheatsheets/" class="_nav-link ">Cheatsheets</a>
    <a href="/about/" class="_nav-link ">About</a>
  </nav>
</header>
	<section class="_sidebar">
		
		<form class="_search">
		  <input type="search" class="_search-input" placeholder="Search&hellip;" autocomplete="off" autocapitalize="off" autocorrect="off" spellcheck="false" maxlength="20">
		  <a class="_search-clear"></a>
		  <div class="_search-tag"></div>
		</form>
		
		<div class="_list-wrap">
			<div class="_list">
			
			</div>
		</div>
	</section>
	<section class="_container ">
		<div class="_content">
			<ins class="adsbygoogle"
     style="display:block"
     data-ad-client="ca-pub-2572770204602497"
     data-ad-slot="6861657091"
     data-ad-format="link"
     data-full-width-responsive="true"></ins>
<script>
     (adsbygoogle = window.adsbygoogle || []).push({});
</script>
			<div class="_page _tensorflow">
				
				
<h1 class="devsite-page-title">Module: tf.nn</h1>       <p>Wrappers for primitive Neural Net (NN) Operations.</p> <h2 id="classes" data-text="Classes" tabindex="0">Classes</h2> <p><a href="nn/rnncelldevicewrapper"><code translate="no" dir="ltr">class RNNCellDeviceWrapper</code></a>: Operator that ensures an RNNCell runs on a particular device.</p> <p><a href="nn/rnncelldropoutwrapper"><code translate="no" dir="ltr">class RNNCellDropoutWrapper</code></a>: Operator adding dropout to inputs and outputs of the given cell.</p> <p><a href="nn/rnncellresidualwrapper"><code translate="no" dir="ltr">class RNNCellResidualWrapper</code></a>: RNNCell wrapper that ensures cell inputs are added to the outputs.</p> <h2 id="functions" data-text="Functions" tabindex="0">Functions</h2> <p><a href="random/all_candidate_sampler"><code translate="no" dir="ltr">all_candidate_sampler(...)</code></a>: Generate the set of all classes.</p> <p><a href="nn/atrous_conv2d"><code translate="no" dir="ltr">atrous_conv2d(...)</code></a>: Atrous convolution (a.k.a. convolution with holes or dilated convolution).</p> <p><a href="nn/atrous_conv2d_transpose"><code translate="no" dir="ltr">atrous_conv2d_transpose(...)</code></a>: The transpose of <code translate="no" dir="ltr">atrous_conv2d</code>.</p> <p><a href="nn/avg_pool"><code translate="no" dir="ltr">avg_pool(...)</code></a>: Performs the avg pooling on the input.</p> <p><a href="nn/avg_pool1d"><code translate="no" dir="ltr">avg_pool1d(...)</code></a>: Performs the average pooling on the input.</p> <p><a href="nn/avg_pool2d"><code translate="no" dir="ltr">avg_pool2d(...)</code></a>: Performs the average pooling on the input.</p> <p><a href="nn/avg_pool3d"><code translate="no" dir="ltr">avg_pool3d(...)</code></a>: Performs the average pooling on the input.</p> <p><a href="nn/batch_norm_with_global_normalization"><code translate="no" dir="ltr">batch_norm_with_global_normalization(...)</code></a>: Batch normalization.</p> <p><a href="nn/batch_normalization"><code translate="no" dir="ltr">batch_normalization(...)</code></a>: Batch normalization.</p> <p><a href="nn/bias_add"><code translate="no" dir="ltr">bias_add(...)</code></a>: Adds <code translate="no" dir="ltr">bias</code> to <code translate="no" dir="ltr">value</code>.</p> <p><a href="nn/collapse_repeated"><code translate="no" dir="ltr">collapse_repeated(...)</code></a>: Merge repeated labels into single labels.</p> <p><a href="nn/compute_accidental_hits"><code translate="no" dir="ltr">compute_accidental_hits(...)</code></a>: Compute the position ids in <code translate="no" dir="ltr">sampled_candidates</code> matching <code translate="no" dir="ltr">true_classes</code>.</p> <p><a href="nn/compute_average_loss"><code translate="no" dir="ltr">compute_average_loss(...)</code></a>: Scales per-example losses with sample_weights and computes their average.</p> <p><a href="nn/conv1d"><code translate="no" dir="ltr">conv1d(...)</code></a>: Computes a 1-D convolution given 3-D input and filter tensors.</p> <p><a href="nn/conv1d_transpose"><code translate="no" dir="ltr">conv1d_transpose(...)</code></a>: The transpose of <code translate="no" dir="ltr">conv1d</code>.</p> <p><a href="nn/conv2d"><code translate="no" dir="ltr">conv2d(...)</code></a>: Computes a 2-D convolution given <code translate="no" dir="ltr">input</code> and 4-D <code translate="no" dir="ltr">filters</code> tensors.</p> <p><a href="nn/conv2d_transpose"><code translate="no" dir="ltr">conv2d_transpose(...)</code></a>: The transpose of <code translate="no" dir="ltr">conv2d</code>.</p> <p><a href="nn/conv3d"><code translate="no" dir="ltr">conv3d(...)</code></a>: Computes a 3-D convolution given 5-D <code translate="no" dir="ltr">input</code> and <code translate="no" dir="ltr">filters</code> tensors.</p> <p><a href="nn/conv3d_transpose"><code translate="no" dir="ltr">conv3d_transpose(...)</code></a>: The transpose of <code translate="no" dir="ltr">conv3d</code>.</p> <p><a href="nn/conv_transpose"><code translate="no" dir="ltr">conv_transpose(...)</code></a>: The transpose of <code translate="no" dir="ltr">convolution</code>.</p> <p><a href="nn/convolution"><code translate="no" dir="ltr">convolution(...)</code></a>: Computes sums of N-D convolutions (actually cross-correlation).</p> <p><a href="nn/crelu"><code translate="no" dir="ltr">crelu(...)</code></a>: Computes Concatenated ReLU.</p> <p><a href="nn/ctc_beam_search_decoder"><code translate="no" dir="ltr">ctc_beam_search_decoder(...)</code></a>: Performs beam search decoding on the logits given in input.</p> <p><a href="nn/ctc_greedy_decoder"><code translate="no" dir="ltr">ctc_greedy_decoder(...)</code></a>: Performs greedy decoding on the logits given in input (best path).</p> <p><a href="nn/ctc_loss"><code translate="no" dir="ltr">ctc_loss(...)</code></a>: Computes CTC (Connectionist Temporal Classification) loss.</p> <p><a href="nn/ctc_unique_labels"><code translate="no" dir="ltr">ctc_unique_labels(...)</code></a>: Get unique labels and indices for batched labels for <a href="nn/ctc_loss"><code translate="no" dir="ltr">tf.nn.ctc_loss</code></a>.</p> <p><a href="nn/depth_to_space"><code translate="no" dir="ltr">depth_to_space(...)</code></a>: DepthToSpace for tensors of type T.</p> <p><a href="nn/depthwise_conv2d"><code translate="no" dir="ltr">depthwise_conv2d(...)</code></a>: Depthwise 2-D convolution.</p> <p><a href="nn/depthwise_conv2d_backprop_filter"><code translate="no" dir="ltr">depthwise_conv2d_backprop_filter(...)</code></a>: Computes the gradients of depthwise convolution with respect to the filter.</p> <p><a href="nn/depthwise_conv2d_backprop_input"><code translate="no" dir="ltr">depthwise_conv2d_backprop_input(...)</code></a>: Computes the gradients of depthwise convolution with respect to the input.</p> <p><a href="nn/dilation2d"><code translate="no" dir="ltr">dilation2d(...)</code></a>: Computes the grayscale dilation of 4-D <code translate="no" dir="ltr">input</code> and 3-D <code translate="no" dir="ltr">filters</code> tensors.</p> <p><a href="nn/dropout"><code translate="no" dir="ltr">dropout(...)</code></a>: Computes dropout: randomly sets elements to zero to prevent overfitting.</p> <p><a href="nn/elu"><code translate="no" dir="ltr">elu(...)</code></a>: Computes exponential linear: <code translate="no" dir="ltr">exp(features) - 1</code> if &lt; 0, <code translate="no" dir="ltr">features</code> otherwise.</p> <p><a href="nn/embedding_lookup"><code translate="no" dir="ltr">embedding_lookup(...)</code></a>: Looks up embeddings for the given <code translate="no" dir="ltr">ids</code> from a list of tensors.</p> <p><a href="nn/embedding_lookup_sparse"><code translate="no" dir="ltr">embedding_lookup_sparse(...)</code></a>: Looks up embeddings for the given ids and weights from a list of tensors.</p> <p><a href="nn/erosion2d"><code translate="no" dir="ltr">erosion2d(...)</code></a>: Computes the grayscale erosion of 4-D <code translate="no" dir="ltr">value</code> and 3-D <code translate="no" dir="ltr">filters</code> tensors.</p> <p><a href="random/fixed_unigram_candidate_sampler"><code translate="no" dir="ltr">fixed_unigram_candidate_sampler(...)</code></a>: Samples a set of classes using the provided (fixed) base distribution.</p> <p><a href="nn/fractional_avg_pool"><code translate="no" dir="ltr">fractional_avg_pool(...)</code></a>: Performs fractional average pooling on the input.</p> <p><a href="nn/fractional_max_pool"><code translate="no" dir="ltr">fractional_max_pool(...)</code></a>: Performs fractional max pooling on the input.</p> <p><a href="math/in_top_k"><code translate="no" dir="ltr">in_top_k(...)</code></a>: Says whether the targets are in the top <code translate="no" dir="ltr">K</code> predictions.</p> <p><a href="nn/l2_loss"><code translate="no" dir="ltr">l2_loss(...)</code></a>: L2 Loss.</p> <p><a href="math/l2_normalize"><code translate="no" dir="ltr">l2_normalize(...)</code></a>: Normalizes along dimension <code translate="no" dir="ltr">axis</code> using an L2 norm.</p> <p><a href="nn/leaky_relu"><code translate="no" dir="ltr">leaky_relu(...)</code></a>: Compute the Leaky ReLU activation function.</p> <p><a href="random/learned_unigram_candidate_sampler"><code translate="no" dir="ltr">learned_unigram_candidate_sampler(...)</code></a>: Samples a set of classes from a distribution learned during training.</p> <p><a href="nn/local_response_normalization"><code translate="no" dir="ltr">local_response_normalization(...)</code></a>: Local Response Normalization.</p> <p><a href="nn/log_poisson_loss"><code translate="no" dir="ltr">log_poisson_loss(...)</code></a>: Computes log Poisson loss given <code translate="no" dir="ltr">log_input</code>.</p> <p><a href="nn/log_softmax"><code translate="no" dir="ltr">log_softmax(...)</code></a>: Computes log softmax activations.</p> <p><a href="nn/local_response_normalization"><code translate="no" dir="ltr">lrn(...)</code></a>: Local Response Normalization.</p> <p><a href="nn/max_pool"><code translate="no" dir="ltr">max_pool(...)</code></a>: Performs the max pooling on the input.</p> <p><a href="nn/max_pool1d"><code translate="no" dir="ltr">max_pool1d(...)</code></a>: Performs the max pooling on the input.</p> <p><a href="nn/max_pool2d"><code translate="no" dir="ltr">max_pool2d(...)</code></a>: Performs the max pooling on the input.</p> <p><a href="nn/max_pool3d"><code translate="no" dir="ltr">max_pool3d(...)</code></a>: Performs the max pooling on the input.</p> <p><a href="nn/max_pool_with_argmax"><code translate="no" dir="ltr">max_pool_with_argmax(...)</code></a>: Performs max pooling on the input and outputs both max values and indices.</p> <p><a href="nn/moments"><code translate="no" dir="ltr">moments(...)</code></a>: Calculates the mean and variance of <code translate="no" dir="ltr">x</code>.</p> <p><a href="nn/nce_loss"><code translate="no" dir="ltr">nce_loss(...)</code></a>: Computes and returns the noise-contrastive estimation training loss.</p> <p><a href="nn/normalize_moments"><code translate="no" dir="ltr">normalize_moments(...)</code></a>: Calculate the mean and variance of based on the sufficient statistics.</p> <p><a href="nn/pool"><code translate="no" dir="ltr">pool(...)</code></a>: Performs an N-D pooling operation.</p> <p><a href="nn/relu"><code translate="no" dir="ltr">relu(...)</code></a>: Computes rectified linear: <code translate="no" dir="ltr">max(features, 0)</code>.</p> <p><a href="nn/relu6"><code translate="no" dir="ltr">relu6(...)</code></a>: Computes Rectified Linear 6: <code translate="no" dir="ltr">min(max(features, 0), 6)</code>.</p> <p><a href="nn/safe_embedding_lookup_sparse"><code translate="no" dir="ltr">safe_embedding_lookup_sparse(...)</code></a>: Lookup embedding results, accounting for invalid IDs and empty features.</p> <p><a href="nn/sampled_softmax_loss"><code translate="no" dir="ltr">sampled_softmax_loss(...)</code></a>: Computes and returns the sampled softmax training loss.</p> <p><a href="nn/scale_regularization_loss"><code translate="no" dir="ltr">scale_regularization_loss(...)</code></a>: Scales the sum of the given regularization losses by number of replicas.</p> <p><a href="nn/selu"><code translate="no" dir="ltr">selu(...)</code></a>: Computes scaled exponential linear: <code translate="no" dir="ltr">scale * alpha * (exp(features) - 1)</code></p> <p><a href="nn/separable_conv2d"><code translate="no" dir="ltr">separable_conv2d(...)</code></a>: 2-D convolution with separable filters.</p> <p><a href="math/sigmoid"><code translate="no" dir="ltr">sigmoid(...)</code></a>: Computes sigmoid of <code translate="no" dir="ltr">x</code> element-wise.</p> <p><a href="nn/sigmoid_cross_entropy_with_logits"><code translate="no" dir="ltr">sigmoid_cross_entropy_with_logits(...)</code></a>: Computes sigmoid cross entropy given <code translate="no" dir="ltr">logits</code>.</p> <p><a href="nn/softmax"><code translate="no" dir="ltr">softmax(...)</code></a>: Computes softmax activations.</p> <p><a href="nn/softmax_cross_entropy_with_logits"><code translate="no" dir="ltr">softmax_cross_entropy_with_logits(...)</code></a>: Computes softmax cross entropy between <code translate="no" dir="ltr">logits</code> and <code translate="no" dir="ltr">labels</code>.</p> <p><a href="math/softplus"><code translate="no" dir="ltr">softplus(...)</code></a>: Computes softplus: <code translate="no" dir="ltr">log(exp(features) + 1)</code>.</p> <p><a href="nn/softsign"><code translate="no" dir="ltr">softsign(...)</code></a>: Computes softsign: <code translate="no" dir="ltr">features / (abs(features) + 1)</code>.</p> <p><a href="space_to_batch"><code translate="no" dir="ltr">space_to_batch(...)</code></a>: SpaceToBatch for N-D tensors of type T.</p> <p><a href="nn/space_to_depth"><code translate="no" dir="ltr">space_to_depth(...)</code></a>: SpaceToDepth for tensors of type T.</p> <p><a href="nn/sparse_softmax_cross_entropy_with_logits"><code translate="no" dir="ltr">sparse_softmax_cross_entropy_with_logits(...)</code></a>: Computes sparse softmax cross entropy between <code translate="no" dir="ltr">logits</code> and <code translate="no" dir="ltr">labels</code>.</p> <p><a href="nn/sufficient_statistics"><code translate="no" dir="ltr">sufficient_statistics(...)</code></a>: Calculate the sufficient statistics for the mean and variance of <code translate="no" dir="ltr">x</code>.</p> <p><a href="nn/swish"><code translate="no" dir="ltr">swish(...)</code></a>: Computes the Swish activation function: <code translate="no" dir="ltr">x * sigmoid(x)</code>.</p> <p><a href="math/tanh"><code translate="no" dir="ltr">tanh(...)</code></a>: Computes hyperbolic tangent of <code translate="no" dir="ltr">x</code> element-wise.</p> <p><a href="math/top_k"><code translate="no" dir="ltr">top_k(...)</code></a>: Finds values and indices of the <code translate="no" dir="ltr">k</code> largest entries for the last dimension.</p> <p><a href="nn/weighted_cross_entropy_with_logits"><code translate="no" dir="ltr">weighted_cross_entropy_with_logits(...)</code></a>: Computes a weighted cross entropy.</p> <p><a href="nn/weighted_moments"><code translate="no" dir="ltr">weighted_moments(...)</code></a>: Returns the frequency-weighted mean and variance of <code translate="no" dir="ltr">x</code>.</p> <p><a href="nn/with_space_to_batch"><code translate="no" dir="ltr">with_space_to_batch(...)</code></a>: Performs <code translate="no" dir="ltr">op</code> on the space-to-batch representation of <code translate="no" dir="ltr">input</code>.</p> <p><a href="math/zero_fraction"><code translate="no" dir="ltr">zero_fraction(...)</code></a>: Returns the fraction of zeros in <code translate="no" dir="ltr">value</code>.</p>  <devsite-page-rating position="footer" selected-rating="0" hover-rating-star="0"> </devsite-page-rating><div class="_attribution">
  <p class="_attribution-p">
    Â© 2020 The TensorFlow Authors. All rights reserved.<br>Licensed under the Creative Commons Attribution License 3.0.<br>Code samples licensed under the Apache 2.0 License.<br>
    <a href="https://www.tensorflow.org/versions/r2.3/api_docs/python/tf/nn" class="_attribution-link">https://www.tensorflow.org/versions/r2.3/api_docs/python/tf/nn</a>
  </p>
</div>

				
			</div>
			<ins class="adsbygoogle"
     style="display:block"
     data-ad-client="ca-pub-2572770204602497"
     data-ad-slot="1992473792"
     data-ad-format="auto"
     data-full-width-responsive="true"></ins>
<script>
     (adsbygoogle = window.adsbygoogle || []).push({});
</script>
		</div>
	</section>

	</div>
	<svg style="display:none">
		<symbol id="icon-dir"><svg viewBox="0 0 20 20"><path d="M15 10c0 .3-.305.515-.305.515l-8.56 5.303c-.625.41-1.135.106-1.135-.67V4.853c0-.777.51-1.078 1.135-.67l8.56 5.305S15 9.702 15 10z"/></svg></symbol>
	  </svg>
</body>
</html>
