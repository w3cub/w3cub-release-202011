
<!DOCTYPE HTML>

<html lang="en" class="_theme-default">

<head>
  <meta charset="utf-8">
  <title>Example&#58; Formulas&#58; Fitting Models Using R-style Formulas - Statsmodels - W3cubDocs</title>
  
  <meta name="description" content="Since version 0.5.0, statsmodels allows users to fit statistical models using R-style formulas. Internally, statsmodels uses the patsy package to &hellip;">
  <meta name="keywords" content="formulas, fitting, models, using, r-style, example, statsmodels">
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="mobile-web-app-capable" content="yes">
  
  <link rel="canonical" href="https://docs.w3cub.com/statsmodels/examples/notebooks/generated/formulas.html">
  <link href="/favicon.png" rel="icon">
  <link rel="stylesheet" type="text/css" href="/assets/application-e4ebd3a2a5652ff55173659804c4390a004917f3bdd17b5bb3ba78ea5c9c46fe181cadaac34517ccd815f5bdc982bbfe67179d6f4ac2f084ef2265e2a3dc8dc5.css" integrity="sha512-5OvToqVlL/VRc2WYBMQ5CgBJF/O90Xtbs7p46lycRv4YHK2qw0UXzNgV9b3Jgrv+Zxedb0rC8ITvImXio9yNxQ==" crossorigin="anonymous">
  <script type="text/javascript" integrity="sha512-EpkDeu98lN/jPKijllzVWdRg/dUSSMCaldYZNFz6bcNoBvpWRNz0HSTRQJ3ENmQc5Cuj1zDW1vHd7b0DzpOgyA==" crossorigin="anonymous" src="/assets/application-1299037aef7c94dfe33ca8a3965cd559d460fdd51248c09a95d619345cfa6dc36806fa5644dcf41d24d1409dc436641ce42ba3d730d6d6f1ddedbd03ce93a0c8.js"></script>
  <script src="/json/statsmodels.js"></script>
  
  <script type="text/javascript">
    var _gaq = _gaq || [];
    _gaq.push(['_setAccount', 'UA-71174418-1']);
    _gaq.push(['_trackPageview']);

    (function() {
      var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
      ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
      var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
    })();
  </script>
  <script data-ad-client="ca-pub-2572770204602497" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script async custom-element="amp-auto-ads"
  src="https://cdn.ampproject.org/v0/amp-auto-ads-0.1.js">
</script>


</head>

<body>
	<amp-auto-ads type="adsense"
              data-ad-client="ca-pub-2572770204602497">
	</amp-auto-ads>
	<div class="_app">
	<header class="_header">
  
  <form class="_search">
    <input type="search" class="_search-input" placeholder="Search&hellip;" autocomplete="off" autocapitalize="off" autocorrect="off" spellcheck="false" maxlength="20">
    <a class="_search-clear"></a>
    <div class="_search-tag"></div>
  </form>
  
  <a class="_home-link" href="/" ></a>
  <a class="_menu-link"></a>
  <h1 class="_logo">
    <a href="/" class="_nav-link" title="API Documentation Browser">W3cubDocs</a>
  </h1>
  
  <span class="_logo-sub-nav">/</span><span class="_logo-sub-nav"><a href="/statsmodels/" class="_nav-link" title="" style="margin-left:0;">Statsmodels</a></span>
  
  <nav class="_nav">
    <a href="https://tools.w3cub.com/?_sp=docs" target="_blank" class="_nav-link ">W3cubTools</a>
    <a href="/cheatsheets/" class="_nav-link ">Cheatsheets</a>
    <a href="/about/" class="_nav-link ">About</a>
  </nav>
</header>
	<section class="_sidebar">
		<div class="_list-wrap">
			<div class="_list">
			
			</div>
		</div>
	</section>
	<section class="_container ">
		<div class="_content">
			<ins class="adsbygoogle"
     style="display:block"
     data-ad-client="ca-pub-2572770204602497"
     data-ad-slot="6861657091"
     data-ad-format="link"
     data-full-width-responsive="true"></ins>
<script>
     (adsbygoogle = window.adsbygoogle || []).push({});
</script>
			<div class="_page _sphinx">
				
				
<h1 id="Formulas:-Fitting-models-using-R-style-formulas">Formulas: Fitting models using R-style formulas</h1>       <p>Since version 0.5.0, <code>statsmodels</code> allows users to fit statistical models using R-style formulas. Internally, <code>statsmodels</code> uses the <a href="http://patsy.readthedocs.org/">patsy</a> package to convert formulas and data to the matrices that are used in model fitting. The formula framework is quite powerful; this tutorial only scratches the surface. A full description of the formula language can be found in the <code>patsy</code> docs:</p> <ul> <li><a href="http://patsy.readthedocs.org/">Patsy formula language description</a></li> </ul> <h2 id="Loading-modules-and-functions">Loading modules and functions</h2>     <div class="input"> <div class="prompt input_prompt">In [1]:</div>   <pre data-language="python">from __future__ import print_function
import numpy as np
import statsmodels.api as sm
</pre>   </div>     <h4 id="Import-convention">Import convention</h4>       <p>You can import explicitly from statsmodels.formula.api</p>     <div class="input"> <div class="prompt input_prompt">In [2]:</div>   <pre data-language="python">from statsmodels.formula.api import ols
</pre>   </div>     <p>Alternatively, you can just use the <code>formula</code> namespace of the main <code>statsmodels.api</code>.</p>     <div class="input"> <div class="prompt input_prompt">In [3]:</div>   <pre data-language="python">sm.formula.ols
</pre>   </div> <div class="output_wrapper"> <div class="output"> <div class="output_area"> <div class="prompt output_prompt">Out[3]:</div> <div class="output_text output_subarea output_execute_result"> <pre>&lt;bound method Model.from_formula of &lt;class 'statsmodels.regression.linear_model.OLS'&gt;&gt;</pre> </div> </div> </div> </div>     <p>Or you can use the following conventioin</p>     <div class="input"> <div class="prompt input_prompt">In [4]:</div>   <pre data-language="python">import statsmodels.formula.api as smf
</pre>   </div>     <p>These names are just a convenient way to get access to each model's <code>from_formula</code> classmethod. See, for instance</p>     <div class="input"> <div class="prompt input_prompt">In [5]:</div>   <pre data-language="python">sm.OLS.from_formula
</pre>   </div> <div class="output_wrapper"> <div class="output"> <div class="output_area"> <div class="prompt output_prompt">Out[5]:</div> <div class="output_text output_subarea output_execute_result"> <pre>&lt;bound method Model.from_formula of &lt;class 'statsmodels.regression.linear_model.OLS'&gt;&gt;</pre> </div> </div> </div> </div>     <p>All of the lower case models accept <code>formula</code> and <code>data</code> arguments, whereas upper case ones take <code>endog</code> and <code>exog</code> design matrices. <code>formula</code> accepts a string which describes the model in terms of a <code>patsy</code> formula. <code>data</code> takes a <a href="http://pandas.pydata.org/">pandas</a> data frame or any other data structure that defines a <code>__getitem__</code> for variable names like a structured array or a dictionary of variables.</p> <p><code>dir(sm.formula)</code> will print a list of available models.</p> <p>Formula-compatible models have the following generic call signature: <code>(formula, data, subset=None, *args, **kwargs)</code></p>       <h2 id="OLS-regression-using-formulas">OLS regression using formulas</h2>
<p>To begin, we fit the linear model described on the <a href="gettingstarted">Getting Started</a> page. Download the data, subset columns, and list-wise delete to remove missing observations:</p>     <div class="input"> <div class="prompt input_prompt">In [6]:</div>   <pre data-language="python">dta = sm.datasets.get_rdataset("Guerry", "HistData", cache=True)
</pre>   </div>   <div class="input"> <div class="prompt input_prompt">In [7]:</div>   <pre data-language="python">df = dta.data[['Lottery', 'Literacy', 'Wealth', 'Region']].dropna()
df.head()
</pre>   </div> <div class="output_wrapper"> <div class="output"> <div class="output_area"> <div class="prompt output_prompt">Out[7]:</div> <div class="output_html rendered_html output_subarea output_execute_result"> <div>  <table class="dataframe"> <thead> <tr style="text-align: right;"> <th></th> <th>Lottery</th> <th>Literacy</th> <th>Wealth</th> <th>Region</th> </tr> </thead>  <tr> <th>0</th> <td>41</td> <td>37</td> <td>73</td> <td>E</td> </tr> <tr> <th>1</th> <td>38</td> <td>51</td> <td>22</td> <td>N</td> </tr> <tr> <th>2</th> <td>66</td> <td>13</td> <td>61</td> <td>C</td> </tr> <tr> <th>3</th> <td>80</td> <td>46</td> <td>76</td> <td>E</td> </tr> <tr> <th>4</th> <td>79</td> <td>69</td> <td>83</td> <td>E</td> </tr>  </table> </div> </div> </div> </div> </div>     <p>Fit the model:</p>     <div class="input"> <div class="prompt input_prompt">In [8]:</div>   <pre data-language="python">mod = ols(formula='Lottery ~ Literacy + Wealth + Region', data=df)
res = mod.fit()
print(res.summary())
</pre>   </div> <div class="output_wrapper"> <div class="output"> <div class="output_area">  <div class="output_subarea output_stream output_stdout output_text"> <pre>                            OLS Regression Results                            
==============================================================================
Dep. Variable:                Lottery   R-squared:                       0.338
Model:                            OLS   Adj. R-squared:                  0.287
Method:                 Least Squares   F-statistic:                     6.636
Date:                Mon, 14 May 2018   Prob (F-statistic):           1.07e-05
Time:                        21:44:51   Log-Likelihood:                -375.30
No. Observations:                  85   AIC:                             764.6
Df Residuals:                      78   BIC:                             781.7
Df Model:                           6                                         
Covariance Type:            nonrobust                                         
===============================================================================
                  coef    std err          t      P&gt;|t|      [0.025      0.975]
-------------------------------------------------------------------------------
Intercept      38.6517      9.456      4.087      0.000      19.826      57.478
Region[T.E]   -15.4278      9.727     -1.586      0.117     -34.793       3.938
Region[T.N]   -10.0170      9.260     -1.082      0.283     -28.453       8.419
Region[T.S]    -4.5483      7.279     -0.625      0.534     -19.039       9.943
Region[T.W]   -10.0913      7.196     -1.402      0.165     -24.418       4.235
Literacy       -0.1858      0.210     -0.886      0.378      -0.603       0.232
Wealth          0.4515      0.103      4.390      0.000       0.247       0.656
==============================================================================
Omnibus:                        3.049   Durbin-Watson:                   1.785
Prob(Omnibus):                  0.218   Jarque-Bera (JB):                2.694
Skew:                          -0.340   Prob(JB):                        0.260
Kurtosis:                       2.454   Cond. No.                         371.
==============================================================================

Warnings:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.
</pre> </div> </div> </div> </div>     <h2 id="Categorical-variables">Categorical variables</h2>
<p>Looking at the summary printed above, notice that <code>patsy</code> determined that elements of <em>Region</em> were text strings, so it treated <em>Region</em> as a categorical variable. <code>patsy</code>'s default is also to include an intercept, so we automatically dropped one of the <em>Region</em> categories.</p> <p>If <em>Region</em> had been an integer variable that we wanted to treat explicitly as categorical, we could have done so by using the <code>C()</code> operator:</p>     <div class="input"> <div class="prompt input_prompt">In [9]:</div>   <pre data-language="python">res = ols(formula='Lottery ~ Literacy + Wealth + C(Region)', data=df).fit()
print(res.params)
</pre>   </div> <div class="output_wrapper"> <div class="output"> <div class="output_area">  <div class="output_subarea output_stream output_stdout output_text"> <pre>Intercept         38.651655
C(Region)[T.E]   -15.427785
C(Region)[T.N]   -10.016961
C(Region)[T.S]    -4.548257
C(Region)[T.W]   -10.091276
Literacy          -0.185819
Wealth             0.451475
dtype: float64
</pre> </div> </div> </div> </div>     <p>Patsy's mode advanced features for categorical variables are discussed in: <a href="contrasts">Patsy: Contrast Coding Systems for categorical variables</a></p>       <h2 id="Operators">Operators</h2>
<p>We have already seen that "~" separates the left-hand side of the model from the right-hand side, and that "+" adds new columns to the design matrix.</p> <h3 id="Removing-variables">Removing variables</h3>
<p>The "-" sign can be used to remove columns/variables. For instance, we can remove the intercept from a model by:</p>     <div class="input"> <div class="prompt input_prompt">In [10]:</div>   <pre data-language="python">res = ols(formula='Lottery ~ Literacy + Wealth + C(Region) -1 ', data=df).fit()
print(res.params)
</pre>   </div> <div class="output_wrapper"> <div class="output"> <div class="output_area">  <div class="output_subarea output_stream output_stdout output_text"> <pre>C(Region)[C]    38.651655
C(Region)[E]    23.223870
C(Region)[N]    28.634694
C(Region)[S]    34.103399
C(Region)[W]    28.560379
Literacy        -0.185819
Wealth           0.451475
dtype: float64
</pre> </div> </div> </div> </div>     <h3 id="Multiplicative-interactions">Multiplicative interactions</h3>
<p>":" adds a new column to the design matrix with the interaction of the other two columns. "*" will also include the individual columns that were multiplied together:</p>     <div class="input"> <div class="prompt input_prompt">In [11]:</div>   <pre data-language="python">res1 = ols(formula='Lottery ~ Literacy : Wealth - 1', data=df).fit()
res2 = ols(formula='Lottery ~ Literacy * Wealth - 1', data=df).fit()
print(res1.params, '\n')
print(res2.params)
</pre>   </div> <div class="output_wrapper"> <div class="output"> <div class="output_area">  <div class="output_subarea output_stream output_stdout output_text"> <pre>Literacy:Wealth    0.018176
dtype: float64 

Literacy           0.427386
Wealth             1.080987
Literacy:Wealth   -0.013609
dtype: float64
</pre> </div> </div> </div> </div>     <p>Many other things are possible with operators. Please consult the <a href="https://patsy.readthedocs.org/en/latest/formulas.html">patsy docs</a> to learn more.</p>       <h2 id="Functions">Functions</h2>
<p>You can apply vectorized functions to the variables in your model:</p>     <div class="input"> <div class="prompt input_prompt">In [12]:</div>   <pre data-language="python">res = smf.ols(formula='Lottery ~ np.log(Literacy)', data=df).fit()
print(res.params)
</pre>   </div> <div class="output_wrapper"> <div class="output"> <div class="output_area">  <div class="output_subarea output_stream output_stdout output_text"> <pre>Intercept           115.609119
np.log(Literacy)    -20.393959
dtype: float64
</pre> </div> </div> </div> </div>     <p>Define a custom function:</p>     <div class="input"> <div class="prompt input_prompt">In [13]:</div>   <pre data-language="python">def log_plus_1(x):
    return np.log(x) + 1.
res = smf.ols(formula='Lottery ~ log_plus_1(Literacy)', data=df).fit()
print(res.params)
</pre>   </div> <div class="output_wrapper"> <div class="output"> <div class="output_area">  <div class="output_subarea output_stream output_stdout output_text"> <pre>Intercept               136.003079
log_plus_1(Literacy)    -20.393959
dtype: float64
</pre> </div> </div> </div> </div>     <p>Any function that is in the calling namespace is available to the formula.</p>       <h2 id="Using-formulas-with-models-that-do-not-(yet)-support-them">Using formulas with models that do not (yet) support them</h2>
<p>Even if a given <code>statsmodels</code> function does not support formulas, you can still use <code>patsy</code>'s formula language to produce design matrices. Those matrices can then be fed to the fitting function as <code>endog</code> and <code>exog</code> arguments.</p> <p>To generate <code>numpy</code> arrays:</p>     <div class="input"> <div class="prompt input_prompt">In [14]:</div>   <pre data-language="python">import patsy
f = 'Lottery ~ Literacy * Wealth'
y,X = patsy.dmatrices(f, df, return_type='matrix')
print(y[:5])
print(X[:5])
</pre>   </div> <div class="output_wrapper"> <div class="output"> <div class="output_area">  <div class="output_subarea output_stream output_stdout output_text"> <pre>[[41.]
 [38.]
 [66.]
 [80.]
 [79.]]
[[1.000e+00 3.700e+01 7.300e+01 2.701e+03]
 [1.000e+00 5.100e+01 2.200e+01 1.122e+03]
 [1.000e+00 1.300e+01 6.100e+01 7.930e+02]
 [1.000e+00 4.600e+01 7.600e+01 3.496e+03]
 [1.000e+00 6.900e+01 8.300e+01 5.727e+03]]
</pre> </div> </div> </div> </div>     <p>To generate pandas data frames:</p>     <div class="input"> <div class="prompt input_prompt">In [15]:</div>   <pre data-language="python">f = 'Lottery ~ Literacy * Wealth'
y,X = patsy.dmatrices(f, df, return_type='dataframe')
print(y[:5])
print(X[:5])
</pre>   </div> <div class="output_wrapper"> <div class="output"> <div class="output_area">  <div class="output_subarea output_stream output_stdout output_text"> <pre>   Lottery
0     41.0
1     38.0
2     66.0
3     80.0
4     79.0
   Intercept  Literacy  Wealth  Literacy:Wealth
0        1.0      37.0    73.0           2701.0
1        1.0      51.0    22.0           1122.0
2        1.0      13.0    61.0            793.0
3        1.0      46.0    76.0           3496.0
4        1.0      69.0    83.0           5727.0
</pre> </div> </div> </div> </div>   <div class="input"> <div class="prompt input_prompt">In [16]:</div>   <pre data-language="python">print(sm.OLS(y, X).fit().summary())
</pre>   </div> <div class="output_wrapper"> <div class="output"> <div class="output_area">  <div class="output_subarea output_stream output_stdout output_text"> <pre>                            OLS Regression Results                            
==============================================================================
Dep. Variable:                Lottery   R-squared:                       0.309
Model:                            OLS   Adj. R-squared:                  0.283
Method:                 Least Squares   F-statistic:                     12.06
Date:                Mon, 14 May 2018   Prob (F-statistic):           1.32e-06
Time:                        21:44:51   Log-Likelihood:                -377.13
No. Observations:                  85   AIC:                             762.3
Df Residuals:                      81   BIC:                             772.0
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
===================================================================================
                      coef    std err          t      P&gt;|t|      [0.025      0.975]
-----------------------------------------------------------------------------------
Intercept          38.6348     15.825      2.441      0.017       7.149      70.121
Literacy           -0.3522      0.334     -1.056      0.294      -1.016       0.312
Wealth              0.4364      0.283      1.544      0.126      -0.126       0.999
Literacy:Wealth    -0.0005      0.006     -0.085      0.933      -0.013       0.012
==============================================================================
Omnibus:                        4.447   Durbin-Watson:                   1.953
Prob(Omnibus):                  0.108   Jarque-Bera (JB):                3.228
Skew:                          -0.332   Prob(JB):                        0.199
Kurtosis:                       2.314   Cond. No.                     1.40e+04
==============================================================================

Warnings:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.
[2] The condition number is large, 1.4e+04. This might indicate that there are
strong multicollinearity or other numerical problems.
</pre> </div> </div> </div> </div>
<div class="_attribution">
  <p class="_attribution-p">
    © 2009–2012 Statsmodels Developers<br>© 2006–2008 Scipy Developers<br>© 2006 Jonathan E. Taylor<br>Licensed under the 3-clause BSD License.<br>
    <a href="http://www.statsmodels.org/stable/examples/notebooks/generated/formulas.html" class="_attribution-link">http://www.statsmodels.org/stable/examples/notebooks/generated/formulas.html</a>
  </p>
</div>

				
			</div>
			<ins class="adsbygoogle"
     style="display:block"
     data-ad-client="ca-pub-2572770204602497"
     data-ad-slot="1992473792"
     data-ad-format="auto"
     data-full-width-responsive="true"></ins>
<script>
     (adsbygoogle = window.adsbygoogle || []).push({});
</script>
		</div>
	</section>

	</div>
	<svg style="display:none">
		<symbol id="icon-dir"><svg viewBox="0 0 20 20"><path d="M15 10c0 .3-.305.515-.305.515l-8.56 5.303c-.625.41-1.135.106-1.135-.67V4.853c0-.777.51-1.078 1.135-.67l8.56 5.305S15 9.702 15 10z"/></svg></symbol>
	  </svg>
</body>
</html>
