
<!DOCTYPE HTML>

<html lang="en" class="_theme-default">

<head>
  <meta charset="utf-8">
  <title>tensorflow&#58;&#58;ops&#58;&#58;TensorArrayGrad - TensorFlow C++ 1.15 - W3cubDocs</title>
  
  <meta name="description" content=" #include &#60;data_flow_ops.h&#62; ">
  <meta name="keywords" content="tensorflow, ops, tensorarraygrad, c++, tensorflow_cpp~1.15">
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="mobile-web-app-capable" content="yes">
  
  <link rel="canonical" href="https://docs.w3cub.com/tensorflow_cpp~1.15/class/tensorflow/ops/tensor-array-grad.html">
  <link href="/favicon.png" rel="icon">
  <link rel="stylesheet" type="text/css" href="/assets/application-e498cd0ebe8746846fec95b1a53ab3bb0fb7f47f794f0a38f44c98a1f0d03b21d777ae2c583732e44a5a890f6eacb79a5333545db9d5f3616091ba21ca17d916.css">
  <script src="/assets/application-79c555f6b25481fffac2cac30a7f3e54e608ca09e9e8e42bb1790095ba6d0fcace47d6bc624ddce952c70370892f2d46864f89e6943d4f7f7ff16c8a3231a91a.js" type="text/javascript"></script>
  <script src="/json/tensorflow_cpp~1.15.js"></script>
  
<!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-R3WC07G3GB"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());
  gtag('config', 'G-R3WC07G3GB');
</script>
<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-2572770204602497"
     crossorigin="anonymous"></script>
<script async custom-element="amp-auto-ads"
  src="https://cdn.ampproject.org/v0/amp-auto-ads-0.1.js">
</script>


</head>

<body class="docs">
	<amp-auto-ads type="adsense"
              data-ad-client="ca-pub-2572770204602497">
	</amp-auto-ads>
	<div class="_app">
	<header class="_header">

  <a class="_home-link" href="/" ></a>
  <a class="_menu-link"></a>
  <h1 class="_logo">
    <a href="/" class="_nav-link" title="API Documentation Browser">W3cubDocs</a>
  </h1>
  
  <span class="_logo-sub-nav">/</span><span class="_logo-sub-nav"><a href="/tensorflow_cpp~1.15/" class="_nav-link" title="" style="margin-left:0;">TensorFlow C++ 1.15</a></span>
  
  <nav class="_nav">
    <a href="https://tools.w3cub.com/?_sp=docs" target="_blank" class="_nav-link ">W3cubTools</a>
    <a href="/cheatsheets/" class="_nav-link ">Cheatsheets</a>
    <a href="/about/" class="_nav-link ">About</a>
  </nav>
</header>
	<section class="_sidebar">
		
		<form class="_search">
		  <input type="search" class="_search-input" placeholder="Search&hellip;" autocomplete="off" autocapitalize="off" autocorrect="off" spellcheck="false" maxlength="20">
		  <a class="_search-clear"></a>
		  <div class="_search-tag"></div>
		</form>
		
		<div class="_list-wrap">
			<div class="_list">
			
			</div>
		</div>
	</section>
	<section class="_container ">
		<div class="_content">
			<ins class="adsbygoogle"
     style="display:block"
     data-ad-client="ca-pub-2572770204602497"
     data-ad-slot="6861657091"
     data-ad-format="auto"
     data-full-width-responsive="true"></ins>
<script>
     (adsbygoogle = window.adsbygoogle || []).push({});
</script>
			<div class="_page _tensorflow">
				
				
<h1 id="tensorflow::ops::tensorarraygrad" data-text="tensorflow::ops::TensorArrayGrad" tabindex="0">tensorflow::ops::TensorArrayGrad</h1> <p><code translate="no" dir="ltr">#include &lt;data_flow_ops.h&gt;</code></p> <p>Creates a <a href="tensor-array#classtensorflow_1_1ops_1_1_tensor_array">TensorArray</a> for storing the gradients of values in the given handle. </p> <h2 id="summary" data-text="Summary" tabindex="0">Summary</h2> <p>If the given <a href="tensor-array#classtensorflow_1_1ops_1_1_tensor_array">TensorArray</a> gradient already exists, returns a reference to it.</p> <p>Locks the size of the original <a href="tensor-array#classtensorflow_1_1ops_1_1_tensor_array">TensorArray</a> by disabling its dynamic size flag.</p> <p> <b>A note about the input flow_in:</b> </p> <p>The handle flow_in forces the execution of the gradient lookup to occur only after certain other operations have occurred. For example, when the forward <a href="tensor-array#classtensorflow_1_1ops_1_1_tensor_array">TensorArray</a> is dynamically sized, writes to this <a href="tensor-array#classtensorflow_1_1ops_1_1_tensor_array">TensorArray</a> may resize the object. The gradient <a href="tensor-array#classtensorflow_1_1ops_1_1_tensor_array">TensorArray</a> is statically sized based on the size of the forward <a href="tensor-array#classtensorflow_1_1ops_1_1_tensor_array">TensorArray</a> when this operation executes. Furthermore, the size of the forward <a href="tensor-array#classtensorflow_1_1ops_1_1_tensor_array">TensorArray</a> is frozen by this call. As a result, the flow is used to ensure that the call to generate the gradient <a href="tensor-array#classtensorflow_1_1ops_1_1_tensor_array">TensorArray</a> only happens after all writes are executed.</p> <p>In the case of dynamically sized TensorArrays, gradient computation should only be performed on read operations that have themselves been chained via flow to occur only after all writes have executed. That way the final size of the forward <a href="tensor-array#classtensorflow_1_1ops_1_1_tensor_array">TensorArray</a> is known when this operation is called.</p> <p> <b>A note about the source attribute:</b> </p> <p><a href="tensor-array#classtensorflow_1_1ops_1_1_tensor_array">TensorArray</a> gradient calls use an accumulator <a href="tensor-array#classtensorflow_1_1ops_1_1_tensor_array">TensorArray</a> object. If multiple gradients are calculated and run in the same session, the multiple gradient nodes may accidentally flow through the same accumulator <a href="tensor-array#classtensorflow_1_1ops_1_1_tensor_array">TensorArray</a>. This double counts and generally breaks the <a href="tensor-array#classtensorflow_1_1ops_1_1_tensor_array">TensorArray</a> gradient flow.</p> <p>The solution is to identify which gradient call this particular <a href="tensor-array#classtensorflow_1_1ops_1_1_tensor_array">TensorArray</a> gradient is being called in. This is performed by identifying a unique string (e.g. "gradients", "gradients_1", ...) from the input gradient <a href="../tensor#classtensorflow_1_1_tensor">Tensor</a>'s name. This string is used as a suffix when creating the <a href="tensor-array#classtensorflow_1_1ops_1_1_tensor_array">TensorArray</a> gradient object here (the attribute <code translate="no" dir="ltr">source</code>).</p> <p>The attribute <code translate="no" dir="ltr">source</code> is added as a suffix to the forward <a href="tensor-array#classtensorflow_1_1ops_1_1_tensor_array">TensorArray</a>'s name when performing the creation / lookup, so that each separate gradient calculation gets its own <a href="tensor-array#classtensorflow_1_1ops_1_1_tensor_array">TensorArray</a> accumulator.</p> <p>Arguments:</p>
<ul> <li>scope: A <a href="../scope#classtensorflow_1_1_scope">Scope</a> object</li> <li>handle: The handle to the forward <a href="tensor-array#classtensorflow_1_1ops_1_1_tensor_array">TensorArray</a>.</li> <li>flow_in: A float scalar that enforces proper chaining of operations.</li> <li>source: The gradient source string, used to decide which gradient <a href="tensor-array#classtensorflow_1_1ops_1_1_tensor_array">TensorArray</a> to return.</li> </ul> <p>Returns:</p>
<ul> <li>
<code translate="no" dir="ltr"><a href="../output#classtensorflow_1_1_output">Output</a></code> grad_handle</li> <li>
<code translate="no" dir="ltr"><a href="../output#classtensorflow_1_1_output">Output</a></code> flow_out </li> </ul> <table class="constructors responsive"> <tr> <th colspan="2"> Constructors and Destructors </th> </tr> <tr> <td colspan="2"> <code translate="no" dir="ltr"><a href="#classtensorflow_1_1ops_1_1_tensor_array_grad_1a6240f50f9c7efdcf3bf8d48c4218d27b">TensorArrayGrad</a>(const ::<a href="../scope#classtensorflow_1_1_scope">tensorflow::Scope</a> &amp; scope, ::<a href="../input#classtensorflow_1_1_input">tensorflow::Input</a> handle, ::<a href="../input#classtensorflow_1_1_input">tensorflow::Input</a> flow_in, StringPiece source)</code> <br> </td> </tr> </table> <table class="properties responsive"> <tr> <th colspan="2"> Public attributes </th> </tr> <tr> <td> <code translate="no" dir="ltr"><a href="#classtensorflow_1_1ops_1_1_tensor_array_grad_1a2499ef8bb9c633df24389a51f37654da">flow_out</a></code> </td> <td> <div> <code translate="no" dir="ltr">::<a href="../output#classtensorflow_1_1_output">tensorflow::Output</a></code> </div> </td> </tr> <tr> <td> <code translate="no" dir="ltr"><a href="#classtensorflow_1_1ops_1_1_tensor_array_grad_1ab5be040d777eb52f767d58a83a3a345d">grad_handle</a></code> </td> <td> <div> <code translate="no" dir="ltr">::<a href="../output#classtensorflow_1_1_output">tensorflow::Output</a></code> </div> </td> </tr> <tr> <td> <code translate="no" dir="ltr"><a href="#classtensorflow_1_1ops_1_1_tensor_array_grad_1ae7c0b0022fc4a44d321bf759c55413c2">operation</a></code> </td> <td> <div> <code translate="no" dir="ltr"><a href="../operation#classtensorflow_1_1_operation">Operation</a></code> </div> </td> </tr> </table> <h2 id="public-attributes_1" data-text="Public attributes" tabindex="0">Public attributes</h2> <div id="classtensorflow_1_1ops_1_1_tensor_array_grad_1a2499ef8bb9c633df24389a51f37654da"> <h3 id="flow_out" data-text="flow_out" tabindex="0">flow_out</h3> <pre class="prettyprint" translate="no" dir="ltr" data-language="cpp">::tensorflow::Output flow_out</pre>  </div> <div id="classtensorflow_1_1ops_1_1_tensor_array_grad_1ab5be040d777eb52f767d58a83a3a345d"> <h3 id="grad_handle" data-text="grad_handle" tabindex="0">grad_handle</h3> <pre class="prettyprint" translate="no" dir="ltr" data-language="cpp">::tensorflow::Output grad_handle</pre>  </div> <div id="classtensorflow_1_1ops_1_1_tensor_array_grad_1ae7c0b0022fc4a44d321bf759c55413c2"> <h3 id="operation" data-text="operation" tabindex="0">operation</h3> <pre class="prettyprint" translate="no" dir="ltr" data-language="cpp">Operation operation</pre>  </div> <h2 id="public-functions" data-text="Public functions" tabindex="0">Public functions</h2> <div id="classtensorflow_1_1ops_1_1_tensor_array_grad_1a6240f50f9c7efdcf3bf8d48c4218d27b"> <h3 id="tensorarraygrad" data-text="TensorArrayGrad" tabindex="0">TensorArrayGrad</h3> <pre class="prettyprint" translate="no" dir="ltr" data-language="cpp"> TensorArrayGrad(
  const ::tensorflow::Scope &amp; scope,
  ::tensorflow::Input handle,
  ::tensorflow::Input flow_in,
  StringPiece source
)</pre>  </div>  <devsite-page-rating position="footer" selected-rating="0" hover-rating-star="0"> </devsite-page-rating><div class="_attribution">
  <p class="_attribution-p">
    Â© 2020 The TensorFlow Authors. All rights reserved.<br>Licensed under the Creative Commons Attribution License 3.0.<br>Code samples licensed under the Apache 2.0 License.<br>
    <a href="https://www.tensorflow.org/versions/r1.15/api_docs/cc/class/tensorflow/ops/tensor-array-grad" class="_attribution-link">https://www.tensorflow.org/versions/r1.15/api_docs/cc/class/tensorflow/ops/tensor-array-grad</a>
  </p>
</div>

				
			</div>
			<ins class="adsbygoogle"
     style="display:block"
     data-ad-client="ca-pub-2572770204602497"
     data-ad-slot="1992473792"
     data-ad-format="auto"
     data-full-width-responsive="true"></ins>
<script>
     (adsbygoogle = window.adsbygoogle || []).push({});
</script>
		</div>
	</section>

	</div>
	<svg style="display:none">
		<symbol id="icon-dir"><svg viewBox="0 0 20 20"><path d="M15 10c0 .3-.305.515-.305.515l-8.56 5.303c-.625.41-1.135.106-1.135-.67V4.853c0-.777.51-1.078 1.135-.67l8.56 5.305S15 9.702 15 10z"/></svg></symbol>
	  </svg>
</body>
</html>
