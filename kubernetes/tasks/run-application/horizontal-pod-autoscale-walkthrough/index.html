
<!DOCTYPE HTML>

<html lang="en" class="_theme-default">

<head>
  <meta charset="utf-8">
  <title>HorizontalPodAutoscaler Walkthrough - Kubernetes - W3cubDocs</title>
  
  <meta name="description" content="A HorizontalPodAutoscaler (HPA for short) automatically updates a workload resource (such as a Deployment or StatefulSet), with the aim of &hellip;">
  <meta name="keywords" content="horizontalpodautoscaler, walkthrough, kubernetes">
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="mobile-web-app-capable" content="yes">
  
  <link rel="canonical" href="https://docs.w3cub.com/kubernetes/tasks/run-application/horizontal-pod-autoscale-walkthrough/">
  <link href="/favicon.png" rel="icon">
  <link rel="stylesheet" type="text/css" href="/assets/application-60a6449bb52e9968d95c133a29f066ffcb8dbe4f077d4022e51c991ce30bf256c8e19c508207a4193c414ffd0414826564317669b0f27f9f85c1cb21b84e097e.css">
  <script src="/assets/application-d9be6f56a823612443fc15b2e027a630e02c4ad2685bb750d13fa4fae28d46c3e7f7ebb69bd4bafddf116f218f9372e9be44021d4247dc20424e2fd1ff8cef81.js" type="text/javascript"></script>
  <script src="/json/kubernetes.js"></script>
  
  <script type="text/javascript">
    var _gaq = _gaq || [];
    _gaq.push(['_setAccount', 'UA-71174418-1']);
    _gaq.push(['_trackPageview']);

    (function() {
      var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
      ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
      var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
    })();
  </script>
  <script data-ad-client="ca-pub-2572770204602497" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script async custom-element="amp-auto-ads"
  src="https://cdn.ampproject.org/v0/amp-auto-ads-0.1.js">
</script>


</head>

<body class="docs">
	<amp-auto-ads type="adsense"
              data-ad-client="ca-pub-2572770204602497">
	</amp-auto-ads>
	<div class="_app">
	<header class="_header">

  <a class="_home-link" href="/" ></a>
  <a class="_menu-link"></a>
  <h1 class="_logo">
    <a href="/" class="_nav-link" title="API Documentation Browser">W3cubDocs</a>
  </h1>
  
  <span class="_logo-sub-nav">/</span><span class="_logo-sub-nav"><a href="/kubernetes/" class="_nav-link" title="" style="margin-left:0;">Kubernetes</a></span>
  
  <nav class="_nav">
    <a href="https://tools.w3cub.com/?_sp=docs" target="_blank" class="_nav-link ">W3cubTools</a>
    <a href="/cheatsheets/" class="_nav-link ">Cheatsheets</a>
    <a href="/about/" class="_nav-link ">About</a>
  </nav>
</header>
	<section class="_sidebar">
		
		<form class="_search">
		  <input type="search" class="_search-input" placeholder="Search&hellip;" autocomplete="off" autocapitalize="off" autocorrect="off" spellcheck="false" maxlength="20">
		  <a class="_search-clear"></a>
		  <div class="_search-tag"></div>
		</form>
		
		<div class="_list-wrap">
			<div class="_list">
			
			</div>
		</div>
	</section>
	<section class="_container ">
		<div class="_content">
			<ins class="adsbygoogle"
     style="display:block"
     data-ad-client="ca-pub-2572770204602497"
     data-ad-slot="6861657091"
     data-ad-format="link"
     data-full-width-responsive="true"></ins>
<script>
     (adsbygoogle = window.adsbygoogle || []).push({});
</script>
			<div class="_page _kubernetes">
				
				
<h1>HorizontalPodAutoscaler Walkthrough</h1>  <p>A <a href="../horizontal-pod-autoscale/index">HorizontalPodAutoscaler</a> (HPA for short) automatically updates a workload resource (such as a <a class="glossary-tooltip" title="Manages a replicated application on your cluster." data-toggle="tooltip" data-placement="top" href="../../../concepts/workloads/controllers/deployment/index" target="_blank" aria-label="Deployment">Deployment</a> or <a class="glossary-tooltip" title="Manages deployment and scaling of a set of Pods, with durable storage and persistent identifiers for each Pod." data-toggle="tooltip" data-placement="top" href="../../../concepts/workloads/controllers/statefulset/index" target="_blank" aria-label="StatefulSet">StatefulSet</a>), with the aim of automatically scaling the workload to match demand.</p> <p>Horizontal scaling means that the response to increased load is to deploy more <a class="glossary-tooltip" title="A Pod represents a set of running containers in your cluster." data-toggle="tooltip" data-placement="top" href="../../../concepts/workloads/pods/index" target="_blank" aria-label="Pods">Pods</a>. This is different from <em>vertical</em> scaling, which for Kubernetes would mean assigning more resources (for example: memory or CPU) to the Pods that are already running for the workload.</p> <p>If the load decreases, and the number of Pods is above the configured minimum, the HorizontalPodAutoscaler instructs the workload resource (the Deployment, StatefulSet, or other similar resource) to scale back down.</p> <p>This document walks you through an example of enabling HorizontalPodAutoscaler to automatically manage scale for an example web app. This example workload is Apache httpd running some PHP code.</p> <h2 id="before-you-begin">Before you begin</h2> 
<p>You need to have a Kubernetes cluster, and the kubectl command-line tool must be configured to communicate with your cluster. It is recommended to run this tutorial on a cluster with at least two nodes that are not acting as control plane hosts. If you do not already have a cluster, you can create one by using <a href="https://minikube.sigs.k8s.io/docs/tutorials/multi_node/">minikube</a> or you can use one of these Kubernetes playgrounds:</p> <ul> <li><a href="https://www.katacoda.com/courses/kubernetes/playground">Katacoda</a></li> <li><a href="http://labs.play-with-k8s.com/">Play with Kubernetes</a></li> </ul> Your Kubernetes server must be at or later than version 1.23. To check the version, enter <code>kubectl version</code>. If you're running an older release of Kubernetes, refer to the version of the documentation for that release (see <a href="https://kubernetes.io/docs/home/supported-doc-versions/">available documentation versions</a>. <p>To follow this walkthrough, you also need to use a cluster that has a <a href="https://github.com/kubernetes-sigs/metrics-server#readme">Metrics Server</a> deployed and configured. The Kubernetes Metrics Server collects resource metrics from the <a class="glossary-tooltip" title="An agent that runs on each node in the cluster. It makes sure that containers are running in a pod." data-toggle="tooltip" data-placement="top" href="../../../reference/generated/kubelet" target="_blank" aria-label="kubelets">kubelets</a> in your cluster, and exposes those metrics through the <a href="../../../concepts/overview/kubernetes-api/index">Kubernetes API</a>, using an <a href="../../../concepts/extend-kubernetes/api-extension/apiserver-aggregation/index">APIService</a> to add new kinds of resource that represent metric readings.</p> <p>To learn how to deploy the Metrics Server, see the <a href="https://github.com/kubernetes-sigs/metrics-server#deployment">metrics-server documentation</a>.</p>  <h2 id="run-and-expose-php-apache-server">Run and expose php-apache server</h2> <p>To demonstrate a HorizontalPodAutoscaler, you will first make a custom container image that uses the <code>php-apache</code> image from Docker Hub as its starting point. The <code>Dockerfile</code> is ready-made for you, and has the following content:</p> <pre class="highlight" data-language="dockerfile">FROM php:5-apache
COPY index.php /var/www/html/index.php
RUN chmod a+rx index.php
</pre>
<p>This code defines a simple <code>index.php</code> page that performs some CPU intensive computations, in order to simulate load in your cluster.</p> <pre class="highlight" data-language="php">&lt;?php
  $x = 0.0001;
  for ($i = 0; $i &lt;= 1000000; $i++) {
    $x += sqrt($x);
  }
  echo "OK!";
?&gt;
</pre>
<p>Once you have made that container image, start a Deployment that runs a container using the image you made, and expose it as a <a class="glossary-tooltip" title="A way to expose an application running on a set of Pods as a network service." data-toggle="tooltip" data-placement="top" href="../../../concepts/services-networking/service/index" target="_blank" aria-label="Service">Service</a> using the following manifest:</p> <pre class="highlight" data-language="">application/php-apache.yaml</pre> <p>To do so, run the following command:</p> <pre class="highlight" data-language="shell">kubectl apply -f https://k8s.io/examples/application/php-apache.yaml
</pre>
<pre><code>deployment.apps/php-apache created
service/php-apache created
</code></pre>
<h2 id="create-horizontal-pod-autoscaler">Create the HorizontalPodAutoscaler</h2> <p>Now that the server is running, create the autoscaler using <code>kubectl</code>. There is <a href="https://kubernetes.io/docs/reference/generated/kubectl/kubectl-commands#autoscale"><code>kubectl autoscale</code></a> subcommand, part of <code>kubectl</code>, that helps you do this.</p> <p>You will shortly run a command that creates a HorizontalPodAutoscaler that maintains between 1 and 10 replicas of the Pods controlled by the php-apache Deployment that you created in the first step of these instructions.</p> <p>Roughly speaking, the HPA <a class="glossary-tooltip" title="A control loop that watches the shared state of the cluster through the apiserver and makes changes attempting to move the current state towards the desired state." data-toggle="tooltip" data-placement="top" href="../../../concepts/architecture/controller/index" target="_blank" aria-label="controller">controller</a> will increase and decrease the number of replicas (by updating the Deployment) to maintain an average CPU utilization across all Pods of 50%. The Deployment then updates the ReplicaSet - this is part of how all Deployments work in Kubernetes - and then the ReplicaSet either adds or removes Pods based on the change to its <code>.spec</code>.</p> <p>Since each pod requests 200 milli-cores by <code>kubectl run</code>, this means an average CPU usage of 100 milli-cores. See <a href="../horizontal-pod-autoscale/index#algorithm-details">Algorithm details</a> for more details on the algorithm.</p> <p>Create the HorizontalPodAutoscaler:</p> <pre class="highlight" data-language="shell">kubectl autoscale deployment php-apache --cpu-percent=50 --min=1 --max=10
</pre>
<pre><code>horizontalpodautoscaler.autoscaling/php-apache autoscaled
</code></pre>
<p>You can check the current status of the newly-made HorizontalPodAutoscaler, by running:</p> <pre class="highlight" data-language="shell"># You can use "hpa" or "horizontalpodautoscaler"; either name works OK.
kubectl get hpa
</pre>
<p>The output is similar to:</p> <pre><code>NAME         REFERENCE                     TARGET    MINPODS   MAXPODS   REPLICAS   AGE
php-apache   Deployment/php-apache/scale   0% / 50%  1         10        1          18s
</code></pre>
<p>(if you see other HorizontalPodAutoscalers with different names, that means they already existed, and isn't usually a problem).</p> <p>Please note that the current CPU consumption is 0% as there are no clients sending requests to the server (the <code>TARGET</code> column shows the average across all the Pods controlled by the corresponding deployment).</p> <h2 id="increase-load">Increase the load</h2> <p>Next, see how the autoscaler reacts to increased load. To do this, you'll start a different Pod to act as a client. The container within the client Pod runs in an infinite loop, sending queries to the php-apache service.</p> <pre class="highlight" data-language="shell"># Run this in a separate terminal
# so that the load generation continues and you can carry on with the rest of the steps
kubectl run -i --tty load-generator --rm --image=busybox --restart=Never -- /bin/sh -c "while sleep 0.01; do wget -q -O- http://php-apache; done"
</pre>
<p>Now run:</p> <pre class="highlight" data-language="shell"># type Ctrl+C to end the watch when you're ready
kubectl get hpa php-apache --watch
</pre>
<p>Within a minute or so, you should see the higher CPU load; for example:</p> <pre><code>NAME         REFERENCE                     TARGET      MINPODS   MAXPODS   REPLICAS   AGE
php-apache   Deployment/php-apache/scale   305% / 50%  1         10        1          3m
</code></pre>
<p>and then, more replicas. For example:</p> <pre><code>NAME         REFERENCE                     TARGET      MINPODS   MAXPODS   REPLICAS   AGE
php-apache   Deployment/php-apache/scale   305% / 50%  1         10        7          3m
</code></pre>
<p>Here, CPU consumption has increased to 305% of the request. As a result, the Deployment was resized to 7 replicas:</p> <pre class="highlight" data-language="shell">kubectl get deployment php-apache
</pre>
<p>You should see the replica count matching the figure from the HorizontalPodAutoscaler</p> <pre><code>NAME         READY   UP-TO-DATE   AVAILABLE   AGE
php-apache   7/7      7           7           19m
</code></pre>
<div class="alert alert-info note callout" role="alert"> <strong>Note:</strong> It may take a few minutes to stabilize the number of replicas. Since the amount of load is not controlled in any way it may happen that the final number of replicas will differ from this example. </div> <h2 id="stop-load">Stop generating load</h2> <p>To finish the example, stop sending the load.</p> <p>In the terminal where you created the Pod that runs a <code>busybox</code> image, terminate the load generation by typing <code>&lt;Ctrl&gt; + C</code>.</p> <p>Then verify the result state (after a minute or so):</p> <pre class="highlight" data-language="shell"># type Ctrl+C to end the watch when you're ready
kubectl get hpa php-apache --watch
</pre>
<p>The output is similar to:</p> <pre><code>NAME         REFERENCE                     TARGET       MINPODS   MAXPODS   REPLICAS   AGE
php-apache   Deployment/php-apache/scale   0% / 50%     1         10        1          11m
</code></pre>
<p>and the Deployment also shows that it has scaled down:</p> <pre class="highlight" data-language="shell">kubectl get deployment php-apache
</pre>
<pre><code>NAME         READY   UP-TO-DATE   AVAILABLE   AGE
php-apache   1/1     1            1           27m
</code></pre>
<p>Once CPU utilization dropped to 0, the HPA automatically scaled the number of replicas back down to 1.</p> <p>Autoscaling the replicas may take a few minutes.</p>  <h2 id="autoscaling-on-multiple-metrics-and-custom-metrics">Autoscaling on multiple metrics and custom metrics</h2> <p>You can introduce additional metrics to use when autoscaling the <code>php-apache</code> Deployment by making use of the <code>autoscaling/v2</code> API version.</p> <p>First, get the YAML of your HorizontalPodAutoscaler in the <code>autoscaling/v2</code> form:</p> <pre class="highlight" data-language="shell">kubectl get hpa php-apache -o yaml &gt; /tmp/hpa-v2.yaml
</pre>
<p>Open the <code>/tmp/hpa-v2.yaml</code> file in an editor, and you should see YAML which looks like this:</p> <pre class="highlight" data-language="yaml">apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: php-apache
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: php-apache
  minReplicas: 1
  maxReplicas: 10
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 50
status:
  observedGeneration: 1
  lastScaleTime: &lt;some-time&gt;
  currentReplicas: 1
  desiredReplicas: 1
  currentMetrics:
  - type: Resource
    resource:
      name: cpu
      current:
        averageUtilization: 0
        averageValue: 0
</pre>
<p>Notice that the <code>targetCPUUtilizationPercentage</code> field has been replaced with an array called <code>metrics</code>. The CPU utilization metric is a <em>resource metric</em>, since it is represented as a percentage of a resource specified on pod containers. Notice that you can specify other resource metrics besides CPU. By default, the only other supported resource metric is memory. These resources do not change names from cluster to cluster, and should always be available, as long as the <code>metrics.k8s.io</code> API is available.</p> <p>You can also specify resource metrics in terms of direct values, instead of as percentages of the requested value, by using a <code>target.type</code> of <code>AverageValue</code> instead of <code>Utilization</code>, and setting the corresponding <code>target.averageValue</code> field instead of the <code>target.averageUtilization</code>.</p> <p>There are two other types of metrics, both of which are considered <em>custom metrics</em>: pod metrics and object metrics. These metrics may have names which are cluster specific, and require a more advanced cluster monitoring setup.</p> <p>The first of these alternative metric types is <em>pod metrics</em>. These metrics describe Pods, and are averaged together across Pods and compared with a target value to determine the replica count. They work much like resource metrics, except that they <em>only</em> support a <code>target</code> type of <code>AverageValue</code>.</p> <p>Pod metrics are specified using a metric block like this:</p> <pre class="highlight" data-language="yaml">type: Pods
pods:
  metric:
    name: packets-per-second
  target:
    type: AverageValue
    averageValue: 1k
</pre>
<p>The second alternative metric type is <em>object metrics</em>. These metrics describe a different object in the same namespace, instead of describing Pods. The metrics are not necessarily fetched from the object; they only describe it. Object metrics support <code>target</code> types of both <code>Value</code> and <code>AverageValue</code>. With <code>Value</code>, the target is compared directly to the returned metric from the API. With <code>AverageValue</code>, the value returned from the custom metrics API is divided by the number of Pods before being compared to the target. The following example is the YAML representation of the <code>requests-per-second</code> metric.</p> <pre class="highlight" data-language="yaml">type: Object
object:
  metric:
    name: requests-per-second
  describedObject:
    apiVersion: networking.k8s.io/v1beta1
    kind: Ingress
    name: main-route
  target:
    type: Value
    value: 2k
</pre>
<p>If you provide multiple such metric blocks, the HorizontalPodAutoscaler will consider each metric in turn. The HorizontalPodAutoscaler will calculate proposed replica counts for each metric, and then choose the one with the highest replica count.</p> <p>For example, if you had your monitoring system collecting metrics about network traffic, you could update the definition above using <code>kubectl edit</code> to look like this:</p> <pre class="highlight" data-language="yaml">apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: php-apache
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: php-apache
  minReplicas: 1
  maxReplicas: 10
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 50
  - type: Pods
    pods:
      metric:
        name: packets-per-second
      target:
        type: AverageValue
        averageValue: 1k
  - type: Object
    object:
      metric:
        name: requests-per-second
      describedObject:
        apiVersion: networking.k8s.io/v1beta1
        kind: Ingress
        name: main-route
      target:
        type: Value
        value: 10k
status:
  observedGeneration: 1
  lastScaleTime: &lt;some-time&gt;
  currentReplicas: 1
  desiredReplicas: 1
  currentMetrics:
  - type: Resource
    resource:
      name: cpu
    current:
      averageUtilization: 0
      averageValue: 0
  - type: Object
    object:
      metric:
        name: requests-per-second
      describedObject:
        apiVersion: networking.k8s.io/v1beta1
        kind: Ingress
        name: main-route
      current:
        value: 10k
</pre>
<p>Then, your HorizontalPodAutoscaler would attempt to ensure that each pod was consuming roughly 50% of its requested CPU, serving 1000 packets per second, and that all pods behind the main-route Ingress were serving a total of 10000 requests per second.</p> <h3 id="autoscaling-on-more-specific-metrics">Autoscaling on more specific metrics</h3> <p>Many metrics pipelines allow you to describe metrics either by name or by a set of additional descriptors called <em>labels</em>. For all non-resource metric types (pod, object, and external, described below), you can specify an additional label selector which is passed to your metric pipeline. For instance, if you collect a metric <code>http_requests</code> with the <code>verb</code> label, you can specify the following metric block to scale only on GET requests:</p> <pre class="highlight" data-language="yaml">type: Object
object:
  metric:
    name: http_requests
    selector: {matchLabels: {verb: GET}}
</pre>
<p>This selector uses the same syntax as the full Kubernetes label selectors. The monitoring pipeline determines how to collapse multiple series into a single value, if the name and selector match multiple series. The selector is additive, and cannot select metrics that describe objects that are <strong>not</strong> the target object (the target pods in the case of the <code>Pods</code> type, and the described object in the case of the <code>Object</code> type).</p> <h3 id="autoscaling-on-metrics-not-related-to-kubernetes-objects">Autoscaling on metrics not related to Kubernetes objects</h3> <p>Applications running on Kubernetes may need to autoscale based on metrics that don't have an obvious relationship to any object in the Kubernetes cluster, such as metrics describing a hosted service with no direct correlation to Kubernetes namespaces. In Kubernetes 1.10 and later, you can address this use case with <em>external metrics</em>.</p> <p>Using external metrics requires knowledge of your monitoring system; the setup is similar to that required when using custom metrics. External metrics allow you to autoscale your cluster based on any metric available in your monitoring system. Provide a <code>metric</code> block with a <code>name</code> and <code>selector</code>, as above, and use the <code>External</code> metric type instead of <code>Object</code>. If multiple time series are matched by the <code>metricSelector</code>, the sum of their values is used by the HorizontalPodAutoscaler. External metrics support both the <code>Value</code> and <code>AverageValue</code> target types, which function exactly the same as when you use the <code>Object</code> type.</p> <p>For example if your application processes tasks from a hosted queue service, you could add the following section to your HorizontalPodAutoscaler manifest to specify that you need one worker per 30 outstanding tasks.</p> <pre class="highlight" data-language="yaml">- type: External
  external:
    metric:
      name: queue_messages_ready
      selector:
        matchLabels:
          queue: "worker_tasks"
    target:
      type: AverageValue
      averageValue: 30
</pre>
<p>When possible, it's preferable to use the custom metric target types instead of external metrics, since it's easier for cluster administrators to secure the custom metrics API. The external metrics API potentially allows access to any metric, so cluster administrators should take care when exposing it.</p> <h2 id="appendix-horizontal-pod-autoscaler-status-conditions">Appendix: Horizontal Pod Autoscaler Status Conditions</h2> <p>When using the <code>autoscaling/v2</code> form of the HorizontalPodAutoscaler, you will be able to see <em>status conditions</em> set by Kubernetes on the HorizontalPodAutoscaler. These status conditions indicate whether or not the HorizontalPodAutoscaler is able to scale, and whether or not it is currently restricted in any way.</p> <p>The conditions appear in the <code>status.conditions</code> field. To see the conditions affecting a HorizontalPodAutoscaler, we can use <code>kubectl describe hpa</code>:</p> <pre class="highlight" data-language="shell">kubectl describe hpa cm-test
</pre>
<pre><code>Name:                           cm-test
Namespace:                      prom
Labels:                         &lt;none&gt;
Annotations:                    &lt;none&gt;
CreationTimestamp:              Fri, 16 Jun 2017 18:09:22 +0000
Reference:                      ReplicationController/cm-test
Metrics:                        ( current / target )
  "http_requests" on pods:      66m / 500m
Min replicas:                   1
Max replicas:                   4
ReplicationController pods:     1 current / 1 desired
Conditions:
  Type                  Status  Reason                  Message
  ----                  ------  ------                  -------
  AbleToScale           True    ReadyForNewScale        the last scale time was sufficiently old as to warrant a new scale
  ScalingActive         True    ValidMetricFound        the HPA was able to successfully calculate a replica count from pods metric http_requests
  ScalingLimited        False   DesiredWithinRange      the desired replica count is within the acceptable range
Events:
</code></pre>
<p>For this HorizontalPodAutoscaler, you can see several conditions in a healthy state. The first, <code>AbleToScale</code>, indicates whether or not the HPA is able to fetch and update scales, as well as whether or not any backoff-related conditions would prevent scaling. The second, <code>ScalingActive</code>, indicates whether or not the HPA is enabled (i.e. the replica count of the target is not zero) and is able to calculate desired scales. When it is <code>False</code>, it generally indicates problems with fetching metrics. Finally, the last condition, <code>ScalingLimited</code>, indicates that the desired scale was capped by the maximum or minimum of the HorizontalPodAutoscaler. This is an indication that you may wish to raise or lower the minimum or maximum replica count constraints on your HorizontalPodAutoscaler.</p> <h2 id="quantities">Quantities</h2> <p>All metrics in the HorizontalPodAutoscaler and metrics APIs are specified using a special whole-number notation known in Kubernetes as a <a class="glossary-tooltip" title="A whole-number representation of small or large numbers using SI suffixes." data-toggle="tooltip" data-placement="top" href="https://kubernetes.io/docs/reference/glossary/?all=true#term-quantity" target="_blank" aria-label="quantity">quantity</a>. For example, the quantity <code>10500m</code> would be written as <code>10.5</code> in decimal notation. The metrics APIs will return whole numbers without a suffix when possible, and will generally return quantities in milli-units otherwise. This means you might see your metric value fluctuate between <code>1</code> and <code>1500m</code>, or <code>1</code> and <code>1.5</code> when written in decimal notation.</p> <h2 id="other-possible-scenarios">Other possible scenarios</h2> <h3 id="creating-the-autoscaler-declaratively">Creating the autoscaler declaratively</h3> <p>Instead of using <code>kubectl autoscale</code> command to create a HorizontalPodAutoscaler imperatively we can use the following manifest to create it declaratively:</p> <pre class="highlight" data-language="">application/hpa/php-apache.yaml</pre> <p>Then, create the autoscaler by executing the following command:</p> <pre class="highlight" data-language="shell">kubectl create -f https://k8s.io/examples/application/hpa/php-apache.yaml
</pre>
<pre><code>horizontalpodautoscaler.autoscaling/php-apache created
</code></pre>
<div class="_attribution">
  <p class="_attribution-p">
    Â© 2022 The Kubernetes Authors<br>Documentation Distributed under CC BY 4.0.<br>
    <a href="https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale-walkthrough/" class="_attribution-link">https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale-walkthrough/</a>
  </p>
</div>

				
			</div>
			<ins class="adsbygoogle"
     style="display:block"
     data-ad-client="ca-pub-2572770204602497"
     data-ad-slot="1992473792"
     data-ad-format="auto"
     data-full-width-responsive="true"></ins>
<script>
     (adsbygoogle = window.adsbygoogle || []).push({});
</script>
		</div>
	</section>

	</div>
	<svg style="display:none">
		<symbol id="icon-dir"><svg viewBox="0 0 20 20"><path d="M15 10c0 .3-.305.515-.305.515l-8.56 5.303c-.625.41-1.135.106-1.135-.67V4.853c0-.777.51-1.078 1.135-.67l8.56 5.305S15 9.702 15 10z"/></svg></symbol>
	  </svg>
</body>
</html>
